{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Getting Started","text":"<ul> <li> <p>\ud83d\udea8 Breaking changes</p> <p>UiPath Python SDK v2.2.0+ will introduce breaking changes starting November 26, 2025 See Details</p> </li> </ul> <ul> <li> <p>UiPath SDK</p> <p>Code with full UiPath context to build custom automations and agents from the ground up.</p> <p>Start Building</p> </li> </ul> <ul> <li> <p>UiPath MCP SDK</p> <p>Build and host Coded MCP Servers within UiPath.</p> <p>Start Building</p> </li> </ul>  Extensions  <ul> <li> <p>UiPath Langchain SDK</p> <p>Build enterprise-grade UiPath agents using the LangChain framework, with seamless integration from build to run.</p> <p>Get Started</p> </li> <li> <p>UiPath LlamaIndex SDK</p> <p>Build enterprise-grade UiPath agents using the LlamaIndex framework, with seamless integration from build to run.</p> <p>Get Started</p> </li> <li> <p>UiPath OpenAI Agents SDK</p> <p>Build enterprise-grade UiPath agents using the OpenAI Agents SDK framework, with seamless integration from build to run.</p> <p>Get Started</p> </li> </ul>"},{"location":"AutomationSuite/","title":"Automation Suite","text":""},{"location":"AutomationSuite/#airgapped-deployments","title":"Airgapped Deployments","text":"<p>Airgapped Automation Suite environments (deployments without internet access) require special configuration for Python package dependencies. You need to configure your project to use a Python package feed that is accessible within your environment.</p> <p>You have two main options for managing Python packages:</p> <ol> <li>Use Azure DevOps Artifacts - Leverage Azure DevOps as a Python package feed with upstream PyPI sources (suitable for environments with restricted but not fully airgapped access)</li> <li>Host your own Python package index - Set up a self-hosted PyPI mirror or repository within your infrastructure (required for truly airgapped environments)</li> </ol>"},{"location":"AutomationSuite/#using-azure-devops-artifacts-as-a-python-feed","title":"Using Azure DevOps Artifacts as a Python Feed","text":"<p>Azure DevOps Artifacts can serve as a private Python package feed that includes packages from common public sources (PyPI). This is suitable for environments with restricted internet access where Azure DevOps services are still accessible.</p>"},{"location":"AutomationSuite/#step-1-create-an-azure-devops-artifacts-feed","title":"Step 1: Create an Azure DevOps Artifacts Feed","text":"<ol> <li>Navigate to your Azure DevOps project</li> <li>Go to Artifacts</li> <li>Click Create Feed</li> <li>Configure your feed settings and ensure you select the option to Include packages from common public sources (this will upstream PyPI packages)</li> </ol>"},{"location":"AutomationSuite/#step-2-authenticate-with-a-personal-access-token-pat","title":"Step 2: Authenticate with a Personal Access Token (PAT)","text":"<p>You'll need to create a Personal Access Token (PAT) to authenticate with your Azure DevOps feed.</p> <ol> <li>Follow the Microsoft documentation to create a PAT</li> <li>Ensure your PAT has at least Packaging (Read) permissions</li> <li>Save your PAT securely - you'll need it for the next step</li> </ol>"},{"location":"AutomationSuite/#step-3-configure-your-project","title":"Step 3: Configure Your Project","text":"<p>Add the following configuration to your <code>pyproject.toml</code> file:</p> <pre><code>[[tool.uv.index]]\nname = \"my-feed\"\nurl = \"https://az:PAT_STRING@YOUR_ORG.pkgs.visualstudio.com/YourProject/_packaging/my-feed/pypi/simple/\"\npublish-url = \"https://az:PAT_STRING@YOUR_ORG.pkgs.visualstudio.com/YourProject/_packaging/my-feed/pypi/upload/\"\ndefault = true\n</code></pre> <p>Replace the following placeholders:</p> <ul> <li><code>PAT_STRING</code>: Your actual Personal Access Token from Step 2</li> <li><code>YOUR_ORG</code>: Your Azure DevOps organization name</li> <li><code>YourProject</code>: Your Azure DevOps project name</li> <li><code>my-feed</code>: The name of your feed (in both the <code>name</code> field and the URL)</li> </ul> <p>Tip</p> <p>Organization-scoped feeds: If you're using an organization-scoped feed instead of a project-scoped feed, the URL format will be slightly different, but the same authentication logic applies. The URL will follow this pattern:</p> <pre><code>url = \"https://az:PAT_STRING@YOUR_ORG.pkgs.visualstudio.com/_packaging/my-feed/pypi/simple/\"\n</code></pre> <p>Note the absence of the project name in the URL path.</p> <p>Tip</p> <p>Using environment variables: You can also configure the feed URL using environment variables instead of hardcoding the PAT in <code>pyproject.toml</code>:</p> <pre><code>[[tool.uv.index]]\nname = \"my-feed\"\nurl = \"https://az:${AZURE_DEVOPS_PAT}@YOUR_ORG.pkgs.visualstudio.com/YourProject/_packaging/my-feed/pypi/simple/\"\ndefault = true # to use this feed as your default\n</code></pre> <p>Then set the environment variable before running your commands locally:</p> <pre><code>export AZURE_DEVOPS_PAT=your_pat_token\n</code></pre> <p>Important: When deploying your process to UiPath, you'll need to configure these environment variables in the process settings. Navigate to your process in UiPath Orchestrator and add the environment variables (e.g., <code>AZURE_DEVOPS_PAT</code>) with their corresponding values. This ensures your process can authenticate with the external feed when running in the UiPath environment.</p> <p>Tip</p> <p>Specifying sources for specific packages: If you don't want to set your custom feed as the default, you can use <code>[tool.uv.sources]</code> to specify which packages should come from your custom feed:</p> <pre><code>[[tool.uv.index]]\nname = \"my-feed\"\nurl = \"https://az:PAT_STRING@YOUR_ORG.pkgs.visualstudio.com/YourProject/_packaging/my-feed/pypi/simple/\"\n\n[tool.uv.sources]\nuipath = { index = \"my-feed\" }\n# Add other packages as needed\nsome-private-package = { index = \"my-feed\" }\n</code></pre> <p>This allows you to selectively pull specific packages from your custom feed while using the default PyPI for others.</p>"},{"location":"AutomationSuite/#step-4-install-dependencies","title":"Step 4: Install Dependencies","text":"<p>Once configured, you can install dependencies using <code>uv</code>:</p> uv add uipath\u280b Resolved 25 packages from my-feed\u2713  Successfully installed uipath"},{"location":"AutomationSuite/#verification","title":"Verification","text":"<p>To verify your feed configuration is working correctly, you can check that <code>uv</code> resolves packages from your custom feed:</p> uv add --dry-run uipath\u280b Checking package availability...\u2713  All packages available from my-feed"},{"location":"AutomationSuite/#hosting-your-own-python-package-index","title":"Hosting Your Own Python Package Index","text":"<p>For truly airgapped deployments where you need complete control over your infrastructure, you can host your own Python package index within your network. This approach eliminates any external dependencies and provides full control over the packages available in your environment.</p>"},{"location":"AutomationSuite/#popular-self-hosted-solutions","title":"Popular Self-Hosted Solutions","text":"<p>Several tools are available for hosting a Python package index:</p> <ul> <li>devpi - A PyPI-compatible server with caching and mirroring capabilities</li> <li>PyPI Server - A minimal PyPI-compatible server for hosting packages</li> <li>JFrog Artifactory - Enterprise artifact repository with Python support</li> <li>Sonatype Nexus Repository - Universal artifact repository manager</li> <li>bandersnatch - PyPI mirror client for creating a complete or filtered mirror</li> </ul>"},{"location":"AutomationSuite/#configuration-for-self-hosted-index","title":"Configuration for Self-Hosted Index","text":"<p>Once you have your Python package index set up and accessible within your airgapped network, configure your <code>pyproject.toml</code> to point to it:</p> <pre><code>[[tool.uv.index]]\nname = \"internal-pypi\"\nurl = \"https://pypi.internal.company.com/simple/\"\ndefault = true\n</code></pre> <p>If your internal index requires authentication:</p> <pre><code>[[tool.uv.index]]\nname = \"internal-pypi\"\nurl = \"https://username:password@pypi.internal.company.com/simple/\"\ndefault = true\n</code></pre>"},{"location":"CONTRIBUTING/","title":"Contributing to UiPath SDK","text":""},{"location":"CONTRIBUTING/#local-development-setup","title":"Local Development Setup","text":""},{"location":"CONTRIBUTING/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Install Python \u2265 3.11:</p> <ul> <li>Download and install Python 3.11 from the official Python website</li> <li>Verify the installation by running:     <pre><code>python3.11 --version\n</code></pre></li> </ul> <p>Alternative: mise</p> </li> <li> <p>Install uv:     Follow the official installation instructions for your operating system.</p> </li> <li> <p>Create a virtual environment in the current working directory:     <pre><code>uv venv\n</code></pre></p> </li> <li> <p>Activate the virtual environment:</p> <ul> <li>Linux/Mac <pre><code>source .venv/bin/activate\n</code></pre></li> <li>Windows Powershell <pre><code>.venv\\Scripts\\Activate.ps1\n</code></pre></li> <li>Windows Bash <pre><code>source .venv/Scripts/activate\n</code></pre></li> </ul> </li> <li> <p>Install dependencies:     <pre><code>uv sync --all-extras --no-cache\n</code></pre></p> </li> </ol> <p>For additional commands related to linting, formatting, and building, run <code>just --list</code>.</p>"},{"location":"CONTRIBUTING/#using-the-sdk-locally","title":"Using the SDK Locally","text":"<ol> <li> <p>Create a project directory:     <pre><code>mkdir project\ncd project\n</code></pre></p> </li> <li> <p>Initialize the Python project:     <pre><code>uv init . --python 3.11\n</code></pre></p> </li> <li> <p>Set the SDK path:     <pre><code>PATH_TO_SDK=/Users/YOUR_USERNAME/uipath-python\n</code></pre></p> </li> <li> <p>Install the SDK in editable mode:     <pre><code>uv add --editable ${PATH_TO_SDK}\n</code></pre></p> </li> </ol> <p>Note: Instead of cloning the project into <code>.venv/lib/python3.11/site-packages/uipath</code>, this mode creates a file named <code>_uipath.pth</code> inside <code>.venv/lib/python3.11/site-packages</code>. This file contains the value of <code>PATH_TO_SDK</code>, which is added to <code>sys.path</code>\u2014the list of directories where Python searches for packages. To view the entries, run <code>python -c 'import sys; print(sys.path)'</code>.</p>"},{"location":"CONTRIBUTING/#api-style-guide","title":"API Style Guide","text":""},{"location":"CONTRIBUTING/#general-rule","title":"General Rule","text":"<ul> <li>Use <code>key</code> instead of <code>id</code> for resource identifiers</li> <li>Write well-typed, type-checker-friendly code.</li> <li>Do not use <code># type: ignore</code> comments unless absolutely required.</li> <li>NEVER use <code># type: ignore</code> at the start of a file.</li> </ul>"},{"location":"CONTRIBUTING/#standard-methods-and-naming-conventions","title":"Standard Methods and Naming Conventions","text":""},{"location":"CONTRIBUTING/#retrieve-a-single-resource","title":"Retrieve a Single Resource","text":"<ul> <li>Method Name: <code>retrieve</code></li> <li>Purpose: Obtain a specific resource instance using its unique identifier (using <code>key</code> instead of <code>id</code>)</li> <li>Variations:</li> <li><code>retrieve_by_[field_name]</code> (for fields other than <code>key</code>)</li> </ul>"},{"location":"CONTRIBUTING/#list-multiple-resources","title":"List Multiple Resources","text":"<ul> <li>Method Name: <code>list</code></li> <li>Purpose: Fetch a collection of resources, optionally filtered by query parameters</li> <li>Example: <pre><code>resources = Resource.list(filters={})\n</code></pre></li> </ul>"},{"location":"CONTRIBUTING/#create-a-resource","title":"Create a Resource","text":"<ul> <li>Method Name: <code>create</code></li> <li>Purpose: Add a new resource to the system</li> </ul>"},{"location":"CONTRIBUTING/#update-a-resource","title":"Update a Resource","text":"<ul> <li>Method Name: <code>update</code></li> <li>Purpose: Modify an existing resource</li> </ul>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull Requests","text":""},{"location":"CONTRIBUTING/#general-rules","title":"General Rules","text":"<ul> <li>Please write informative description to the PRs for the reviewers to understand the context.</li> <li>If you want to publish a <code>dev</code> build, please add a <code>build:dev</code> label to your PR.</li> <li>You can then use the published <code>dev</code> version from the PR description/comments to use as needed </li> </ul>"},{"location":"FAQ/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"FAQ/#q-why-am-i-getting-a-failed-to-prepare-environment-error-when-deploying-my-python-agent-to-uipath-cloud-platform","title":"Q: Why am I getting a \"Failed to prepare environment\" error when deploying my python agent to UiPath Cloud Platform?","text":""},{"location":"FAQ/#error-message","title":"Error Message","text":"<pre><code>{\n    \"Code\": \"Serverless.PythonCodedAgent.PrepareEnvironmentError\",\n    \"Title\": \"Failed to prepare environment\",\n    \"Detail\": \"An error occurred while installing the package dependencies. Please try again. If the error persists, please contact support.\",\n    \"Category\": \"System\",\n    \"Status\": null\n}\n</code></pre>"},{"location":"FAQ/#visual-example","title":"Visual Example","text":"<p>Example of the error as it appears in UiPath Cloud Platform</p>"},{"location":"FAQ/#description","title":"Description","text":"<p>This error might occur when deploying coded-agents to UiPath Cloud Platform, even though the same project might work correctly in your local environment. The issue is often related to how Python packages are discovered and distributed during the cloud deployment process.</p>"},{"location":"FAQ/#common-causes","title":"Common Causes","text":"<ol> <li>Multiple top-level packages or modules in your project structure</li> <li>Improper configuration or formatting in the pyproject.toml file</li> </ol>"},{"location":"FAQ/#solution","title":"Solution","text":""},{"location":"FAQ/#1-check-your-project-structure","title":"1. Check Your Project Structure","text":"<ul> <li>Ensure your Python files are organized under a non top-level directory (e.g., using the <code>src</code> layout)</li> <li>Follow the recommended project structure:</li> </ul> <pre><code>project_root/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 your_package/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 your_modules.py\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 setup.cfg/setup.py\n</code></pre>"},{"location":"FAQ/#2-configure-package-discovery","title":"2. Configure Package Discovery","text":"<p>If you need to maintain your current project structure, you can configure custom package discovery in your <code>pyproject.toml</code>:</p> <pre><code>[tool.setuptools]\npy-modules = []\npackages = [\"your_package\"]\n</code></pre>"},{"location":"FAQ/#3-verify-dependencies","title":"3. Verify Dependencies","text":"<ul> <li>Ensure all required dependencies are properly listed in your <code>pyproject.toml</code></li> </ul>"},{"location":"FAQ/#reference","title":"Reference","text":"<p>For more detailed information about package discovery and configuration, refer to the official setuptools documentation.</p>"},{"location":"FAQ/#q-why-am-i-getting-timeouts-or-ssl-certificate_verify_failed-certificate-verify-failed-errors","title":"Q: Why am I getting timeouts or \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed\" errors?","text":"<p>The UiPath CLI automatically works with your corporate network setup, including proxy servers and security tools like ZScaler, by leveraging your system's native SSL certificate store.</p>"},{"location":"FAQ/#proxy-configuration","title":"Proxy Configuration","text":"<p>Configure these environment variables to route CLI traffic through your corporate proxy:</p> Linux/macOS BashWindows PowerShellWindows CMD export HTTP_PROXY=http://proxy.company.com:8080export HTTPS_PROXY=https://proxy.company.com:8080export NO_PROXY=localhost,127.0.0.1uipath auth\u280b Authenticating with UiPath ...\u2713  Authentication successful. $env:HTTP_PROXY=\"http://proxy.company.com:8080\"$env:HTTPS_PROXY=\"https://proxy.company.com:8080\"$env:NO_PROXY=\"localhost,127.0.0.1\"uipath auth\u280b Authenticating with UiPath ...\u2713  Authentication successful. set HTTP_PROXY=http://proxy.company.com:8080set HTTPS_PROXY=https://proxy.company.com:8080set NO_PROXY=localhost,127.0.0.1uipath auth\u280b Authenticating with UiPath ...\u2713  Authentication successful."},{"location":"FAQ/#proxy-authentication","title":"Proxy Authentication","text":"Linux/macOS BashWindows PowerShellWindows CMD export HTTP_PROXY=http://username:password@proxy.company.com:8080export HTTPS_PROXY=https://username:password@proxy.company.com:8080export NO_PROXY=localhost,127.0.0.1uipath publish\u280b Fetching available package feeds...\u2713  Package published successfully! $env:HTTP_PROXY=\"http://username:password@proxy.company.com:8080\"$env:HTTPS_PROXY=\"https://username:password@proxy.company.com:8080\"$env:NO_PROXY=\"localhost,127.0.0.1\"uipath publish\u280b Fetching available package feeds...\u2713  Package published successfully! set HTTP_PROXY=http://username:password@proxy.company.com:8080set HTTPS_PROXY=https://username:password@proxy.company.com:8080set NO_PROXY=localhost,127.0.0.1uipath publish\u280b Fetching available package feeds...\u2713  Package published successfully! <p>Tip</p> <p>For IT Administrators: Add these environment variables to your Group Policy or system configuration:</p> <pre><code>HTTP_PROXY=http://your-proxy.company.com:8080\nHTTPS_PROXY=https://your-proxy.company.com:8080\nNO_PROXY=localhost,127.0.0.1,*.company.com\n</code></pre> <p>Warning</p> <p>The CLI uses a local HTTP server for the authentication callback. You must exclude localhost from your proxy using <code>NO_PROXY=localhost,127.0.0.1</code> or authentication will fail.</p>"},{"location":"FAQ/#troubleshooting","title":"Troubleshooting","text":"# Test proxy connectivitycurl -v --proxy $HTTP_PROXY https://cloud.uipath.com*   Trying 192.168.1.100:8080...* Connected to proxy.company.com (192.168.1.100) port 8080\u2713 Connection successful# Test localhost exclusioncurl --proxy $HTTP_PROXY http://localhost:8080* Bypassing proxy for localhost\u2713 Direct connection to localhost successful"},{"location":"FAQ/#ssl-certificates","title":"SSL Certificates","text":"<p>The UiPath CLI automatically uses your system's certificate store (Windows Certificate Store, macOS Keychain, Linux ca-certificates). Corporate certificates installed via Group Policy or IT tools will be automatically recognized.</p>"},{"location":"FAQ/#troubleshooting-ssl-issues","title":"Troubleshooting SSL Issues","text":"<p>If you encounter SSL certificate errors:</p> <ol> <li>Disable SSL verification (for testing only):</li> </ol> Linux/macOS BashWindows PowerShellWindows CMD export UIPATH_DISABLE_SSL_VERIFY=trueuipath auth\u280b Authenticating with UiPath ...\u2713  Authentication successful. $env:UIPATH_DISABLE_SSL_VERIFY=\"true\"uipath auth\u280b Authenticating with UiPath ...\u2713  Authentication successful. set UIPATH_DISABLE_SSL_VERIFY=trueuipath auth\u280b Authenticating with UiPath ...\u2713  Authentication successful. <ol> <li>Use custom certificate bundle (if needed):</li> </ol> Linux/macOS BashWindows PowerShellWindows CMD export SSL_CERT_FILE=/path/to/company-ca-bundle.pemexport REQUESTS_CA_BUNDLE=/path/to/company-ca-bundle.pemuipath publish\u280b Publishing most recent package...\u2713  Package published successfully! $env:SSL_CERT_FILE=\"C:\\certs\\company-ca-bundle.pem\"$env:REQUESTS_CA_BUNDLE=\"C:\\certs\\company-ca-bundle.pem\"uipath publish\u280b Publishing most recent package...\u2713  Package published successfully! set SSL_CERT_FILE=C:\\certs\\company-ca-bundle.pemset REQUESTS_CA_BUNDLE=C:\\certs\\company-ca-bundle.pemuipath publish\u280b Publishing most recent package...\u2713  Package published successfully!"},{"location":"FAQ/#q-why-are-my-agent-runs-hanging-on-uipath-cloud-platform","title":"Q: Why are my agent runs hanging on UiPath Cloud Platform?","text":""},{"location":"FAQ/#error-message_1","title":"Error Message","text":"<p>You may see errors like these in the logs panel:</p> <pre><code>[Error] .venv/lib/python3.14/site-packages/azure/monitor/opentelemetry/exporter/export/_base.py:472: SyntaxWarning: 'return' in a 'finally' block\n[Error]   return ExportResult.FAILED_NOT_RETRYABLE  # pylint: disable=W0134\n[Error] .venv/lib/python3.14/site-packages/azure/monitor/opentelemetry/exporter/export/_base.py:474: SyntaxWarning: 'return' in a 'finally' block\n[Error]   return result  # pylint: disable=W0134\n</code></pre>"},{"location":"FAQ/#description_1","title":"Description","text":"<p>If your Python agent runs are hanging or not completing when deployed to UiPath Cloud Platform's serverless environment, this may be caused by a library incompatibility issue from an outdated version of the UiPath Python library.</p>"},{"location":"FAQ/#solution_1","title":"Solution","text":"<p>Ensure you're using <code>uipath</code> version 2.1.169 or later. This version includes fixes for serverless execution.</p> <p>To check your current version:</p> uipath --versionuipath version 2.1.169 <p>To upgrade to the latest version:</p> uv sync --upgrade-package uipathInstalled 1 package in 15ms - uipath==2.1.140 + uipath==2.1.169 <p>After upgrading, update your <code>pyproject.toml</code> to ensure the correct version is used in your deployment:</p> <p>pyproject.toml: <pre><code>[project]\ndependencies = [\n    \"uipath&gt;=2.1.169\",\n]\n</code></pre></p> <p>Note: This FAQ will be updated as new information becomes available. If you continue experiencing issues after following these solutions, please contact UiPath support.</p>"},{"location":"release_policy/","title":"Release Policy","text":"<p>The UiPath Python ecosystem is composed of different component packages:</p> <ul> <li><code>uipath</code>: The core SDK package (version &gt;= 2.0.0)</li> <li><code>uipath-langchain</code>: The LangChain integration package (version &gt;= 0.0.0)</li> </ul> <p>Both packages are under rapid development, following semantic versioning in the format of X.Y.Z:</p> <ul> <li>X (major version):<ul> <li><code>uipath</code>: X = 2</li> <li><code>uipath-langchain</code>: X = 0</li> </ul> </li> <li>Y (minor version) increases indicate breaking changes for public interfaces not marked as beta</li> <li>Z (patch version) increases indicate:<ul> <li>Bug fixes</li> <li>New features</li> <li>Changes to private interfaces</li> <li>Changes to beta features</li> </ul> </li> </ul>"},{"location":"release_policy/#version-number-format","title":"Version Number Format","text":"<p>The version format is <code>X.Y.Z</code> where:</p> <ul> <li>For <code>uipath</code>: X = 2 (e.g., 2.0.0, 2.1.0)</li> <li>For <code>uipath-langchain</code>: X = 0 (e.g., 0.0.0, 0.1.0)</li> <li>Y represents the minor version</li> <li>Z represents the patch version</li> </ul>"},{"location":"release_policy/#release-candidates","title":"Release Candidates","text":"<p>From time to time, we will version packages as release candidates. These are versions that are intended to be released as stable versions, but we want to get feedback from the community before doing so.</p> <p>Release candidates are versioned as <code>X.Y.ZrcN</code>. For example:</p> <ul> <li><code>uipath</code>: <code>2.2.0rc1</code></li> <li><code>uipath-langchain</code>: <code>0.1.0rc1</code></li> </ul> <p>If no issues are found, the release candidate will be released as a stable version with the same version number. If issues are found, we will release a new release candidate with an incremented N value (e.g., <code>2.2.0rc2</code> or <code>0.1.0rc2</code>).</p> <p>When upgrading between minor versions, users should review the list of breaking changes and deprecations.</p>"},{"location":"release_policy/#release-cadence","title":"Release Cadence","text":""},{"location":"release_policy/#minor-releases-xy0","title":"Minor Releases (X.Y.0)","text":"<ul> <li>Released as needed based on feature development and breaking changes</li> <li>Include breaking changes for public interfaces not marked as beta</li> <li>Require a migration guide for users</li> <li>Preceded by a release candidate (RC) phase</li> </ul>"},{"location":"release_policy/#patch-releases-xyz","title":"Patch Releases (X.Y.Z)","text":"<ul> <li>Released as needed based on bug fixes and improvements</li> <li>Include bug fixes, new features, and changes to private interfaces</li> <li>Always maintain backward compatibility for public interfaces</li> </ul>"},{"location":"release_policy/#api-stability","title":"API Stability","text":""},{"location":"release_policy/#public-api","title":"Public API","text":"<p>The following components are considered part of the public API:</p> <ul> <li>All classes and methods in the <code>src/uipath</code> directory</li> <li>CLI commands and their interfaces</li> </ul>"},{"location":"release_policy/#internal-api","title":"Internal API","text":"<p>Components marked as internal include:</p> <ul> <li>Methods and classes prefixed with <code>_</code></li> <li>Test utilities and fixtures</li> <li>Build and development tools</li> </ul>"},{"location":"release_policy/#breaking-changes","title":"Breaking Changes","text":"<p>Breaking changes are introduced in minor releases (X.Y.0) and follow these guidelines:</p> <ol> <li>Deprecation Period: Features marked for removal will be deprecated for at least one minor release cycle</li> <li>Migration Path: Breaking changes must provide a clear migration path</li> <li>Documentation: All breaking changes must be documented in the release notes and migration guide</li> <li>Beta Features: Breaking changes to beta features can occur in patch releases</li> </ol>"},{"location":"release_policy/#deprecation-policy","title":"Deprecation Policy","text":"<ol> <li>Announcement: Features to be deprecated will be announced in release notes</li> <li>Warning Period: Deprecated features will trigger warnings when used</li> <li>Removal: Deprecated features will be removed in the next major release</li> </ol>"},{"location":"release_policy/#release-process","title":"Release Process","text":"<ol> <li> <p>Development:</p> <ul> <li>Features and fixes are developed in feature branches</li> <li>All changes require tests and documentation</li> <li>Code must pass all CI checks</li> </ul> </li> <li> <p>Release Candidate:</p> <ul> <li>Minor releases include an RC phase</li> <li>RCs are versioned as <code>X.Y.ZrcN</code></li> <li>Community feedback is collected during RC phase</li> </ul> </li> <li> <p>Release:</p> <ul> <li>Version number is updated in <code>pyproject.toml</code></li> <li>Release notes are prepared</li> <li>Package is published to PyPI</li> <li>Documentation is updated</li> </ul> </li> </ol>"},{"location":"release_policy/#support-policy","title":"Support Policy","text":"<ul> <li>Current major version: Full support</li> <li>Previous major version: Security fixes only</li> <li>Older versions: No official support</li> </ul>"},{"location":"release_policy/#dependencies","title":"Dependencies","text":"<p>The SDK maintains compatibility with:</p> <ul> <li>Python 3.11+</li> <li>Key dependencies as specified in <code>pyproject.toml</code></li> <li>Regular updates to dependencies are performed in minor releases</li> </ul>"},{"location":"release_policy/#documentation","title":"Documentation","text":"<ul> <li>All public APIs must be documented</li> <li>Documentation follows Google-style docstrings</li> <li>Examples and usage guides are provided for new features</li> <li>Breaking changes are clearly documented in migration guides</li> </ul>"},{"location":"cli/","title":"CLI Reference","text":""},{"location":"cli/#auth","title":"auth","text":"<p>Authenticate with UiPath Cloud Platform.</p> <p>The domain for authentication is determined by the UIPATH_URL environment variable if set. Otherwise, it can be specified with --cloud (default), --staging, or --alpha flags.</p> <p>Interactive mode (default): Opens browser for OAuth authentication.</p> <p>Unattended mode: Use --client-id, --client-secret, --base-url and --scope for client credentials flow.</p> <p>Network options:</p> <ul> <li>Set HTTP_PROXY/HTTPS_PROXY/NO_PROXY environment variables for proxy configuration</li> <li>Set REQUESTS_CA_BUNDLE to specify a custom CA bundle for SSL verification</li> <li>Set UIPATH_DISABLE_SSL_VERIFY to disable SSL verification (not recommended)</li> </ul> <p>Usage:</p> <pre><code>auth [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--cloud</code> text Use production environment <code>Sentinel.UNSET</code> <code>--staging</code> text Use staging environment <code>Sentinel.UNSET</code> <code>--alpha</code> text Use alpha environment <code>Sentinel.UNSET</code> <code>-f</code>, <code>--force</code> boolean Force new token <code>False</code> <code>--client-id</code> text Client ID for client credentials authentication (unattended mode) <code>Sentinel.UNSET</code> <code>--client-secret</code> text Client secret for client credentials authentication (unattended mode) <code>Sentinel.UNSET</code> <code>--base-url</code> text Base URL for the UiPath tenant instance (required for client credentials) <code>Sentinel.UNSET</code> <code>--tenant</code> text Tenant name within UiPath Automation Cloud <code>Sentinel.UNSET</code> <code>--scope</code> text Space-separated list of OAuth scopes to request (e.g., 'OR.Execution OR.Queues'). Defaults to 'OR.Execution' <code>OR.Execution</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>UiPath Automation Suite</p> <p>For UiPath Automation Suite deployments, you must set the <code>UIPATH_URL</code> environment variable to your dedicated instance URL before running this command.</p> <p>Example: <pre><code>UIPATH_URL=https://your-instance.com/account/tenant/orchestrator_/\n</code></pre></p> <p>You can set this environment variable either: - In a <code>.env</code> file in your project directory - As a system-wide environment variable</p> uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful."},{"location":"cli/#init","title":"init","text":"<p>Initialize the project.</p> <p>Usage:</p> <pre><code>init [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--no-agents-md-override</code> boolean Won't override existing .agent files and AGENTS.md file. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Package requirements (bindings) are dependencies that are required by the automation package for successful execution.</p> <p>For more information about package requirements, see  the official documentation</p> <p>Warning</p> <p>The <code>uipath.json</code> file should include your entry points in the <code>functions</code> section: <pre><code>{\n  \"functions\": {\n    \"main\": \"main.py:main\"\n  }\n}\n</code></pre></p> <p>Running <code>uipath init</code> will process these function definitions and create the corresponding <code>entry-points.json</code> file needed for deployment.</p> uipath init\u280b Initializing UiPath project ...\u2713  Created 'entry-points.json' file."},{"location":"cli/#run","title":"run","text":"<p>Execute the project.</p> <p>Usage:</p> <pre><code>run [OPTIONS] [ENTRYPOINT] [INPUT]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--resume</code> boolean Resume execution from a previous state <code>False</code> <code>-f</code>, <code>--file</code> path File path for the .json input <code>Sentinel.UNSET</code> <code>--input-file</code> path Alias for '-f/--file' arguments <code>Sentinel.UNSET</code> <code>--output-file</code> path File path where the output will be written <code>Sentinel.UNSET</code> <code>--trace-file</code> path File path where the trace spans will be written (JSON Lines format) <code>Sentinel.UNSET</code> <code>--state-file</code> path File path where the state file is stored for persisting execution state. If not provided, a temporary file will be used. <code>Sentinel.UNSET</code> <code>--debug</code> boolean Enable debugging with debugpy. The process will wait for a debugger to attach. <code>False</code> <code>--debug-port</code> integer Port for the debug server (default: 5678) <code>5678</code> <code>--keep-state-file</code> boolean Keep the temporary state file even when not resuming and no job id is provided <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Tip</p> <p>For step-by-step debugging with breakpoints and variable inspection (supported from <code>2.0.66</code> onward): <pre><code># Install debugpy package\n[uv] pip install debugpy\n# Run agent with debugging enabled\nuipath run [ENTRYPOINT] [INPUT] --debug\n</code></pre> For vscode: 1. add the debug configuration in your <code>.vscode/launch.json</code> file. 2. Place breakpoints in your code where needed. 3. Use the shortcut <code>F5</code>, or navigate to Run -&gt; Start Debugging -&gt; Python Debugger: Attach.</p> <p>Upon starting the debugging process, one should see the following logs in terminal: <pre><code>\ud83d\udc1b Debug server started on port 5678\n\ud83d\udccc Waiting for debugger to attach...\n  - VS Code: Run -&gt; Start Debugging -&gt; Python Debugger: Attach\n\u2713  Debugger attached successfully!\n</code></pre></p> <p>Warning</p> <p>Depending on the shell you are using, it may be necessary to escape the input json:</p> Bash/ZSHWindows CMDWindows PowerShell <pre><code>uipath run agent '{\"topic\": \"UiPath\"}'\n</code></pre> <pre><code>uipath run agent \"{\"\"topic\"\": \"\"UiPath\"\"}\"\n</code></pre> <pre><code>uipath run agent '{\\\"topic\\\":\\\"uipath\\\"}'\n</code></pre> uipath run main '{\"message\": \"test\"}'[2025-04-11 10:13:58,857][INFO] {'message': 'test'}"},{"location":"cli/#pack","title":"pack","text":"<p>Pack the project.</p> <p>Usage:</p> <pre><code>pack [OPTIONS] [ROOT]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--nolock</code> boolean Skip running uv lock and exclude uv.lock from the package <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Packages your project into a <code>.nupkg</code> file that can be deployed to UiPath.</p> <p>Info</p> <p>Warning</p> <p>Your <code>pyproject.toml</code> must include:</p> <ul> <li>A description field (avoid characters: &amp;, &lt;, &gt;, \", ', ;)</li> <li>Author information</li> </ul> <p>Example:</p> <pre><code>description = \"Your package description\"\nauthors = [{name = \"Your Name\", email = \"your.email@example.com\"}]\n</code></pre> uipath pack\u280b Packaging project ...Name       : testVersion    : 0.1.0Description: Add your description hereAuthors    : Your Name\u2713  Project successfully packaged."},{"location":"cli/#default-files-included-in-nupkg","title":"Default Files Included in <code>.nupkg</code>","text":"<p>By default, the following file types are included in the <code>.nupkg</code> file:</p> <ul> <li><code>.py</code></li> <li><code>.mermaid</code></li> <li><code>.json</code></li> <li><code>.yaml</code></li> <li><code>.yml</code></li> </ul>"},{"location":"cli/#including-extra-files","title":"Including Extra Files","text":"<p>To include additional files, update the <code>uipath.json</code> file by adding a <code>packOptions</code> section. Use the following configuration format:</p> <pre><code>{\n    \"packOptions\": {\n        \"filesIncluded\": [\n            \"&lt;file here&gt;\"\n        ],\n        \"fileExtensionsIncluded\": [\n            \"&lt;new file extension to include (e.g., 'go')&gt;\"\n        ]\n    }\n}\n</code></pre>"},{"location":"cli/#publish","title":"publish","text":"<p>Publish the package.</p> <p>Usage:</p> <pre><code>publish [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--tenant</code>, <code>-t</code> text Whether to publish to the tenant package feed <code>Sentinel.UNSET</code> <code>--my-workspace</code>, <code>-w</code> text Whether to publish to the personal workspace <code>Sentinel.UNSET</code> <code>--folder</code>, <code>-f</code> text Folder name to publish to (skips interactive selection) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code> <p>Warning</p> <p>To properly use the CLI for packaging and publishing, your project should include:</p> <ul> <li>A <code>pyproject.toml</code> file with project metadata</li> <li>A <code>uipath.json</code> file (generated by <code>uipath init</code>)</li> <li>Any Python files needed for your automation</li> </ul> uipath publish\u280b Fetching available package feeds...\ud83d\udc47 Select package feed:  0: Orchestrator Tenant Processes Feed  1: Orchestrator Personal Workspace FeedSelect feed number: 0Selected feed: Orchestrator Tenant Processes Feed\u2838 Publishing most recent package: test.0.1.0.nupkg ...\u2713  Package published successfully!"},{"location":"cli/#deploy","title":"deploy","text":"<p>Pack and publish the project.</p> <p>Usage:</p> <pre><code>deploy [OPTIONS] [ROOT]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--tenant</code>, <code>-t</code> text Whether to publish to the tenant package feed <code>Sentinel.UNSET</code> <code>--my-workspace</code>, <code>-w</code> text Whether to publish to the personal workspace <code>Sentinel.UNSET</code> <code>--folder</code>, <code>-f</code> text Folder name to publish to (skips interactive selection) <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"cli/#invoke","title":"invoke","text":"<p>Invoke an agent published in my workspace.</p> <p>Usage:</p> <pre><code>invoke [OPTIONS] [ENTRYPOINT] [INPUT]\n</code></pre> <p>Options:</p> Name Type Description Default <code>-f</code>, <code>--file</code> path File path for the .json input <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code> uipath invoke agent '{\"topic\": \"UiPath\"}'\u2834 Loading configuration ...\u2834 Starting job ...\u2728 Job started successfully!\ud83d\udd17 Monitor your job here: [LINK]"},{"location":"cli/#push","title":"push","text":"<p>Push local project files to Studio Web.</p> <p>This command pushes the local project files to a UiPath Studio Web project. It ensures that the remote project structure matches the local files by:</p> <ul> <li>Updating existing files that have changed</li> <li>Uploading new files</li> <li>Deleting remote files that no longer exist locally</li> <li>Optionally managing the UV lock file</li> </ul> <p>Environment Variables:</p> <ul> <li><code>UIPATH_PROJECT_ID</code>: Required. The ID of the UiPath Cloud project</li> </ul> <p>Example:</p> <pre><code>$ uipath push\n$ uipath push --nolock\n$ uipath push --overwrite\n$ uipath push --ignore-resources\n</code></pre> <p>Usage:</p> <pre><code>push [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--ignore-resources</code> boolean Skip importing the referenced resources to Studio Web solution <code>False</code> <code>--nolock</code> boolean Skip running uv lock and exclude uv.lock from the package <code>False</code> <code>--overwrite</code> boolean Automatically overwrite remote files without prompts <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code> uipath pushPushing UiPath project to Studio Web...Uploading 'main.py'Uploading 'uipath.json'Updating 'pyproject.toml'Uploading '.uipath/studio_metadata.json'Importing referenced resources to Studio Web project... \ud83d\udd35 Resource import summary: 0 total resources - 0 created, 0 updated, 0 unchanged, 0 not found"},{"location":"cli/#pull","title":"pull","text":"<p>Pull remote project files from Studio Web.</p> <p>This command pulls the remote project files from a UiPath Studio Web project.</p> <p>Environment Variables:     UIPATH_PROJECT_ID: Required. The ID of the UiPath Studio Web project</p> <p>Example:</p> <pre><code>$ uipath pull\n$ uipath pull /path/to/project\n$ uipath pull --overwrite\n</code></pre> <p>Usage:</p> <pre><code>pull [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--overwrite</code> boolean Automatically overwrite local files without prompts <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code> uipath pullPulling UiPath project from Studio Web...Processing: main.pyUpdated 'main.py'Processing: uipath.jsonFile 'uipath.json' is up to date\u2713  Project pulled successfully"},{"location":"core/assets/","title":"Assets","text":""},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService","title":"AssetsService","text":"<p>Service for managing UiPath assets.</p> <p>Assets are key-value pairs that can be used to store configuration data, credentials, and other settings used by automation processes.</p>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.list","title":"list","text":"<pre><code>list(\n    *,\n    folder_path=None,\n    folder_key=None,\n    filter=None,\n    orderby=None,\n    skip=0,\n    top=100,\n)\n</code></pre> <p>List assets using OData API with offset-based pagination.</p> <p>Returns a single page of results with pagination metadata.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str | None</code> <p>Folder path to filter assets.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key (mutually exclusive with folder_path).</p> <code>None</code> <code>filter</code> <code>str | None</code> <p>OData $filter expression (e.g., \"ValueType eq 'Text'\").</p> <code>None</code> <code>orderby</code> <code>str | None</code> <p>OData $orderby expression (e.g., \"Name asc\").</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of items to skip (default 0, max 10000).</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum items per page (default 100, max 1000).</p> <code>100</code> <p>Returns:</p> Type Description <code>PagedResult[Asset]</code> <p>PagedResult[Asset]: Page of assets with pagination metadata.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip or top parameters are invalid.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\n# List all assets in the default folder\nresult = client.assets.list(top=100)\nfor asset in result.items:\n    print(asset.name, asset.value_type)\n\n# List with filter\nresult = client.assets.list(filter=\"ValueType eq 'Text'\")\n\n# Paginate through all assets\nskip = 0\nwhile True:\n    result = client.assets.list(skip=skip, top=100)\n    for asset in result.items:\n        print(asset.name)\n    if not result.has_more:\n        break\n    skip += 100\n</code></pre>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.list_async","title":"list_async  <code>async</code>","text":"<pre><code>list_async(\n    *,\n    folder_path=None,\n    folder_key=None,\n    filter=None,\n    orderby=None,\n    skip=0,\n    top=100,\n)\n</code></pre> <p>Asynchronously list assets using OData API with offset-based pagination.</p> <p>Returns a single page of results with pagination metadata.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str | None</code> <p>Folder path to filter assets.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key (mutually exclusive with folder_path).</p> <code>None</code> <code>filter</code> <code>str | None</code> <p>OData $filter expression (e.g., \"ValueType eq 'Text'\").</p> <code>None</code> <code>orderby</code> <code>str | None</code> <p>OData $orderby expression (e.g., \"Name asc\").</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of items to skip (default 0, max 10000).</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum items per page (default 100, max 1000).</p> <code>100</code> <p>Returns:</p> Type Description <code>PagedResult[Asset]</code> <p>PagedResult[Asset]: Page of assets with pagination metadata.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip or top parameters are invalid.</p>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.retrieve","title":"retrieve","text":"<pre><code>retrieve(name, *, folder_key=None, folder_path=None)\n</code></pre> <p>Retrieve an asset by its name.</p> <p>Related Activity: Get Asset</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the asset.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>UserAsset</code> <code>UserAsset | Asset</code> <p>The asset data.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\nclient.assets.retrieve(name=\"MyAsset\")\n</code></pre>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(name, *, folder_key=None, folder_path=None)\n</code></pre> <p>Asynchronously retrieve an asset by its name.</p> <p>Related Activity: Get Asset</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the asset.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>UserAsset</code> <code>UserAsset | Asset</code> <p>The asset data.</p>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.retrieve_credential","title":"retrieve_credential","text":"<pre><code>retrieve_credential(\n    name, *, folder_key=None, folder_path=None\n)\n</code></pre> <p>Gets a specified Orchestrator credential.</p> <p>The robot id is retrieved from the execution context (<code>UIPATH_ROBOT_KEY</code> environment variable)</p> <p>Related Activity: Get Credential</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the credential asset.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>str | None</code> <p>Optional[str]: The decrypted credential password.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is called for a user asset.</p>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.retrieve_credential_async","title":"retrieve_credential_async  <code>async</code>","text":"<pre><code>retrieve_credential_async(\n    name, *, folder_key=None, folder_path=None\n)\n</code></pre> <p>Asynchronously gets a specified Orchestrator credential.</p> <p>The robot id is retrieved from the execution context (<code>UIPATH_ROBOT_KEY</code> environment variable)</p> <p>Related Activity: Get Credential</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the credential asset.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>str | None</code> <p>Optional[str]: The decrypted credential password.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is called for a user asset.</p>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.update","title":"update","text":"<pre><code>update(robot_asset, *, folder_key=None, folder_path=None)\n</code></pre> <p>Update an asset's value.</p> <p>Related Activity: Set Asset</p> <p>Parameters:</p> Name Type Description Default <code>robot_asset</code> <code>UserAsset</code> <p>The asset object containing the updated values.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>The HTTP response confirming the update.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the method is called for a user asset.</p>"},{"location":"core/assets/#uipath.platform.orchestrator._assets_service.AssetsService.update_async","title":"update_async  <code>async</code>","text":"<pre><code>update_async(\n    robot_asset, *, folder_key=None, folder_path=None\n)\n</code></pre> <p>Asynchronously update an asset's value.</p> <p>Related Activity: Set Asset</p> <p>Parameters:</p> Name Type Description Default <code>robot_asset</code> <code>UserAsset</code> <p>The asset object containing the updated values.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>The HTTP response confirming the update.</p>"},{"location":"core/attachments/","title":"Attachments","text":""},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService","title":"AttachmentsService","text":"<p>Service for managing UiPath attachments.</p> <p>Attachments allow you to upload and download files to be used within UiPath processes, actions, and other UiPath services.</p> <p>Reference: https://docs.uipath.com/orchestrator/reference/api-attachments</p>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.custom_headers","title":"custom_headers  <code>property</code>","text":"<pre><code>custom_headers\n</code></pre> <p>Return custom headers for API requests.</p>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.delete","title":"delete","text":"<pre><code>delete(*, key, folder_key=None, folder_path=None)\n</code></pre> <p>Delete an attachment.</p> <p>This method deletes an attachment from UiPath. If the attachment is not found in UiPath (404 error), it will check for a local file in the temporary directory that matches the UUID.</p> Note <p>The local file fallback functionality is intended for local development and debugging purposes only.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>UUID</code> <p>The key of the attachment to delete.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion fails and no local file is found.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\nclient.attachments.delete(\n    key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\")\n)\nprint(\"Attachment deleted successfully\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(*, key, folder_key=None, folder_path=None)\n</code></pre> <p>Delete an attachment asynchronously.</p> <p>This method asynchronously deletes an attachment from UiPath. If the attachment is not found in UiPath (404 error), it will check for a local file in the temporary directory that matches the UUID.</p> Note <p>The local file fallback functionality is intended for local development and debugging purposes only.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>UUID</code> <p>The key of the attachment to delete.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion fails and no local file is found.</p> <p>Examples:</p> <pre><code>import asyncio\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nasync def main():\n    await client.attachments.delete_async(\n        key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\")\n    )\n    print(\"Attachment deleted successfully\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.download","title":"download","text":"<pre><code>download(\n    *,\n    key,\n    destination_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Download an attachment.</p> <p>This method downloads an attachment from UiPath to a local file. If the attachment is not found in UiPath (404 error), it will check for a local file in the temporary directory that matches the UUID.</p> Note <p>The local file fallback functionality is intended for local development and debugging purposes only.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>UUID</code> <p>The key of the attachment to download.</p> required <code>destination_path</code> <code>str</code> <p>The local path where the attachment will be saved.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the downloaded attachment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the download fails and no local file is found.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\nattachment_name = client.attachments.download(\n    key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\"),\n    destination_path=\"path/to/save/document.pdf\"\n)\nprint(f\"Downloaded attachment: {attachment_name}\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.download_async","title":"download_async  <code>async</code>","text":"<pre><code>download_async(\n    *,\n    key,\n    destination_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Download an attachment asynchronously.</p> <p>This method asynchronously downloads an attachment from UiPath to a local file. If the attachment is not found in UiPath (404 error), it will check for a local file in the temporary directory that matches the UUID.</p> Note <p>The local file fallback functionality is intended for local development and debugging purposes only.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>UUID</code> <p>The key of the attachment to download.</p> required <code>destination_path</code> <code>str</code> <p>The local path where the attachment will be saved.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the downloaded attachment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the download fails and no local file is found.</p> <p>Examples:</p> <pre><code>import asyncio\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nasync def main():\n    attachment_name = await client.attachments.download_async(\n        key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\"),\n        destination_path=\"path/to/save/document.pdf\"\n    )\n    print(f\"Downloaded attachment: {attachment_name}\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.get_blob_file_access_uri","title":"get_blob_file_access_uri","text":"<pre><code>get_blob_file_access_uri(\n    *, key, folder_key=None, folder_path=None\n)\n</code></pre> <p>Get the BlobFileAccess information for an attachment.</p> <p>This method retrieves the blob storage URI and filename for downloading an attachment without actually downloading the file.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>UUID</code> <p>The key of the attachment.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BlobFileAccessInfo</code> <code>BlobFileAccessInfo</code> <p>Object containing the blob storage URI and attachment name.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the attachment is not found or the request fails.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\ninfo = client.attachments.get_blob_file_access_uri(\n    key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\")\n)\nprint(f\"Attachment ID: {info.id}\")\nprint(f\"Blob URI: {info.uri}\")\nprint(f\"File name: {info.name}\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.get_blob_file_access_uri_async","title":"get_blob_file_access_uri_async  <code>async</code>","text":"<pre><code>get_blob_file_access_uri_async(\n    *, key, folder_key=None, folder_path=None\n)\n</code></pre> <p>Get the BlobFileAccess information for an attachment asynchronously.</p> <p>This method asynchronously retrieves the blob storage URI and filename for downloading an attachment without actually downloading the file.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>UUID</code> <p>The key of the attachment.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BlobFileAccessInfo</code> <code>BlobFileAccessInfo</code> <p>Object containing the blob storage URI and attachment name.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the attachment is not found or the request fails.</p> <p>Examples:</p> <pre><code>import asyncio\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nasync def main():\n    info = await client.attachments.get_blob_file_access_uri_async(\n        key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\")\n    )\n    print(f\"Attachment ID: {info.id}\")\n    print(f\"Blob URI: {info.uri}\")\n    print(f\"File name: {info.name}\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.open","title":"open","text":"<pre><code>open(\n    *,\n    attachment,\n    mode=AttachmentMode.READ,\n    content=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Open an attachment.</p> <p>Parameters:</p> Name Type Description Default <code>attachment</code> <code>Attachment</code> <p>The attachment to open.</p> required <code>mode</code> <code>AttachmentMode</code> <p>The mode to use.</p> <code>READ</code> <code>content</code> <code>RequestContent | None</code> <p>An optional request content to upload.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>Iterator[tuple[Attachment, Response]]</code> <p>The name of the downloaded attachment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the download fails and no local file is found.</p>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.open_async","title":"open_async  <code>async</code>","text":"<pre><code>open_async(\n    *,\n    attachment,\n    mode=AttachmentMode.READ,\n    content=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Open an attachment asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>attachment</code> <code>Attachment</code> <p>The attachment to open.</p> required <code>mode</code> <code>AttachmentMode</code> <p>The mode to use.</p> <code>READ</code> <code>content</code> <code>RequestContent</code> <p>An optional request content to upload.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>AsyncIterator[tuple[Attachment, Response]]</code> <p>The name of the downloaded attachment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the download fails and no local file is found.</p>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.upload","title":"upload","text":"<pre><code>upload(\n    *,\n    name,\n    content=None,\n    source_path=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Upload a file or content to UiPath as an attachment.</p> <p>This method uploads content to UiPath and makes it available as an attachment. You can either provide a file path or content in memory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the attachment file.</p> required <code>content</code> <code>str | bytes | None</code> <p>The content to upload (string or bytes).</p> <code>None</code> <code>source_path</code> <code>str | None</code> <p>The local path of the file to upload.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>UUID</code> <p>uuid.UUID: The UUID of the created attachment.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither content nor source_path is provided, or if both are provided.</p> <code>Exception</code> <p>If the upload fails.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\n# Upload a file from disk\nattachment_key = client.attachments.upload(\n    name=\"my-document.pdf\",\n    source_path=\"path/to/local/document.pdf\",\n)\nprint(f\"Uploaded attachment with key: {attachment_key}\")\n\n# Upload content from memory\nattachment_key = client.attachments.upload(\n    name=\"notes.txt\",\n    content=\"This is a text file content\",\n)\nprint(f\"Uploaded attachment with key: {attachment_key}\")\n</code></pre>"},{"location":"core/attachments/#uipath.platform.orchestrator._attachments_service.AttachmentsService.upload_async","title":"upload_async  <code>async</code>","text":"<pre><code>upload_async(\n    *,\n    name,\n    content=None,\n    source_path=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Upload a file or content to UiPath as an attachment asynchronously.</p> <p>This method asynchronously uploads content to UiPath and makes it available as an attachment. You can either provide a file path or content in memory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the attachment file.</p> required <code>content</code> <code>str | bytes | None</code> <p>The content to upload (string or bytes).</p> <code>None</code> <code>source_path</code> <code>str | None</code> <p>The local path of the file to upload.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>UUID</code> <p>uuid.UUID: The UUID of the created attachment.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither content nor source_path is provided, or if both are provided.</p> <code>Exception</code> <p>If the upload fails.</p> <p>Examples:</p> <pre><code>import asyncio\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nasync def main():\n    # Upload a file from disk\n    attachment_key = await client.attachments.upload_async(\n        name=\"my-document.pdf\",\n        source_path=\"path/to/local/document.pdf\",\n    )\n    print(f\"Uploaded attachment with key: {attachment_key}\")\n\n    # Upload content from memory\n    attachment_key = await client.attachments.upload_async(\n        name=\"notes.txt\",\n        content=\"This is a text file content\",\n    )\n    print(f\"Uploaded attachment with key: {attachment_key}\")\n</code></pre>"},{"location":"core/buckets/","title":"Buckets","text":""},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService","title":"BucketsService","text":"<p>Service for managing UiPath storage buckets.</p> <p>Buckets are cloud storage containers that can be used to store and manage files used by automation processes.</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.create","title":"create","text":"<pre><code>create(\n    name,\n    *,\n    description=None,\n    identifier=None,\n    folder_path=None,\n    folder_key=None,\n)\n</code></pre> <p>Create a new bucket.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Bucket name (must be unique within folder)</p> required <code>description</code> <code>str | None</code> <p>Optional description</p> <code>None</code> <code>identifier</code> <code>str | None</code> <p>UUID identifier (auto-generated if not provided)</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder to create bucket in</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Bucket</code> <code>Bucket</code> <p>Newly created bucket resource</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If bucket creation fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bucket = sdk.buckets.create(\"my-storage\")\n&gt;&gt;&gt; bucket = sdk.buckets.create(\n...     \"data-storage\",\n...     description=\"Production data\"\n... )\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.create_async","title":"create_async  <code>async</code>","text":"<pre><code>create_async(\n    name,\n    *,\n    description=None,\n    identifier=None,\n    folder_path=None,\n    folder_key=None,\n)\n</code></pre> <p>Async version of create().</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.delete","title":"delete","text":"<pre><code>delete(\n    *,\n    name=None,\n    key=None,\n    folder_path=None,\n    folder_key=None,\n)\n</code></pre> <p>Delete a bucket.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier (UUID)</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <p>Raises:</p> Type Description <code>LookupError</code> <p>If bucket is not found</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sdk.buckets.delete(name=\"old-storage\")\n&gt;&gt;&gt; sdk.buckets.delete(key=\"abc-123-def\")\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(\n    *,\n    name=None,\n    key=None,\n    folder_path=None,\n    folder_key=None,\n)\n</code></pre> <p>Async version of delete().</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.delete_file","title":"delete_file","text":"<pre><code>delete_file(\n    *,\n    name=None,\n    key=None,\n    blob_file_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Delete a file from a bucket.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>Path to the file in the bucket</p> required <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sdk.buckets.delete_file(name=\"my-storage\", blob_file_path=\"data/file.txt\")\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.delete_file_async","title":"delete_file_async  <code>async</code>","text":"<pre><code>delete_file_async(\n    *,\n    name=None,\n    key=None,\n    blob_file_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Delete a file from a bucket asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>Path to the file in the bucket</p> required <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; await sdk.buckets.delete_file_async(name=\"my-storage\", blob_file_path=\"data/file.txt\")\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.download","title":"download","text":"<pre><code>download(\n    *,\n    name=None,\n    key=None,\n    blob_file_path,\n    destination_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Download a file from a bucket.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | None</code> <p>The key of the bucket.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>The name of the bucket.</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>The path to the file in the bucket.</p> required <code>destination_path</code> <code>str</code> <p>The local path where the file will be saved.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the bucket resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the bucket resides.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither key nor name is provided.</p> <code>Exception</code> <p>If the bucket with the specified key is not found.</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.download_async","title":"download_async  <code>async</code>","text":"<pre><code>download_async(\n    *,\n    name=None,\n    key=None,\n    blob_file_path,\n    destination_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Download a file from a bucket asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | None</code> <p>The key of the bucket.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>The name of the bucket.</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>The path to the file in the bucket.</p> required <code>destination_path</code> <code>str</code> <p>The local path where the file will be saved.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the bucket resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the bucket resides.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither key nor name is provided.</p> <code>Exception</code> <p>If the bucket with the specified key is not found.</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.exists","title":"exists","text":"<pre><code>exists(name, *, folder_key=None, folder_path=None)\n</code></pre> <p>Check if bucket exists.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Bucket name</p> required <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if bucket exists</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; if sdk.buckets.exists(\"my-storage\"):\n...     print(\"Bucket found\")\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.exists_async","title":"exists_async  <code>async</code>","text":"<pre><code>exists_async(name, *, folder_key=None, folder_path=None)\n</code></pre> <p>Async version of exists().</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.exists_file","title":"exists_file","text":"<pre><code>exists_file(\n    *,\n    name=None,\n    key=None,\n    blob_file_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Check if a file exists in a bucket.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>Path to the file in the bucket (cannot be empty)</p> required <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if file exists, False otherwise</p> Note <p>This method uses short-circuit iteration to stop at the first match, making it memory-efficient even for large buckets. It will raise LookupError if the bucket itself doesn't exist.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If blob_file_path is empty or whitespace-only</p> <code>LookupError</code> <p>If bucket is not found</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; if sdk.buckets.exists_file(name=\"my-storage\", blob_file_path=\"data/file.csv\"):\n...     print(\"File exists\")\n&gt;&gt;&gt; # Check in specific folder\n&gt;&gt;&gt; exists = sdk.buckets.exists_file(\n...     name=\"my-storage\",\n...     blob_file_path=\"reports/2024/summary.pdf\",\n...     folder_path=\"Production\"\n... )\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.exists_file_async","title":"exists_file_async  <code>async</code>","text":"<pre><code>exists_file_async(\n    *,\n    name=None,\n    key=None,\n    blob_file_path,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Async version of exists_file().</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>Path to the file in the bucket (cannot be empty)</p> required <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if file exists, False otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If blob_file_path is empty or whitespace-only</p> <code>LookupError</code> <p>If bucket is not found</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; if await sdk.buckets.exists_file_async(name=\"my-storage\", blob_file_path=\"data/file.csv\"):\n...     print(\"File exists\")\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.get_files","title":"get_files","text":"<pre><code>get_files(\n    *,\n    name=None,\n    key=None,\n    prefix=\"\",\n    recursive=False,\n    file_name_glob=None,\n    skip=0,\n    top=500,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Get files using OData GetFiles API with offset-based pagination.</p> <p>This method uses the OData API with $skip/$top for pagination. Supports recursive traversal, glob filtering, and OData features. Automatically excludes directories from results.</p> <p>Note: Offset-based pagination can degrade performance with very large skip values (e.g., skip &gt; 10000). For sequential iteration over large datasets, consider list_files() instead.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Directory path to filter files (default: root)</p> <code>''</code> <code>recursive</code> <code>bool</code> <p>Recurse subdirectories for flat view (default: False)</p> <code>False</code> <code>file_name_glob</code> <code>str | None</code> <p>File filter pattern (e.g., \".pdf\", \"data_.csv\")</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of files to skip (default 0, max 10000). Used for pagination.</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum number of files to return (default 500, max 1000).</p> <code>500</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Type Description <code>PagedResult[BucketFile]</code> <p>PagedResult[BucketFile]: Page containing files (directories excluded) and pagination metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip &lt; 0, skip &gt; 10000, top &lt; 1, top &gt; 1000, neither name nor key is provided, or file_name_glob is empty</p> <code>LookupError</code> <p>If bucket not found</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get first page\n&gt;&gt;&gt; result = sdk.buckets.get_files(name=\"my-storage\")\n&gt;&gt;&gt; for file in result.items:\n...     print(file.name)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Filter with glob pattern\n&gt;&gt;&gt; result = sdk.buckets.get_files(\n...     name=\"my-storage\",\n...     recursive=True,\n...     file_name_glob=\"*.pdf\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Manual offset-based pagination\n&gt;&gt;&gt; skip = 0\n&gt;&gt;&gt; top = 500\n&gt;&gt;&gt; all_files = []\n&gt;&gt;&gt; while True:\n...     result = sdk.buckets.get_files(\n...         name=\"my-storage\",\n...         prefix=\"reports/\",\n...         skip=skip,\n...         top=top\n...     )\n...     all_files.extend(result.items)\n...     if not result.has_more:\n...         break\n...     skip += top\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Helper function\n&gt;&gt;&gt; def iter_all_files_odata(sdk, bucket_name, **filters):\n...     skip = 0\n...     top = 500\n...     while True:\n...         result = sdk.buckets.get_files(\n...             name=bucket_name,\n...             skip=skip,\n...             top=top,\n...             **filters\n...         )\n...         yield from result.items\n...         if not result.has_more:\n...             break\n...         skip += top\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Usage with filters\n&gt;&gt;&gt; for file in iter_all_files_odata(\n...     sdk,\n...     \"my-storage\",\n...     recursive=True,\n...     file_name_glob=\"*.pdf\"\n... ):\n...     process_file(file)\n</code></pre> Performance <p>Best for: Filtered queries, random access, sorted results. Consider list_files() for: Sequential iteration over large datasets.</p> <p>Performance degrades with large skip values due to database offset costs.</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.get_files_async","title":"get_files_async  <code>async</code>","text":"<pre><code>get_files_async(\n    *,\n    name=None,\n    key=None,\n    prefix=\"\",\n    recursive=False,\n    file_name_glob=None,\n    skip=0,\n    top=500,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Async version of get_files() with offset-based pagination.</p> <p>Returns a single page of results with pagination metadata. Automatically excludes directories from results.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Directory path to filter files</p> <code>''</code> <code>recursive</code> <code>bool</code> <p>Recurse subdirectories for flat view</p> <code>False</code> <code>file_name_glob</code> <code>str | None</code> <p>File filter pattern (e.g., \"*.pdf\")</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of files to skip (default 0, max 10000)</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum number of files to return (default 500, max 1000)</p> <code>500</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Type Description <code>PagedResult[BucketFile]</code> <p>PagedResult[BucketFile]: Page containing files (directories excluded) and pagination metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip &lt; 0, skip &gt; 10000, top &lt; 1, top &gt; 1000, neither name nor key is provided, or file_name_glob is empty</p> <code>LookupError</code> <p>If bucket not found</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get first page\n&gt;&gt;&gt; result = await sdk.buckets.get_files_async(\n...     name=\"my-storage\",\n...     recursive=True,\n...     file_name_glob=\"*.pdf\"\n... )\n&gt;&gt;&gt; for file in result.items:\n...     print(file.name)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Manual pagination\n&gt;&gt;&gt; skip = 0\n&gt;&gt;&gt; top = 500\n&gt;&gt;&gt; all_files = []\n&gt;&gt;&gt; while True:\n...     result = await sdk.buckets.get_files_async(\n...         name=\"my-storage\",\n...         skip=skip,\n...         top=top\n...     )\n...     all_files.extend(result.items)\n...     if not result.has_more:\n...         break\n...     skip += top\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.list","title":"list","text":"<pre><code>list(\n    *,\n    folder_path=None,\n    folder_key=None,\n    name=None,\n    skip=0,\n    top=100,\n)\n</code></pre> <p>List buckets using OData API with offset-based pagination.</p> <p>Returns a single page of results with pagination metadata.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str | None</code> <p>Folder path to filter buckets</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key (mutually exclusive with folder_path)</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Filter by bucket name (contains match)</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of buckets to skip (default 0, max 10000)</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum number of buckets to return (default 100, max 1000)</p> <code>100</code> <p>Returns:</p> Type Description <code>PagedResult[Bucket]</code> <p>PagedResult[Bucket]: Page containing buckets and pagination metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip &lt; 0, skip &gt; 10000, top &lt; 1, or top &gt; 1000</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get first page\n&gt;&gt;&gt; result = sdk.buckets.list(top=100)\n&gt;&gt;&gt; for bucket in result.items:\n...     print(bucket.name)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Check pagination metadata\n&gt;&gt;&gt; if result.has_more:\n...     print(f\"More results available. Current: skip={result.skip}, top={result.top}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Manual pagination to get all buckets\n&gt;&gt;&gt; skip = 0\n&gt;&gt;&gt; top = 100\n&gt;&gt;&gt; all_buckets = []\n&gt;&gt;&gt; while True:\n...     result = sdk.buckets.list(skip=skip, top=top, name=\"invoice\")\n...     all_buckets.extend(result.items)\n...     if not result.has_more:\n...         break\n...     skip += top\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Helper function for complete iteration\n&gt;&gt;&gt; def iter_all_buckets(sdk, top=100, **filters):\n...     skip = 0\n...     while True:\n...         result = sdk.buckets.list(skip=skip, top=top, **filters)\n...         yield from result.items\n...         if not result.has_more:\n...             break\n...         skip += top\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Usage\n&gt;&gt;&gt; for bucket in iter_all_buckets(sdk, name=\"invoice\"):\n...     process_bucket(bucket)\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.list_async","title":"list_async  <code>async</code>","text":"<pre><code>list_async(\n    *,\n    folder_path=None,\n    folder_key=None,\n    name=None,\n    skip=0,\n    top=100,\n)\n</code></pre> <p>Async version of list() with offset-based pagination.</p> <p>Returns a single page of results with pagination metadata.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str | None</code> <p>Folder path to filter buckets</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key (mutually exclusive with folder_path)</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Filter by bucket name (contains match)</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of buckets to skip (default 0, max 10000)</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum number of buckets to return (default 100, max 1000)</p> <code>100</code> <p>Returns:</p> Type Description <code>PagedResult[Bucket]</code> <p>PagedResult[Bucket]: Page containing buckets and pagination metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip &lt; 0, skip &gt; 10000, top &lt; 1, or top &gt; 1000</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get first page\n&gt;&gt;&gt; result = await sdk.buckets.list_async(top=100)\n&gt;&gt;&gt; for bucket in result.items:\n...     print(bucket.name)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Manual pagination\n&gt;&gt;&gt; skip = 0\n&gt;&gt;&gt; top = 100\n&gt;&gt;&gt; all_buckets = []\n&gt;&gt;&gt; while True:\n...     result = await sdk.buckets.list_async(skip=skip, top=top)\n...     all_buckets.extend(result.items)\n...     if not result.has_more:\n...         break\n...     skip += top\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.list_files","title":"list_files","text":"<pre><code>list_files(\n    *,\n    name=None,\n    key=None,\n    prefix=\"\",\n    take_hint=500,\n    continuation_token=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>List files in a bucket using cursor-based pagination.</p> <p>Returns a single page of results with continuation token for manual pagination. This method uses the REST API with continuation tokens for efficient pagination of large file sets. Recommended for sequential iteration over millions of files.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Filter files by prefix</p> <code>''</code> <code>take_hint</code> <code>int</code> <p>Minimum number of files to return (default 500, max 1000).       The API may return up to 2x this value in some cases.</p> <code>500</code> <code>continuation_token</code> <code>str | None</code> <p>Token from previous response. Pass None for first page.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Type Description <code>PagedResult[BucketFile]</code> <p>PagedResult[BucketFile]: Page containing files and continuation token metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If take_hint is not between 1 and 1000</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get first page\n&gt;&gt;&gt; result = sdk.buckets.list_files(name=\"my-storage\")\n&gt;&gt;&gt; print(f\"Got {len(result.items)} files\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Manual pagination to get all files\n&gt;&gt;&gt; all_files = []\n&gt;&gt;&gt; token = None\n&gt;&gt;&gt; while True:\n...     result = sdk.buckets.list_files(\n...         name=\"my-storage\",\n...         prefix=\"reports/2024/\",\n...         continuation_token=token\n...     )\n...     all_files.extend(result.items)\n...     if not result.continuation_token:\n...         break\n...     token = result.continuation_token\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Helper function for iteration\n&gt;&gt;&gt; def iter_all_files(sdk, bucket_name, prefix=\"\"):\n...     token = None\n...     while True:\n...         result = sdk.buckets.list_files(\n...             name=bucket_name,\n...             prefix=prefix,\n...             continuation_token=token\n...         )\n...         yield from result.items\n...         if not result.continuation_token:\n...             break\n...         token = result.continuation_token\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Usage\n&gt;&gt;&gt; for file in iter_all_files(sdk, \"my-storage\", \"reports/\"):\n...     print(file.path)\n</code></pre> Performance <p>Cursor-based pagination scales efficiently to millions of files. Each page requires one API call regardless of dataset size.</p> <p>For sequential processing, this is the most efficient method. For filtered queries, consider get_files() with OData filters.</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.list_files_async","title":"list_files_async  <code>async</code>","text":"<pre><code>list_files_async(\n    *,\n    name=None,\n    key=None,\n    prefix=\"\",\n    take_hint=500,\n    continuation_token=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Async version of list_files() with cursor-based pagination.</p> <p>Returns a single page of results with continuation token for manual pagination.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Bucket name</p> <code>None</code> <code>key</code> <code>str | None</code> <p>Bucket identifier</p> <code>None</code> <code>prefix</code> <code>str</code> <p>Filter files by prefix</p> <code>''</code> <code>take_hint</code> <code>int</code> <p>Minimum number of files to return (default 500, max 1000).       The API may return up to 2x this value in some cases.</p> <code>500</code> <code>continuation_token</code> <code>str | None</code> <p>Token from previous response. Pass None for first page.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Type Description <code>PagedResult[BucketFile]</code> <p>PagedResult[BucketFile]: Page containing files and continuation token metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If take_hint is not between 1 and 1000</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get first page\n&gt;&gt;&gt; result = await sdk.buckets.list_files_async(name=\"my-storage\")\n&gt;&gt;&gt; print(f\"Got {len(result.items)} files\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Manual pagination\n&gt;&gt;&gt; all_files = []\n&gt;&gt;&gt; token = None\n&gt;&gt;&gt; while True:\n...     result = await sdk.buckets.list_files_async(\n...         name=\"my-storage\",\n...         continuation_token=token\n...     )\n...     all_files.extend(result.items)\n...     if not result.continuation_token:\n...         break\n...     token = result.continuation_token\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    *,\n    name=None,\n    key=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Retrieve bucket information by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>The name of the bucket to retrieve.</p> <code>None</code> <code>key</code> <code>str | None</code> <p>The key of the bucket.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the bucket resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the bucket resides.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Bucket</code> <code>Bucket</code> <p>The bucket resource instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither bucket key nor bucket name is provided.</p> <code>Exception</code> <p>If the bucket with the specified name is not found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bucket = sdk.buckets.retrieve(name=\"my-storage\")\n&gt;&gt;&gt; print(bucket.name, bucket.identifier)\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(\n    *,\n    name=None,\n    key=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Asynchronously retrieve bucket information by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>The name of the bucket to retrieve.</p> <code>None</code> <code>key</code> <code>str | None</code> <p>The key of the bucket.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the bucket resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the bucket resides.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Bucket</code> <code>Bucket</code> <p>The bucket resource instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither bucket key nor bucket name is provided.</p> <code>Exception</code> <p>If the bucket with the specified name is not found.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; bucket = await sdk.buckets.retrieve_async(name=\"my-storage\")\n&gt;&gt;&gt; print(bucket.name, bucket.identifier)\n</code></pre>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.upload","title":"upload","text":"<pre><code>upload(\n    *,\n    key=None,\n    name=None,\n    blob_file_path,\n    content_type=None,\n    source_path=None,\n    content=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Upload a file to a bucket.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | None</code> <p>The key of the bucket.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>The name of the bucket.</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>The path where the file will be stored in the bucket.</p> required <code>content_type</code> <code>str | None</code> <p>The MIME type of the file. For file inputs this is computed dynamically. Default is \"application/octet-stream\".</p> <code>None</code> <code>source_path</code> <code>str | None</code> <p>The local path of the file to upload.</p> <code>None</code> <code>content</code> <code>str | bytes | None</code> <p>The content to upload (string or bytes).</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the bucket resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the bucket resides.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither key nor name is provided.</p> <code>Exception</code> <p>If the bucket with the specified key or name is not found.</p>"},{"location":"core/buckets/#uipath.platform.orchestrator._buckets_service.BucketsService.upload_async","title":"upload_async  <code>async</code>","text":"<pre><code>upload_async(\n    *,\n    key=None,\n    name=None,\n    blob_file_path,\n    content_type=None,\n    source_path=None,\n    content=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Upload a file to a bucket asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str | None</code> <p>The key of the bucket.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>The name of the bucket.</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>The path where the file will be stored in the bucket.</p> required <code>content_type</code> <code>str | None</code> <p>The MIME type of the file. For file inputs this is computed dynamically. Default is \"application/octet-stream\".</p> <code>None</code> <code>source_path</code> <code>str | None</code> <p>The local path of the file to upload.</p> <code>None</code> <code>content</code> <code>str | bytes | None</code> <p>The content to upload (string or bytes).</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the bucket resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the bucket resides.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither key nor name is provided.</p> <code>Exception</code> <p>If the bucket with the specified key or name is not found.</p>"},{"location":"core/connections/","title":"Connections","text":""},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService","title":"ConnectionsService","text":"<p>Service for managing UiPath external service connections.</p> <p>This service provides methods to retrieve direct connection information retrieval and secure token management.</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.invoke_activity","title":"invoke_activity","text":"<pre><code>invoke_activity(\n    activity_metadata, connection_id, activity_input\n)\n</code></pre> <p>Invoke an activity synchronously.</p> <p>Parameters:</p> Name Type Description Default <code>activity_metadata</code> <code>ActivityMetadata</code> <p>Metadata describing the activity to invoke</p> required <code>connection_id</code> <code>str</code> <p>The ID of the connection</p> required <code>activity_input</code> <code>dict[str, Any]</code> <p>Input parameters for the activity</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The response from the activity</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required parameters are missing or invalid</p> <code>RuntimeError</code> <p>If the HTTP request fails or returns an error status</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.invoke_activity_async","title":"invoke_activity_async  <code>async</code>","text":"<pre><code>invoke_activity_async(\n    activity_metadata, connection_id, activity_input\n)\n</code></pre> <p>Invoke an activity asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>activity_metadata</code> <code>ActivityMetadata</code> <p>Metadata describing the activity to invoke</p> required <code>connection_id</code> <code>str</code> <p>The ID of the connection</p> required <code>activity_input</code> <code>dict[str, Any]</code> <p>Input parameters for the activity</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The response from the activity</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required parameters are missing or invalid</p> <code>RuntimeError</code> <p>If the HTTP request fails or returns an error status</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.list","title":"list","text":"<pre><code>list(\n    *,\n    name=None,\n    folder_path=None,\n    folder_key=None,\n    connector_key=None,\n    skip=None,\n    top=None,\n)\n</code></pre> <p>Lists all connections with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional connection name to filter (supports partial matching)</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Optional folder path for filtering connections</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Optional folder key (mutually exclusive with folder_path)</p> <code>None</code> <code>connector_key</code> <code>str | None</code> <p>Optional connector key to filter by specific connector type</p> <code>None</code> <code>skip</code> <code>int | None</code> <p>Number of records to skip (for pagination)</p> <code>None</code> <code>top</code> <code>int | None</code> <p>Maximum number of records to return</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Connection]</code> <p>List[Connection]: List of connection instances</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both folder_path and folder_key are provided together, or if folder_path is provided but cannot be resolved to a folder_key</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # List all connections\n&gt;&gt;&gt; connections = sdk.connections.list()\n</code></pre> <pre><code>&gt;&gt;&gt; # Find connections by name\n&gt;&gt;&gt; salesforce_conns = sdk.connections.list(name=\"Salesforce\")\n</code></pre> <pre><code>&gt;&gt;&gt; # List all Slack connections in Finance folder\n&gt;&gt;&gt; connections = sdk.connections.list(\n...     folder_path=\"Finance\",\n...     connector_key=\"uipath-slack\"\n... )\n</code></pre>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.list_async","title":"list_async  <code>async</code>","text":"<pre><code>list_async(\n    *,\n    name=None,\n    folder_path=None,\n    folder_key=None,\n    connector_key=None,\n    skip=None,\n    top=None,\n)\n</code></pre> <p>Asynchronously lists all connections with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional connection name to filter (supports partial matching)</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Optional folder path for filtering connections</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Optional folder key (mutually exclusive with folder_path)</p> <code>None</code> <code>connector_key</code> <code>str | None</code> <p>Optional connector key to filter by specific connector type</p> <code>None</code> <code>skip</code> <code>int | None</code> <p>Number of records to skip (for pagination)</p> <code>None</code> <code>top</code> <code>int | None</code> <p>Maximum number of records to return</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Connection]</code> <p>List[Connection]: List of connection instances</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both folder_path and folder_key are provided together, or if folder_path is provided but cannot be resolved to a folder_key</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # List all connections\n&gt;&gt;&gt; connections = await sdk.connections.list_async()\n</code></pre> <pre><code>&gt;&gt;&gt; # Find connections by name\n&gt;&gt;&gt; salesforce_conns = await sdk.connections.list_async(name=\"Salesforce\")\n</code></pre> <pre><code>&gt;&gt;&gt; # List all Slack connections in Finance folder\n&gt;&gt;&gt; connections = await sdk.connections.list_async(\n...     folder_path=\"Finance\",\n...     connector_key=\"uipath-slack\"\n... )\n</code></pre>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.metadata","title":"metadata","text":"<pre><code>metadata(\n    element_instance_id,\n    connector_key,\n    tool_path,\n    parameters=None,\n    schema_mode=True,\n    max_jit_depth=5,\n)\n</code></pre> <p>Synchronously retrieve connection API metadata.</p> <p>This method fetches the metadata for a connection. When parameters are provided, it automatically fetches JIT (Just-In-Time) metadata for cascading fields in a loop, following action URLs up to a maximum depth.</p> <p>Parameters:</p> Name Type Description Default <code>element_instance_id</code> <code>int</code> <p>The element instance ID of the connection.</p> required <code>connector_key</code> <code>str</code> <p>The connector key (e.g., 'uipath-atlassian-jira', 'uipath-slack').</p> required <code>tool_path</code> <code>str</code> <p>The tool path to retrieve metadata for.</p> required <code>parameters</code> <code>dict[str, str] | None</code> <p>Parameter values. When provided, triggers automatic JIT fetching for cascading fields.</p> <code>None</code> <code>schema_mode</code> <code>bool</code> <p>Whether or not to represent the output schema in the response fields.</p> <code>True</code> <code>max_jit_depth</code> <code>int</code> <p>The maximum depth of the JIT resolution loop.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>ConnectionMetadata</code> <code>ConnectionMetadata</code> <p>The connection metadata.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metadata = sdk.connections.metadata(\n...     element_instance_id=123,\n...     connector_key=\"uipath-atlassian-jira\",\n...     tool_path=\"Issue\",\n...     parameters={\"projectId\": \"PROJ-123\"}  # Optional\n... )\n</code></pre>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.metadata_async","title":"metadata_async  <code>async</code>","text":"<pre><code>metadata_async(\n    element_instance_id,\n    connector_key,\n    tool_path,\n    parameters=None,\n    schema_mode=True,\n    max_jit_depth=5,\n)\n</code></pre> <p>Asynchronously retrieve connection API metadata.</p> <p>This method fetches the metadata for a connection. When parameters are provided, it automatically fetches JIT (Just-In-Time) metadata for cascading fields in a loop, following action URLs up to a maximum depth.</p> <p>Parameters:</p> Name Type Description Default <code>element_instance_id</code> <code>int</code> <p>The element instance ID of the connection.</p> required <code>connector_key</code> <code>str</code> <p>The connector key (e.g., 'uipath-atlassian-jira', 'uipath-slack').</p> required <code>tool_path</code> <code>str</code> <p>The tool path to retrieve metadata for.</p> required <code>parameters</code> <code>dict[str, str] | None</code> <p>Parameter values. When provided, triggers automatic JIT fetching for cascading fields.</p> <code>None</code> <code>schema_mode</code> <code>bool</code> <p>Whether or not to represent the output schema in the response fields.</p> <code>True</code> <code>max_jit_depth</code> <code>int</code> <p>The maximum depth of the JIT resolution loop.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>ConnectionMetadata</code> <code>ConnectionMetadata</code> <p>The connection metadata.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; metadata = await sdk.connections.metadata_async(\n...     element_instance_id=123,\n...     connector_key=\"uipath-atlassian-jira\",\n...     tool_path=\"Issue\",\n...     parameters={\"projectId\": \"PROJ-123\"}  # Optional\n... )\n</code></pre>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.retrieve","title":"retrieve","text":"<pre><code>retrieve(key)\n</code></pre> <p>Retrieve connection details by its key.</p> <p>This method fetches the configuration and metadata for a connection, which can be used to establish communication with an external service.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The unique identifier of the connection to retrieve.</p> required <p>Returns:</p> Name Type Description <code>Connection</code> <code>Connection</code> <p>The connection details, including configuration parameters and authentication information.</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(key)\n</code></pre> <p>Asynchronously retrieve connection details by its key.</p> <p>This method fetches the configuration and metadata for a connection, which can be used to establish communication with an external service.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The unique identifier of the connection to retrieve.</p> required <p>Returns:</p> Name Type Description <code>Connection</code> <code>Connection</code> <p>The connection details, including configuration parameters and authentication information.</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.retrieve_event_payload","title":"retrieve_event_payload","text":"<pre><code>retrieve_event_payload(event_args)\n</code></pre> <p>Retrieve event payload from UiPath Integration Service.</p> <p>Parameters:</p> Name Type Description Default <code>event_args</code> <code>EventArguments</code> <p>The event arguments. Should be passed along from the job's input.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: The event payload data</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.retrieve_event_payload_async","title":"retrieve_event_payload_async  <code>async</code>","text":"<pre><code>retrieve_event_payload_async(event_args)\n</code></pre> <p>Retrieve event payload from UiPath Integration Service.</p> <p>Parameters:</p> Name Type Description Default <code>event_args</code> <code>EventArguments</code> <p>The event arguments. Should be passed along from the job's input.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict[str, Any]: The event payload data</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.retrieve_token","title":"retrieve_token","text":"<pre><code>retrieve_token(key, token_type=ConnectionTokenType.DIRECT)\n</code></pre> <p>Retrieve an authentication token for a connection.</p> <p>This method obtains a fresh authentication token that can be used to communicate with the external service. This is particularly useful for services that use token-based authentication.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The unique identifier of the connection.</p> required <code>token_type</code> <code>ConnectionTokenType</code> <p>The token type to use.</p> <code>DIRECT</code> <p>Returns:</p> Name Type Description <code>ConnectionToken</code> <code>ConnectionToken</code> <p>The authentication token details, including the token value and any associated metadata.</p>"},{"location":"core/connections/#uipath.platform.connections._connections_service.ConnectionsService.retrieve_token_async","title":"retrieve_token_async  <code>async</code>","text":"<pre><code>retrieve_token_async(\n    key, token_type=ConnectionTokenType.DIRECT\n)\n</code></pre> <p>Asynchronously retrieve an authentication token for a connection.</p> <p>This method obtains a fresh authentication token that can be used to communicate with the external service. This is particularly useful for services that use token-based authentication.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The unique identifier of the connection.</p> required <code>token_type</code> <code>ConnectionTokenType</code> <p>The token type to use.</p> <code>DIRECT</code> <p>Returns:</p> Name Type Description <code>ConnectionToken</code> <code>ConnectionToken</code> <p>The authentication token details, including the token value and any associated metadata.</p>"},{"location":"core/context_grounding/","title":"Context Grounding","text":""},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService","title":"ContextGroundingService","text":"<p>Service for managing semantic automation contexts in UiPath.</p> <p>Context Grounding is a feature that helps in understanding and managing the semantic context in which automation processes operate. It provides capabilities for indexing, retrieving, and searching through contextual information that can be used to enhance AI-enabled automation.</p> <p>This service requires a valid folder key to be set in the environment, as context grounding operations are always performed within a specific folder context.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.add_to_index","title":"add_to_index","text":"<pre><code>add_to_index(\n    name,\n    blob_file_path,\n    content_type=None,\n    content=None,\n    source_path=None,\n    folder_key=None,\n    folder_path=None,\n    ingest_data=True,\n)\n</code></pre> <p>Add content to the index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the index to add content to.</p> required <code>content_type</code> <code>str | None</code> <p>The MIME type of the file. For file inputs this is computed dynamically. Default is \"application/octet-stream\".</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>The path where the blob will be stored in the storage bucket.</p> required <code>content</code> <code>str | bytes | None</code> <p>The content to be added, either as a string or bytes.</p> <code>None</code> <code>source_path</code> <code>str | None</code> <p>The source path of the content if it is being uploaded from a file.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code> <code>ingest_data</code> <code>bool</code> <p>Whether to ingest data in the index after content is uploaded. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither content nor source_path is provided, or if both are provided.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.add_to_index_async","title":"add_to_index_async  <code>async</code>","text":"<pre><code>add_to_index_async(\n    name,\n    blob_file_path,\n    content_type=None,\n    content=None,\n    source_path=None,\n    folder_key=None,\n    folder_path=None,\n    ingest_data=True,\n)\n</code></pre> <p>Asynchronously add content to the index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the index to add content to.</p> required <code>content_type</code> <code>str | None</code> <p>The MIME type of the file. For file inputs this is computed dynamically. Default is \"application/octet-stream\".</p> <code>None</code> <code>blob_file_path</code> <code>str</code> <p>The path where the blob will be stored in the storage bucket.</p> required <code>content</code> <code>str | bytes | None</code> <p>The content to be added, either as a string or bytes.</p> <code>None</code> <code>source_path</code> <code>str | None</code> <p>The source path of the content if it is being uploaded from a file.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code> <code>ingest_data</code> <code>bool</code> <p>Whether to ingest data in the index after content is uploaded. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither content nor source_path is provided, or if both are provided.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.create_ephemeral_index","title":"create_ephemeral_index","text":"<pre><code>create_ephemeral_index(usage, attachments)\n</code></pre> <p>Create a new ephemeral context grounding index.</p> <p>Parameters:</p> Name Type Description Default <code>usage</code> <code>EphemeralIndexUsage</code> <p>The task type for the ephemeral index (DeepRAG or BatchRAG)</p> required <code>attachments</code> <code>list[str]</code> <p>The list of attachments ids from which the ephemeral index will be created</p> required <p>Returns:</p> Name Type Description <code>ContextGroundingIndex</code> <code>ContextGroundingIndex</code> <p>The created index information.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.create_ephemeral_index_async","title":"create_ephemeral_index_async  <code>async</code>","text":"<pre><code>create_ephemeral_index_async(usage, attachments)\n</code></pre> <p>Create a new ephemeral context grounding index.</p> <p>Parameters:</p> Name Type Description Default <code>usage</code> <code>EphemeralIndexUsage</code> <p>The task type for the ephemeral index (DeepRAG or BatchRAG)</p> required <code>attachments</code> <code>list[str]</code> <p>The list of attachments ids from which the ephemeral index will be created</p> required <p>Returns:</p> Name Type Description <code>ContextGroundingIndex</code> <code>ContextGroundingIndex</code> <p>The created index information.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.create_index","title":"create_index","text":"<pre><code>create_index(\n    name,\n    source,\n    description=None,\n    advanced_ingestion=True,\n    preprocessing_request=LLMV4_REQUEST,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Create a new context grounding index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the index to create.</p> required <code>source</code> <code>SourceConfig</code> <p>Source configuration using one of: - BucketSourceConfig: For storage buckets - GoogleDriveSourceConfig: For Google Drive - DropboxSourceConfig: For Dropbox - OneDriveSourceConfig: For OneDrive - ConfluenceSourceConfig: For Confluence</p> <p>The source can include an optional indexer field for scheduled indexing:     source.indexer = Indexer(cron_expression=\"0 0 18 ? * 2\", time_zone_id=\"UTC\")</p> required <code>description</code> <code>str | None</code> <p>Description of the index.</p> <code>None</code> <code>advanced_ingestion</code> <code>bool | None</code> <p>Enable advanced ingestion with preprocessing. Defaults to True.</p> <code>True</code> <code>preprocessing_request</code> <code>str | None</code> <p>The OData type for preprocessing request. Defaults to LLMV4_REQUEST.</p> <code>LLMV4_REQUEST</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index will be created.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index will be created.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ContextGroundingIndex</code> <code>ContextGroundingIndex</code> <p>The created index information.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.create_index_async","title":"create_index_async  <code>async</code>","text":"<pre><code>create_index_async(\n    name,\n    source,\n    description=None,\n    advanced_ingestion=True,\n    preprocessing_request=LLMV4_REQUEST,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Create a new context grounding index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the index to create.</p> required <code>source</code> <code>SourceConfig</code> <p>Source configuration using one of: - BucketSourceConfig: For storage buckets - GoogleDriveSourceConfig: For Google Drive - DropboxSourceConfig: For Dropbox - OneDriveSourceConfig: For OneDrive - ConfluenceSourceConfig: For Confluence</p> <p>The source can include an optional indexer field for scheduled indexing:     source.indexer = Indexer(cron_expression=\"0 0 18 ? * 2\", time_zone_id=\"UTC\")</p> required <code>description</code> <code>str | None</code> <p>Description of the index.</p> <code>None</code> <code>advanced_ingestion</code> <code>bool | None</code> <p>Enable advanced ingestion with preprocessing. Defaults to True.</p> <code>True</code> <code>preprocessing_request</code> <code>str | None</code> <p>The OData type for preprocessing request. Defaults to LLMV4_REQUEST.</p> <code>LLMV4_REQUEST</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index will be created.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index will be created.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ContextGroundingIndex</code> <code>ContextGroundingIndex</code> <p>The created index information.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.delete_index","title":"delete_index","text":"<pre><code>delete_index(index, folder_key=None, folder_path=None)\n</code></pre> <p>Delete a context grounding index.</p> <p>This method removes the specified context grounding index from Orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>ContextGroundingIndex</code> <p>The context grounding index to delete.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.delete_index_async","title":"delete_index_async  <code>async</code>","text":"<pre><code>delete_index_async(\n    index, folder_key=None, folder_path=None\n)\n</code></pre> <p>Asynchronously delete a context grounding index.</p> <p>This method removes the specified context grounding index from Orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>ContextGroundingIndex</code> <p>The context grounding index to delete.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.download_batch_transform_result","title":"download_batch_transform_result","text":"<pre><code>download_batch_transform_result(\n    id,\n    destination_path,\n    *,\n    validate_status=True,\n    index_name=None,\n)\n</code></pre> <p>Downloads the Batch Transform result file to the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the Batch Transform task.</p> required <code>destination_path</code> <code>str</code> <p>The local file path where the result file will be saved.</p> required <code>validate_status</code> <code>bool</code> <p>Whether to validate the batch transform status before downloading. Defaults to True.</p> <code>True</code> <code>index_name</code> <code>str | None</code> <p>Index name hint for resource override.</p> <code>None</code> <p>Raises:</p> Type Description <code>BatchTransformNotCompleteException</code> <p>If validate_status is True and the batch transform is not complete.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.download_batch_transform_result_async","title":"download_batch_transform_result_async  <code>async</code>","text":"<pre><code>download_batch_transform_result_async(\n    id,\n    destination_path,\n    *,\n    validate_status=True,\n    index_name=None,\n)\n</code></pre> <p>Asynchronously downloads the Batch Transform result file to the specified path.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the Batch Transform task.</p> required <code>destination_path</code> <code>str</code> <p>The local file path where the result file will be saved.</p> required <code>validate_status</code> <code>bool</code> <p>Whether to validate the batch transform status before downloading. Defaults to True.</p> <code>True</code> <code>index_name</code> <code>str | None</code> <p>Index name hint for resource override.</p> <code>None</code> <p>Raises:</p> Type Description <code>BatchTransformNotCompleteException</code> <p>If validate_status is True and the batch transform is not complete.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.ingest_data","title":"ingest_data","text":"<pre><code>ingest_data(index, folder_key=None, folder_path=None)\n</code></pre> <p>Ingest data into the context grounding index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>ContextGroundingIndex</code> <p>The context grounding index to perform data ingestion.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.ingest_data_async","title":"ingest_data_async  <code>async</code>","text":"<pre><code>ingest_data_async(index, folder_key=None, folder_path=None)\n</code></pre> <p>Asynchronously ingest data into the context grounding index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>ContextGroundingIndex</code> <p>The context grounding index to perform data ingestion.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve","title":"retrieve","text":"<pre><code>retrieve(name, folder_key=None, folder_path=None)\n</code></pre> <p>Retrieve context grounding index information by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the context index to retrieve.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ContextGroundingIndex</code> <code>ContextGroundingIndex</code> <p>The index information, including its configuration and metadata if found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no index with the given name is found.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(name, folder_key=None, folder_path=None)\n</code></pre> <p>Asynchronously retrieve context grounding index information by its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the context index to retrieve.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ContextGroundingIndex</code> <code>ContextGroundingIndex</code> <p>The index information, including its configuration and metadata if found.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no index with the given name is found.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_batch_transform","title":"retrieve_batch_transform","text":"<pre><code>retrieve_batch_transform(id, *, index_name=None)\n</code></pre> <p>Retrieves a Batch Transform task status.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the Batch Transform task.</p> required <code>index_name</code> <code>str | None</code> <p>Index name hint for resource override.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchTransformResponse</code> <code>BatchTransformResponse</code> <p>The Batch Transform task response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_batch_transform_async","title":"retrieve_batch_transform_async  <code>async</code>","text":"<pre><code>retrieve_batch_transform_async(id, *, index_name=None)\n</code></pre> <p>Asynchronously retrieves a Batch Transform task status.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the Batch Transform task.</p> required <code>index_name</code> <code>str | None</code> <p>Index name hint for resource override.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchTransformResponse</code> <code>BatchTransformResponse</code> <p>The Batch Transform task response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_by_id","title":"retrieve_by_id","text":"<pre><code>retrieve_by_id(id, folder_key=None, folder_path=None)\n</code></pre> <p>Retrieve context grounding index information by its ID.</p> <p>This method provides direct access to a context index using its unique identifier, which can be more efficient than searching by name.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The unique identifier of the context index.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The index information, including its configuration and metadata.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_by_id_async","title":"retrieve_by_id_async  <code>async</code>","text":"<pre><code>retrieve_by_id_async(id, folder_key=None, folder_path=None)\n</code></pre> <p>Retrieve asynchronously context grounding index information by its ID.</p> <p>This method provides direct access to a context index using its unique identifier, which can be more efficient than searching by name.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The unique identifier of the context index.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder where the index resides.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder where the index resides.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The index information, including its configuration and metadata.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_deep_rag","title":"retrieve_deep_rag","text":"<pre><code>retrieve_deep_rag(id, *, index_name=None)\n</code></pre> <p>Retrieves a Deep RAG task.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the Deep RAG task.</p> required <code>index_name</code> <code>str | None</code> <p>Index name hint for resource override.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeepRagResponse</code> <code>DeepRagResponse</code> <p>The Deep RAG task response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.retrieve_deep_rag_async","title":"retrieve_deep_rag_async  <code>async</code>","text":"<pre><code>retrieve_deep_rag_async(id, *, index_name=None)\n</code></pre> <p>Asynchronously retrieves a Deep RAG task.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The id of the Deep RAG task.</p> required <code>index_name</code> <code>str | None</code> <p>Index name hint for resource override.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeepRagResponse</code> <code>DeepRagResponse</code> <p>The Deep RAG task response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.search","title":"search","text":"<pre><code>search(\n    name,\n    query,\n    number_of_results=10,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Search for contextual information within a specific index.</p> <p>This method performs a semantic search against the specified context index, helping to find relevant information that can be used in automation processes. The search is powered by AI and understands natural language queries.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the context index to search in.</p> required <code>query</code> <code>str</code> <p>The search query in natural language.</p> required <code>number_of_results</code> <code>int</code> <p>Maximum number of results to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[ContextGroundingQueryResponse]</code> <p>List[ContextGroundingQueryResponse]: A list of search results, each containing relevant contextual information and metadata.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.search_async","title":"search_async  <code>async</code>","text":"<pre><code>search_async(\n    name,\n    query,\n    number_of_results=10,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Search asynchronously for contextual information within a specific index.</p> <p>This method performs a semantic search against the specified context index, helping to find relevant information that can be used in automation processes. The search is powered by AI and understands natural language queries.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the context index to search in.</p> required <code>query</code> <code>str</code> <p>The search query in natural language.</p> required <code>number_of_results</code> <code>int</code> <p>Maximum number of results to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[ContextGroundingQueryResponse]</code> <p>List[ContextGroundingQueryResponse]: A list of search results, each containing relevant contextual information and metadata.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_batch_transform","title":"start_batch_transform","text":"<pre><code>start_batch_transform(\n    name,\n    prompt,\n    output_columns,\n    storage_bucket_folder_path_prefix=None,\n    target_file_name=None,\n    enable_web_search_grounding=False,\n    index_name=None,\n    index_id=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Starts a Batch Transform, task on the targeted index.</p> <p>Batch Transform tasks are processing and transforming csv files from the index. Only one file can be processed per batch transform job.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>index_name</code> <code>str</code> <p>The name of the context index to search in.</p> <code>None</code> <code>prompt</code> <code>str</code> <p>Describe the task: what to research, what to synthesize.</p> required <code>output_columns</code> <code>list[BatchTransformOutputColumn]</code> <p>The output columns to add into the csv.</p> required <code>storage_bucket_folder_path_prefix</code> <code>str</code> <p>The prefix pattern for filtering files in the storage bucket. Can be combined with target_file_name. Defaults to None.</p> <code>None</code> <code>target_file_name</code> <code>str</code> <p>Specific file name to target. If both target_file_name and storage_bucket_folder_path_prefix are provided, they will be combined (e.g., \"data/file.csv\"). If only target_file_name is provided, it will be used directly. Only one file can be processed per batch transform job.</p> <code>None</code> <code>enable_web_search_grounding</code> <code>bool | None</code> <p>Whether to enable web search. Defaults to False.</p> <code>False</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <code>folder_key</code> <code>str</code> <p>The folder key where the index resides. Defaults to None.</p> <code>None</code> <code>folder_path</code> <code>str</code> <p>The folder path where the index resides. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchTransformCreationResponse</code> <code>BatchTransformCreationResponse</code> <p>The batch transform task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_batch_transform_async","title":"start_batch_transform_async  <code>async</code>","text":"<pre><code>start_batch_transform_async(\n    name,\n    prompt,\n    output_columns,\n    storage_bucket_folder_path_prefix=None,\n    target_file_name=None,\n    enable_web_search_grounding=False,\n    index_name=None,\n    index_id=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Asynchronously starts a Batch Transform, task on the targeted index.</p> <p>Batch Transform tasks are processing and transforming csv files from the index. Only one file can be processed per batch transform job.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>index_name</code> <code>str</code> <p>The name of the context index to search in.</p> <code>None</code> <code>prompt</code> <code>str</code> <p>Describe the task: what to research, what to synthesize.</p> required <code>output_columns</code> <code>list[BatchTransformOutputColumn]</code> <p>The output columns to add into the csv.</p> required <code>storage_bucket_folder_path_prefix</code> <code>str</code> <p>The prefix pattern for filtering files in the storage bucket. Can be combined with target_file_name. Defaults to None.</p> <code>None</code> <code>target_file_name</code> <code>str</code> <p>Specific file name to target. If both target_file_name and storage_bucket_folder_path_prefix are provided, they will be combined (e.g., \"data/file.csv\"). If only target_file_name is provided, it will be used directly. Only one file can be processed per batch transform job.</p> <code>None</code> <code>enable_web_search_grounding</code> <code>bool | None</code> <p>Whether to enable web search. Defaults to False.</p> <code>False</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <code>folder_key</code> <code>str</code> <p>The folder key where the index resides. Defaults to None.</p> <code>None</code> <code>folder_path</code> <code>str</code> <p>The folder path where the index resides. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchTransformCreationResponse</code> <code>BatchTransformCreationResponse</code> <p>The batch transform task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_batch_transform_ephemeral","title":"start_batch_transform_ephemeral  <code>async</code>","text":"<pre><code>start_batch_transform_ephemeral(\n    name,\n    prompt,\n    output_columns,\n    storage_bucket_folder_path_prefix=None,\n    enable_web_search_grounding=False,\n    index_id=None,\n)\n</code></pre> <p>Asynchronously starts a Batch Transform, task on the targeted index.</p> <p>Batch Transform tasks are processing and transforming csv files from the index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>prompt</code> <code>str</code> <p>Describe the task: what to research, what to synthesize.</p> required <code>output_columns</code> <code>list[BatchTransformOutputColumn]</code> <p>The output columns to add into the csv.</p> required <code>storage_bucket_folder_path_prefix</code> <code>str</code> <p>The prefix pattern for filtering files in the storage bucket. Use \"\" to include all files. Defaults to \"\".</p> <code>None</code> <code>enable_web_search_grounding</code> <code>bool | None</code> <p>Whether to enable web search. Defaults to False.</p> <code>False</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchTransformCreationResponse</code> <code>BatchTransformCreationResponse</code> <p>The batch transform task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_batch_transform_ephemeral_async","title":"start_batch_transform_ephemeral_async  <code>async</code>","text":"<pre><code>start_batch_transform_ephemeral_async(\n    name,\n    prompt,\n    output_columns,\n    storage_bucket_folder_path_prefix=None,\n    enable_web_search_grounding=False,\n    index_id=None,\n)\n</code></pre> <p>Asynchronously starts a Batch Transform, task on the targeted index.</p> <p>Batch Transform tasks are processing and transforming csv files from the index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>prompt</code> <code>str</code> <p>Describe the task: what to research, what to synthesize.</p> required <code>output_columns</code> <code>list[BatchTransformOutputColumn]</code> <p>The output columns to add into the csv.</p> required <code>storage_bucket_folder_path_prefix</code> <code>str</code> <p>The prefix pattern for filtering files in the storage bucket. Use \"\" to include all files. Defaults to \"\".</p> <code>None</code> <code>enable_web_search_grounding</code> <code>bool | None</code> <p>Whether to enable web search. Defaults to False.</p> <code>False</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <p>Returns:</p> Name Type Description <code>BatchTransformCreationResponse</code> <code>BatchTransformCreationResponse</code> <p>The batch transform task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_deep_rag","title":"start_deep_rag","text":"<pre><code>start_deep_rag(\n    name,\n    prompt,\n    glob_pattern=\"**\",\n    citation_mode=CitationMode.SKIP,\n    index_name=None,\n    index_id=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Starts a Deep RAG task on the targeted index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>index_name</code> <code>str</code> <p>The name of the context index to search in.</p> <code>None</code> <code>prompt</code> <code>str</code> <p>Describe the task: what to research across documents, what to synthesize and how to cite sources.</p> required <code>glob_pattern</code> <code>str</code> <p>The glob pattern to search in the index. Defaults to \"**\".</p> <code>'**'</code> <code>citation_mode</code> <code>CitationMode</code> <p>The citation mode to use. Defaults to SKIP.</p> <code>SKIP</code> <code>folder_key</code> <code>str</code> <p>The folder key where the index resides. Defaults to None.</p> <code>None</code> <code>folder_path</code> <code>str</code> <p>The folder path where the index resides. Defaults to None.</p> <code>None</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeepRagCreationResponse</code> <code>DeepRagCreationResponse</code> <p>The Deep RAG task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_deep_rag_async","title":"start_deep_rag_async  <code>async</code>","text":"<pre><code>start_deep_rag_async(\n    name,\n    prompt,\n    glob_pattern=\"**\",\n    citation_mode=CitationMode.SKIP,\n    index_name=None,\n    index_id=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Asynchronously starts a Deep RAG task on the targeted index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>index_name</code> <code>str</code> <p>The name of the context index to search in.</p> <code>None</code> <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>prompt</code> <code>str</code> <p>Describe the task: what to research across documents, what to synthesize and how to cite sources.</p> required <code>glob_pattern</code> <code>str</code> <p>The glob pattern to search in the index. Defaults to \"**\".</p> <code>'**'</code> <code>citation_mode</code> <code>CitationMode</code> <p>The citation mode to use. Defaults to SKIP.</p> <code>SKIP</code> <code>folder_key</code> <code>str</code> <p>The folder key where the index resides. Defaults to None.</p> <code>None</code> <code>folder_path</code> <code>str</code> <p>The folder path where the index resides. Defaults to None.</p> <code>None</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeepRagCreationResponse</code> <code>DeepRagCreationResponse</code> <p>The Deep RAG task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_deep_rag_ephemeral","title":"start_deep_rag_ephemeral  <code>async</code>","text":"<pre><code>start_deep_rag_ephemeral(\n    name,\n    prompt,\n    glob_pattern=\"**\",\n    citation_mode=CitationMode.SKIP,\n    index_id=None,\n)\n</code></pre> <p>Asynchronously starts a Deep RAG task on the targeted index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>prompt</code> <code>str</code> <p>Describe the task: what to research across documents, what to synthesize and how to cite sources.</p> required <code>glob_pattern</code> <code>str</code> <p>The glob pattern to search in the index. Defaults to \"**\".</p> <code>'**'</code> <code>citation_mode</code> <code>CitationMode</code> <p>The citation mode to use. Defaults to SKIP.</p> <code>SKIP</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeepRagCreationResponse</code> <code>DeepRagCreationResponse</code> <p>The Deep RAG task creation response.</p>"},{"location":"core/context_grounding/#uipath.platform.context_grounding._context_grounding_service.ContextGroundingService.start_deep_rag_ephemeral_async","title":"start_deep_rag_ephemeral_async  <code>async</code>","text":"<pre><code>start_deep_rag_ephemeral_async(\n    name,\n    prompt,\n    glob_pattern=\"**\",\n    citation_mode=CitationMode.SKIP,\n    index_id=None,\n)\n</code></pre> <p>Asynchronously starts a Deep RAG task on the targeted index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>name</code> <code>str</code> <p>The name of the Deep RAG task.</p> required <code>prompt</code> <code>str</code> <p>Describe the task: what to research across documents, what to synthesize and how to cite sources.</p> required <code>glob_pattern</code> <code>str</code> <p>The glob pattern to search in the index. Defaults to \"**\".</p> <code>'**'</code> <code>citation_mode</code> <code>CitationMode</code> <p>The citation mode to use. Defaults to SKIP.</p> <code>SKIP</code> <code>index_id</code> <code>str</code> <p>The id of the context index to search in, used in place of name if present</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DeepRagCreationResponse</code> <code>DeepRagCreationResponse</code> <p>The Deep RAG task creation response.</p>"},{"location":"core/documents/","title":"Documents","text":""},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService","title":"DocumentsService","text":"<p>Service for managing UiPath DocumentUnderstanding Document Operations.</p> <p>This service provides methods to extract data from documents using UiPath's Document Understanding capabilities.</p> <p>Preview Feature</p> <p>This function is currently experimental. Behavior and parameters are subject to change in future versions.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.classify","title":"classify","text":"<pre><code>classify(\n    project_type,\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n)\n</code></pre> <p>Classify a document using a DU Modern project.</p> <p>Parameters:</p> Name Type Description Default <code>project_type</code> <code>ProjectType</code> <p>Type of the project.</p> required <code>project_name</code> <code>str</code> <p>Name of the DU Modern project. Must be provided if <code>project_type</code> is not <code>ProjectType.PRETRAINED</code>.</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag of the published project version. Must be provided if <code>project_type</code> is not <code>ProjectType.PRETRAINED</code>.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version of the published project. It can be used instead of <code>tag</code>.</p> <code>None</code> <code>file</code> <code>FileContent</code> <p>The document file to be classified.</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the document file to be classified.</p> <code>None</code> Note <p>Either <code>file</code> or <code>file_path</code> must be provided, but not both.</p> <p>Returns:</p> Type Description <code>list[ClassificationResult]</code> <p>List[ClassificationResult]: A list of classification results.</p> <p>Examples:</p> <pre><code>Modern DU project:\nwith open(\"path/to/document.pdf\", \"rb\") as file:\n    classification_results = service.classify(\n        project_name=\"MyModernProjectName\",\n        tag=\"Production\",\n        file=file,\n    )\n\nPretrained project:\nwith open(\"path/to/document.pdf\", \"rb\") as file:\n    classification_results = service.classify(\n        project_type=ProjectType.PRETRAINED,\n        file=file,\n    )\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.classify_async","title":"classify_async  <code>async</code>","text":"<pre><code>classify_async(\n    project_type,\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n)\n</code></pre> <p>Asynchronously version of the <code>classify</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.create_validate_classification_action","title":"create_validate_classification_action","text":"<pre><code>create_validate_classification_action(\n    classification_results,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Create a validate classification action for a document based on the classification results. More details about validation actions can be found in the official documentation.</p> <p>Parameters:</p> Name Type Description Default <code>classification_results</code> <code>list[ClassificationResult]</code> <p>The classification results to be validated, typically obtained from the <code>classify</code> method.</p> required <code>action_title</code> <code>str</code> <p>Title of the action.</p> required <code>action_priority</code> <code>ActionPriority</code> <p>Priority of the action.</p> <code>None</code> <code>action_catalog</code> <code>str</code> <p>Catalog of the action.</p> <code>None</code> <code>action_folder</code> <code>str</code> <p>Folder of the action.</p> <code>None</code> <code>storage_bucket_name</code> <code>str</code> <p>Name of the storage bucket.</p> <code>None</code> <code>storage_bucket_directory_path</code> <code>str</code> <p>Directory path in the storage bucket.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ValidateClassificationAction</code> <code>ValidateClassificationAction</code> <p>The created validate classification action.</p> <p>Examples:</p> <pre><code>validation_action = service.create_validate_classification_action(\n    action_title=\"Test Validation Action\",\n    action_priority=ActionPriority.MEDIUM,\n    action_catalog=\"default_du_actions\",\n    action_folder=\"Shared\",\n    storage_bucket_name=\"du_storage_bucket\",\n    storage_bucket_directory_path=\"TestDirectory\",\n    classification_results=classification_results,\n)\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.create_validate_classification_action_async","title":"create_validate_classification_action_async  <code>async</code>","text":"<pre><code>create_validate_classification_action_async(\n    classification_results,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Asynchronous version of the <code>create_validation_action</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.create_validate_extraction_action","title":"create_validate_extraction_action","text":"<pre><code>create_validate_extraction_action(\n    extraction_response,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Create a validate extraction action for a document based on the extraction response. More details about validation actions can be found in the official documentation.</p> <p>Parameters:</p> Name Type Description Default <code>extraction_response</code> <code>ExtractionResponse</code> <p>The extraction result to be validated, typically obtained from the <code>extract</code> method.</p> required <code>action_title</code> <code>str</code> <p>Title of the action.</p> required <code>action_priority</code> <code>ActionPriority</code> <p>Priority of the action.</p> <code>None</code> <code>action_catalog</code> <code>str</code> <p>Catalog of the action.</p> <code>None</code> <code>action_folder</code> <code>str</code> <p>Folder of the action.</p> <code>None</code> <code>storage_bucket_name</code> <code>str</code> <p>Name of the storage bucket.</p> <code>None</code> <code>storage_bucket_directory_path</code> <code>str</code> <p>Directory path in the storage bucket.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ValidateClassificationAction</code> <code>ValidateExtractionAction</code> <p>The created validation action.</p> <p>Examples:</p> <pre><code>validation_action = service.create_validate_extraction_action(\n    action_title=\"Test Validation Action\",\n    action_priority=ActionPriority.MEDIUM,\n    action_catalog=\"default_du_actions\",\n    action_folder=\"Shared\",\n    storage_bucket_name=\"du_storage_bucket\",\n    storage_bucket_directory_path=\"TestDirectory\",\n    extraction_response=extraction_response,\n)\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.create_validate_extraction_action_async","title":"create_validate_extraction_action_async  <code>async</code>","text":"<pre><code>create_validate_extraction_action_async(\n    extraction_response,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Asynchronous version of the <code>create_validation_action</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.extract","title":"extract","text":"<pre><code>extract(\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n    classification_result=None,\n    project_type=None,\n    document_type_name=None,\n)\n</code></pre> <p>Extract predicted data from a document using an DU Modern/IXP project.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>Name of the IXP/DU Modern project. Must be provided if <code>classification_result</code> is not provided.</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag of the published project version. Must be provided if <code>classification_result</code> is not provided and <code>project_type</code> is not <code>ProjectType.PRETRAINED</code>.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version of the published project. It can be used instead of <code>tag</code>.</p> <code>None</code> <code>file</code> <code>FileContent</code> <p>The document file to be processed. Must be provided if <code>classification_result</code> is not provided.</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the document file to be processed. Must be provided if <code>classification_result</code> is not provided.</p> <code>None</code> <code>project_type</code> <code>ProjectType</code> <p>Type of the project. Must be provided if <code>project_name</code> is provided.</p> <code>None</code> <code>document_type_name</code> <code>str</code> <p>Document type name associated with the extractor to be used for extraction. Required if <code>project_type</code> is <code>ProjectType.MODERN</code> and <code>project_name</code> is provided.</p> <code>None</code> <code>classification_result</code> <code>ClassificationResult</code> <p>The classification result obtained from a previous classification step. If provided, <code>project_name</code>, <code>project_type</code>, <code>file</code>, <code>file_path</code>, and <code>document_type_name</code> must not be provided.</p> <code>None</code> Note <p>Either <code>file</code> or <code>file_path</code> must be provided, but not both.</p> <p>Returns:</p> Type Description <code>ExtractionResponse | ExtractionResponseIXP</code> <p>Union[ExtractionResponse, ExtractionResponseIXP]: The extraction response containing the extracted data.</p> <p>Examples:</p> <p>IXP projects: <pre><code>with open(\"path/to/document.pdf\", \"rb\") as file:\n    extraction_response = service.extract(\n        project_name=\"MyIXPProjectName\",\n        tag=\"live\",\n        file=file,\n    )\n</code></pre></p> <p>DU Modern projects (providing document type name): <pre><code>with open(\"path/to/document.pdf\", \"rb\") as file:\n    extraction_response = service.extract(\n        project_name=\"MyModernProjectName\",\n        tag=\"Production\",\n        file=file,\n        project_type=ProjectType.MODERN,\n        document_type_name=\"Receipts\",\n    )\n</code></pre></p> <p>DU Modern projects (using existing classification result): <pre><code>with open(\"path/to/document.pdf\", \"rb\") as file:\n    classification_results = uipath.documents.classify(\n        tag=\"Production\",\n        project_name=\"MyModernProjectName\",\n        file=file,\n    )\n\nextraction_result = uipath.documents.extract(\n    classification_result=max(classification_results, key=lambda result: result.confidence),\n)\n</code></pre></p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.extract_async","title":"extract_async  <code>async</code>","text":"<pre><code>extract_async(\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n    classification_result=None,\n    project_type=None,\n    document_type_name=None,\n)\n</code></pre> <p>Asynchronously version of the <code>extract</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.get_validate_classification_result","title":"get_validate_classification_result","text":"<pre><code>get_validate_classification_result(validation_action)\n</code></pre> <p>Get the result of a validate classification action.</p> Note <p>This method will block until the validation action is completed, meaning the user has completed the validation in UiPath Action Center.</p> <p>Parameters:</p> Name Type Description Default <code>validation_action</code> <code>ValidateClassificationAction</code> <p>The validation action to get the result for, typically obtained from the <code>create_validate_classification_action</code> method.</p> required <p>Returns:</p> Type Description <code>list[ClassificationResult]</code> <p>List[ClassificationResult]: The validated classification results.</p> <p>Examples:</p> <pre><code>validated_results = service.get_validate_classification_result(validate_classification_action)\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.get_validate_classification_result_async","title":"get_validate_classification_result_async  <code>async</code>","text":"<pre><code>get_validate_classification_result_async(validation_action)\n</code></pre> <p>Asynchronous version of the <code>get_validation_result</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.get_validate_extraction_result","title":"get_validate_extraction_result","text":"<pre><code>get_validate_extraction_result(validation_action)\n</code></pre> <p>Get the result of a validate extraction action.</p> Note <p>This method will block until the validation action is completed, meaning the user has completed the validation in UiPath Action Center.</p> <p>Parameters:</p> Name Type Description Default <code>validation_action</code> <code>ValidateClassificationAction</code> <p>The validation action to get the result for, typically obtained from the <code>create_validate_extraction_action</code> method.</p> required <p>Returns:</p> Type Description <code>ExtractionResponse | ExtractionResponseIXP</code> <p>Union[ExtractionResponse, ExtractionResponseIXP]: The validated extraction response.</p> <p>Examples:</p> <pre><code>validated_result = service.get_validate_extraction_result(validate_extraction_action)\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.get_validate_extraction_result_async","title":"get_validate_extraction_result_async  <code>async</code>","text":"<pre><code>get_validate_extraction_result_async(validation_action)\n</code></pre> <p>Asynchronous version of the <code>get_validation_result</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.retrieve_ixp_extraction_result","title":"retrieve_ixp_extraction_result","text":"<pre><code>retrieve_ixp_extraction_result(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Retrieve the result of an IXP extraction operation (single-shot, non-blocking).</p> <p>This method retrieves the result of an IXP extraction that was previously started with <code>start_ixp_extraction</code>. It does not poll - it makes a single request and returns the result if available, or raises an exception if not complete.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>The ID of the IXP project.</p> required <code>tag</code> <code>str</code> <p>The tag of the published project version.</p> required <code>operation_id</code> <code>str</code> <p>The operation ID returned from <code>start_ixp_extraction</code>.</p> required <p>Returns:</p> Name Type Description <code>ExtractionResponseIXP</code> <code>ExtractionResponseIXP</code> <p>The extraction response containing the extracted data.</p> <p>Raises:</p> Type Description <code>OperationNotCompleteException</code> <p>If the extraction is not yet complete.</p> <code>OperationFailedException</code> <p>If the extraction operation failed.</p> <p>Examples:</p> <pre><code># After receiving a callback/webhook that extraction is complete:\nresult = service.retrieve_ixp_extraction_result(\n    project_id=start_response.project_id,\n    tag=start_response.tag,\n    operation_id=start_response.operation_id,\n)\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.retrieve_ixp_extraction_result_async","title":"retrieve_ixp_extraction_result_async  <code>async</code>","text":"<pre><code>retrieve_ixp_extraction_result_async(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Asynchronous version of the <code>retrieve_ixp_extraction_result</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.retrieve_ixp_extraction_validation_result","title":"retrieve_ixp_extraction_validation_result","text":"<pre><code>retrieve_ixp_extraction_validation_result(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Retrieve the result of an IXP create validate extraction action operation (single-shot, non-blocking).</p> <p>This method retrieves the result of an IXP create validate extraction action that was previously started with <code>start_ixp_extraction_validation</code>. It does not poll - it makes a single request and returns the result if available, or raises an exception if not complete.</p> <p>Parameters:</p> Name Type Description Default <code>operation_id</code> <code>str</code> <p>The operation ID returned from <code>start_ixp_extraction_validation</code>.</p> required <code>project_id</code> <code>str</code> <p>The ID of the IXP project.</p> required <code>tag</code> <code>str</code> <p>The tag of the published project version.</p> required <p>Returns:</p> Name Type Description <code>ValidateExtractionAction</code> <code>ValidateExtractionAction</code> <p>The validation action</p> <p>Raises:</p> Type Description <code>OperationNotCompleteException</code> <p>If the validation action is not yet complete.</p> <code>OperationFailedException</code> <p>If the validation action has failed.</p> <p>Examples:</p> <pre><code># After receiving a callback/webhook that validation is complete:\nvalidation_result = service.retrieve_ixp_extraction_validation_result(\n    operation_id=start_operation_response.operation_id,\n    project_id=start_operation_response.project_id,\n    tag=start_operation_response.tag,\n)\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.retrieve_ixp_extraction_validation_result_async","title":"retrieve_ixp_extraction_validation_result_async  <code>async</code>","text":"<pre><code>retrieve_ixp_extraction_validation_result_async(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Asynchronous version of the <code>retrieve_ixp_extraction_validation_result</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.start_ixp_extraction","title":"start_ixp_extraction","text":"<pre><code>start_ixp_extraction(\n    project_name, tag, file=None, file_path=None\n)\n</code></pre> <p>Start an IXP extraction process without waiting for results (non-blocking).</p> <p>This method uploads the file as an attachment and starts the extraction process, returning immediately without waiting for the extraction to complete. Use this for async workflows where you want to receive results via callback/webhook.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>Name of the IXP project.</p> required <code>tag</code> <code>str</code> <p>Tag of the published project version (e.g., \"staging\").</p> required <code>file</code> <code>FileContent</code> <p>The document file to be processed.</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the document file to be processed.</p> <code>None</code> Note <p>Either <code>file</code> or <code>file_path</code> must be provided, but not both.</p> <p>Returns:</p> Name Type Description <code>ExtractionStartResponse</code> <code>StartExtractionResponse</code> <p>Contains the operation_id, document_id, project_id, and tag</p> <p>Examples:</p> <pre><code>start_response = uipath.documents.start_ixp_extraction(\n    project_name=\"MyIXPProjectName\",\n    tag=\"staging\",\n    file_path=\"path/to/document.pdf\",\n)\n# start_response.operation_id can be used to poll for results later\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.start_ixp_extraction_async","title":"start_ixp_extraction_async  <code>async</code>","text":"<pre><code>start_ixp_extraction_async(\n    project_name, tag, file=None, file_path=None\n)\n</code></pre> <p>Asynchronous version of the <code>start_ixp_extraction</code> method.</p>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.start_ixp_extraction_validation","title":"start_ixp_extraction_validation","text":"<pre><code>start_ixp_extraction_validation(\n    extraction_response,\n    action_title,\n    action_catalog=None,\n    action_priority=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Start an IXP extraction validation action without waiting for results (non-blocking).</p> <p>Parameters:</p> Name Type Description Default <code>extraction_response</code> <code>ExtractionResponseIXP</code> <p>The extraction response from the IXP extraction process.</p> required <code>action_title</code> <code>str</code> <p>The title of the validation action.</p> required <code>action_catalog</code> <code>str</code> <p>The catalog of the validation action.</p> <code>None</code> <code>action_priority</code> <code>ActionPriority</code> <p>The priority of the validation action.</p> <code>None</code> <code>action_folder</code> <code>str</code> <p>The folder of the validation action.</p> <code>None</code> <code>storage_bucket_name</code> <code>str</code> <p>The name of the storage bucket where validation data will be stored.</p> <code>None</code> <code>storage_bucket_directory_path</code> <code>str</code> <p>The directory path within the storage bucket.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>StartExtractionValidationResponse</code> <code>StartExtractionValidationResponse</code> <p>Contains the operation_id, document_id, project_id, and tag.</p> <p>Examples:</p> <pre><code>start_operation_response = service.start_ixp_extraction_validation(\n    action_title=\"Validate IXP Extraction\",\n    action_priority=ActionPriority.HIGH,\n    action_catalog=\"DefaultCatalog\",\n    action_folder=\"Validations\",\n    storage_bucket_name=\"my-storage-bucket\",\n    storage_bucket_directory_path=\"validations/ixp\",\n    extraction_response=extraction_response,\n)\n# start_operation_response can be used to poll for validation results later\n</code></pre>"},{"location":"core/documents/#uipath.platform.documents._documents_service.DocumentsService.start_ixp_extraction_validation_async","title":"start_ixp_extraction_validation_async  <code>async</code>","text":"<pre><code>start_ixp_extraction_validation_async(\n    extraction_response,\n    action_title,\n    action_catalog=None,\n    action_priority=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Asynchronous version of the <code>start_ixp_extraction_validation</code> method.</p>"},{"location":"core/documents_models/","title":"Documents","text":"<p>UiPath Documents Models.</p> <p>This module contains models related to UiPath Document Understanding service.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ActionPriority","title":"ActionPriority","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Priority levels for validation actions. More details can be found in the official documentation.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ActionPriority.CRITICAL","title":"CRITICAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CRITICAL = 'Critical'\n</code></pre> <p>Critical priority</p>"},{"location":"core/documents_models/#uipath.platform.documents.ActionPriority.HIGH","title":"HIGH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HIGH = 'High'\n</code></pre> <p>High priority</p>"},{"location":"core/documents_models/#uipath.platform.documents.ActionPriority.LOW","title":"LOW  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LOW = 'Low'\n</code></pre> <p>Low priority</p>"},{"location":"core/documents_models/#uipath.platform.documents.ActionPriority.MEDIUM","title":"MEDIUM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEDIUM = 'Medium'\n</code></pre> <p>Medium priority</p>"},{"location":"core/documents_models/#uipath.platform.documents.ActionPriority.from_str","title":"from_str  <code>classmethod</code>","text":"<pre><code>from_str(value)\n</code></pre> <p>Creates an ActionPriority from a string.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ClassificationResponse","title":"ClassificationResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing the response from a document classification process.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ClassificationResult","title":"ClassificationResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing the result of a document classification.</p> <p>Attributes:</p> Name Type Description <code>document_id</code> <code>str</code> <p>The ID of the classified document.</p> <code>document_type_id</code> <code>str</code> <p>The ID of the predicted document type.</p> <code>confidence</code> <code>float</code> <p>The confidence score of the classification.</p> <code>ocr_confidence</code> <code>float</code> <p>The OCR confidence score of the document.</p> <code>reference</code> <code>Reference</code> <p>The reference information for the classified document.</p> <code>document_bounds</code> <code>DocumentBounds</code> <p>The bounds of the document in terms of pages and text.</p> <code>classifier_name</code> <code>str</code> <p>The name of the classifier used.</p> <code>project_id</code> <code>str</code> <p>The ID of the project associated with the classification.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentBounds","title":"DocumentBounds","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing the bounds of a document in terms of pages and text.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService","title":"DocumentsService","text":"<p>               Bases: <code>FolderContext</code>, <code>BaseService</code></p> <p>Service for managing UiPath DocumentUnderstanding Document Operations.</p> <p>This service provides methods to extract data from documents using UiPath's Document Understanding capabilities.</p> <p>Preview Feature</p> <p>This function is currently experimental. Behavior and parameters are subject to change in future versions.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.classify","title":"classify","text":"<pre><code>classify(\n    project_type,\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n)\n</code></pre> <p>Classify a document using a DU Modern project.</p> <p>Parameters:</p> Name Type Description Default <code>project_type</code> <code>ProjectType</code> <p>Type of the project.</p> required <code>project_name</code> <code>str</code> <p>Name of the DU Modern project. Must be provided if <code>project_type</code> is not <code>ProjectType.PRETRAINED</code>.</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag of the published project version. Must be provided if <code>project_type</code> is not <code>ProjectType.PRETRAINED</code>.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version of the published project. It can be used instead of <code>tag</code>.</p> <code>None</code> <code>file</code> <code>FileContent</code> <p>The document file to be classified.</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the document file to be classified.</p> <code>None</code> Note <p>Either <code>file</code> or <code>file_path</code> must be provided, but not both.</p> <p>Returns:</p> Type Description <code>list[ClassificationResult]</code> <p>List[ClassificationResult]: A list of classification results.</p> <p>Examples:</p> <pre><code>Modern DU project:\nwith open(\"path/to/document.pdf\", \"rb\") as file:\n    classification_results = service.classify(\n        project_name=\"MyModernProjectName\",\n        tag=\"Production\",\n        file=file,\n    )\n\nPretrained project:\nwith open(\"path/to/document.pdf\", \"rb\") as file:\n    classification_results = service.classify(\n        project_type=ProjectType.PRETRAINED,\n        file=file,\n    )\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.classify_async","title":"classify_async  <code>async</code>","text":"<pre><code>classify_async(\n    project_type,\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n)\n</code></pre> <p>Asynchronously version of the <code>classify</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.create_validate_classification_action","title":"create_validate_classification_action","text":"<pre><code>create_validate_classification_action(\n    classification_results,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Create a validate classification action for a document based on the classification results. More details about validation actions can be found in the official documentation.</p> <p>Parameters:</p> Name Type Description Default <code>classification_results</code> <code>list[ClassificationResult]</code> <p>The classification results to be validated, typically obtained from the <code>classify</code> method.</p> required <code>action_title</code> <code>str</code> <p>Title of the action.</p> required <code>action_priority</code> <code>ActionPriority</code> <p>Priority of the action.</p> <code>None</code> <code>action_catalog</code> <code>str</code> <p>Catalog of the action.</p> <code>None</code> <code>action_folder</code> <code>str</code> <p>Folder of the action.</p> <code>None</code> <code>storage_bucket_name</code> <code>str</code> <p>Name of the storage bucket.</p> <code>None</code> <code>storage_bucket_directory_path</code> <code>str</code> <p>Directory path in the storage bucket.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ValidateClassificationAction</code> <code>ValidateClassificationAction</code> <p>The created validate classification action.</p> <p>Examples:</p> <pre><code>validation_action = service.create_validate_classification_action(\n    action_title=\"Test Validation Action\",\n    action_priority=ActionPriority.MEDIUM,\n    action_catalog=\"default_du_actions\",\n    action_folder=\"Shared\",\n    storage_bucket_name=\"du_storage_bucket\",\n    storage_bucket_directory_path=\"TestDirectory\",\n    classification_results=classification_results,\n)\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.create_validate_classification_action_async","title":"create_validate_classification_action_async  <code>async</code>","text":"<pre><code>create_validate_classification_action_async(\n    classification_results,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Asynchronous version of the <code>create_validation_action</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.create_validate_extraction_action","title":"create_validate_extraction_action","text":"<pre><code>create_validate_extraction_action(\n    extraction_response,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Create a validate extraction action for a document based on the extraction response. More details about validation actions can be found in the official documentation.</p> <p>Parameters:</p> Name Type Description Default <code>extraction_response</code> <code>ExtractionResponse</code> <p>The extraction result to be validated, typically obtained from the <code>extract</code> method.</p> required <code>action_title</code> <code>str</code> <p>Title of the action.</p> required <code>action_priority</code> <code>ActionPriority</code> <p>Priority of the action.</p> <code>None</code> <code>action_catalog</code> <code>str</code> <p>Catalog of the action.</p> <code>None</code> <code>action_folder</code> <code>str</code> <p>Folder of the action.</p> <code>None</code> <code>storage_bucket_name</code> <code>str</code> <p>Name of the storage bucket.</p> <code>None</code> <code>storage_bucket_directory_path</code> <code>str</code> <p>Directory path in the storage bucket.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ValidateClassificationAction</code> <code>ValidateExtractionAction</code> <p>The created validation action.</p> <p>Examples:</p> <pre><code>validation_action = service.create_validate_extraction_action(\n    action_title=\"Test Validation Action\",\n    action_priority=ActionPriority.MEDIUM,\n    action_catalog=\"default_du_actions\",\n    action_folder=\"Shared\",\n    storage_bucket_name=\"du_storage_bucket\",\n    storage_bucket_directory_path=\"TestDirectory\",\n    extraction_response=extraction_response,\n)\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.create_validate_extraction_action_async","title":"create_validate_extraction_action_async  <code>async</code>","text":"<pre><code>create_validate_extraction_action_async(\n    extraction_response,\n    action_title,\n    action_priority=None,\n    action_catalog=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Asynchronous version of the <code>create_validation_action</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.extract","title":"extract","text":"<pre><code>extract(\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n    classification_result=None,\n    project_type=None,\n    document_type_name=None,\n)\n</code></pre> <p>Extract predicted data from a document using an DU Modern/IXP project.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>Name of the IXP/DU Modern project. Must be provided if <code>classification_result</code> is not provided.</p> <code>None</code> <code>tag</code> <code>str</code> <p>Tag of the published project version. Must be provided if <code>classification_result</code> is not provided and <code>project_type</code> is not <code>ProjectType.PRETRAINED</code>.</p> <code>None</code> <code>version</code> <code>int</code> <p>Version of the published project. It can be used instead of <code>tag</code>.</p> <code>None</code> <code>file</code> <code>FileContent</code> <p>The document file to be processed. Must be provided if <code>classification_result</code> is not provided.</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the document file to be processed. Must be provided if <code>classification_result</code> is not provided.</p> <code>None</code> <code>project_type</code> <code>ProjectType</code> <p>Type of the project. Must be provided if <code>project_name</code> is provided.</p> <code>None</code> <code>document_type_name</code> <code>str</code> <p>Document type name associated with the extractor to be used for extraction. Required if <code>project_type</code> is <code>ProjectType.MODERN</code> and <code>project_name</code> is provided.</p> <code>None</code> <code>classification_result</code> <code>ClassificationResult</code> <p>The classification result obtained from a previous classification step. If provided, <code>project_name</code>, <code>project_type</code>, <code>file</code>, <code>file_path</code>, and <code>document_type_name</code> must not be provided.</p> <code>None</code> Note <p>Either <code>file</code> or <code>file_path</code> must be provided, but not both.</p> <p>Returns:</p> Type Description <code>ExtractionResponse | ExtractionResponseIXP</code> <p>Union[ExtractionResponse, ExtractionResponseIXP]: The extraction response containing the extracted data.</p> <p>Examples:</p> <p>IXP projects: <pre><code>with open(\"path/to/document.pdf\", \"rb\") as file:\n    extraction_response = service.extract(\n        project_name=\"MyIXPProjectName\",\n        tag=\"live\",\n        file=file,\n    )\n</code></pre></p> <p>DU Modern projects (providing document type name): <pre><code>with open(\"path/to/document.pdf\", \"rb\") as file:\n    extraction_response = service.extract(\n        project_name=\"MyModernProjectName\",\n        tag=\"Production\",\n        file=file,\n        project_type=ProjectType.MODERN,\n        document_type_name=\"Receipts\",\n    )\n</code></pre></p> <p>DU Modern projects (using existing classification result): <pre><code>with open(\"path/to/document.pdf\", \"rb\") as file:\n    classification_results = uipath.documents.classify(\n        tag=\"Production\",\n        project_name=\"MyModernProjectName\",\n        file=file,\n    )\n\nextraction_result = uipath.documents.extract(\n    classification_result=max(classification_results, key=lambda result: result.confidence),\n)\n</code></pre></p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.extract_async","title":"extract_async  <code>async</code>","text":"<pre><code>extract_async(\n    tag=None,\n    version=None,\n    project_name=None,\n    file=None,\n    file_path=None,\n    classification_result=None,\n    project_type=None,\n    document_type_name=None,\n)\n</code></pre> <p>Asynchronously version of the <code>extract</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.get_validate_classification_result","title":"get_validate_classification_result","text":"<pre><code>get_validate_classification_result(validation_action)\n</code></pre> <p>Get the result of a validate classification action.</p> Note <p>This method will block until the validation action is completed, meaning the user has completed the validation in UiPath Action Center.</p> <p>Parameters:</p> Name Type Description Default <code>validation_action</code> <code>ValidateClassificationAction</code> <p>The validation action to get the result for, typically obtained from the <code>create_validate_classification_action</code> method.</p> required <p>Returns:</p> Type Description <code>list[ClassificationResult]</code> <p>List[ClassificationResult]: The validated classification results.</p> <p>Examples:</p> <pre><code>validated_results = service.get_validate_classification_result(validate_classification_action)\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.get_validate_classification_result_async","title":"get_validate_classification_result_async  <code>async</code>","text":"<pre><code>get_validate_classification_result_async(validation_action)\n</code></pre> <p>Asynchronous version of the <code>get_validation_result</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.get_validate_extraction_result","title":"get_validate_extraction_result","text":"<pre><code>get_validate_extraction_result(validation_action)\n</code></pre> <p>Get the result of a validate extraction action.</p> Note <p>This method will block until the validation action is completed, meaning the user has completed the validation in UiPath Action Center.</p> <p>Parameters:</p> Name Type Description Default <code>validation_action</code> <code>ValidateClassificationAction</code> <p>The validation action to get the result for, typically obtained from the <code>create_validate_extraction_action</code> method.</p> required <p>Returns:</p> Type Description <code>ExtractionResponse | ExtractionResponseIXP</code> <p>Union[ExtractionResponse, ExtractionResponseIXP]: The validated extraction response.</p> <p>Examples:</p> <pre><code>validated_result = service.get_validate_extraction_result(validate_extraction_action)\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.get_validate_extraction_result_async","title":"get_validate_extraction_result_async  <code>async</code>","text":"<pre><code>get_validate_extraction_result_async(validation_action)\n</code></pre> <p>Asynchronous version of the <code>get_validation_result</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.retrieve_ixp_extraction_result","title":"retrieve_ixp_extraction_result","text":"<pre><code>retrieve_ixp_extraction_result(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Retrieve the result of an IXP extraction operation (single-shot, non-blocking).</p> <p>This method retrieves the result of an IXP extraction that was previously started with <code>start_ixp_extraction</code>. It does not poll - it makes a single request and returns the result if available, or raises an exception if not complete.</p> <p>Parameters:</p> Name Type Description Default <code>project_id</code> <code>str</code> <p>The ID of the IXP project.</p> required <code>tag</code> <code>str</code> <p>The tag of the published project version.</p> required <code>operation_id</code> <code>str</code> <p>The operation ID returned from <code>start_ixp_extraction</code>.</p> required <p>Returns:</p> Name Type Description <code>ExtractionResponseIXP</code> <code>ExtractionResponseIXP</code> <p>The extraction response containing the extracted data.</p> <p>Raises:</p> Type Description <code>OperationNotCompleteException</code> <p>If the extraction is not yet complete.</p> <code>OperationFailedException</code> <p>If the extraction operation failed.</p> <p>Examples:</p> <pre><code># After receiving a callback/webhook that extraction is complete:\nresult = service.retrieve_ixp_extraction_result(\n    project_id=start_response.project_id,\n    tag=start_response.tag,\n    operation_id=start_response.operation_id,\n)\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.retrieve_ixp_extraction_result_async","title":"retrieve_ixp_extraction_result_async  <code>async</code>","text":"<pre><code>retrieve_ixp_extraction_result_async(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Asynchronous version of the <code>retrieve_ixp_extraction_result</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.retrieve_ixp_extraction_validation_result","title":"retrieve_ixp_extraction_validation_result","text":"<pre><code>retrieve_ixp_extraction_validation_result(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Retrieve the result of an IXP create validate extraction action operation (single-shot, non-blocking).</p> <p>This method retrieves the result of an IXP create validate extraction action that was previously started with <code>start_ixp_extraction_validation</code>. It does not poll - it makes a single request and returns the result if available, or raises an exception if not complete.</p> <p>Parameters:</p> Name Type Description Default <code>operation_id</code> <code>str</code> <p>The operation ID returned from <code>start_ixp_extraction_validation</code>.</p> required <code>project_id</code> <code>str</code> <p>The ID of the IXP project.</p> required <code>tag</code> <code>str</code> <p>The tag of the published project version.</p> required <p>Returns:</p> Name Type Description <code>ValidateExtractionAction</code> <code>ValidateExtractionAction</code> <p>The validation action</p> <p>Raises:</p> Type Description <code>OperationNotCompleteException</code> <p>If the validation action is not yet complete.</p> <code>OperationFailedException</code> <p>If the validation action has failed.</p> <p>Examples:</p> <pre><code># After receiving a callback/webhook that validation is complete:\nvalidation_result = service.retrieve_ixp_extraction_validation_result(\n    operation_id=start_operation_response.operation_id,\n    project_id=start_operation_response.project_id,\n    tag=start_operation_response.tag,\n)\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.retrieve_ixp_extraction_validation_result_async","title":"retrieve_ixp_extraction_validation_result_async  <code>async</code>","text":"<pre><code>retrieve_ixp_extraction_validation_result_async(\n    project_id, tag, operation_id\n)\n</code></pre> <p>Asynchronous version of the <code>retrieve_ixp_extraction_validation_result</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.start_ixp_extraction","title":"start_ixp_extraction","text":"<pre><code>start_ixp_extraction(\n    project_name, tag, file=None, file_path=None\n)\n</code></pre> <p>Start an IXP extraction process without waiting for results (non-blocking).</p> <p>This method uploads the file as an attachment and starts the extraction process, returning immediately without waiting for the extraction to complete. Use this for async workflows where you want to receive results via callback/webhook.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>Name of the IXP project.</p> required <code>tag</code> <code>str</code> <p>Tag of the published project version (e.g., \"staging\").</p> required <code>file</code> <code>FileContent</code> <p>The document file to be processed.</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the document file to be processed.</p> <code>None</code> Note <p>Either <code>file</code> or <code>file_path</code> must be provided, but not both.</p> <p>Returns:</p> Name Type Description <code>ExtractionStartResponse</code> <code>StartExtractionResponse</code> <p>Contains the operation_id, document_id, project_id, and tag</p> <p>Examples:</p> <pre><code>start_response = uipath.documents.start_ixp_extraction(\n    project_name=\"MyIXPProjectName\",\n    tag=\"staging\",\n    file_path=\"path/to/document.pdf\",\n)\n# start_response.operation_id can be used to poll for results later\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.start_ixp_extraction_async","title":"start_ixp_extraction_async  <code>async</code>","text":"<pre><code>start_ixp_extraction_async(\n    project_name, tag, file=None, file_path=None\n)\n</code></pre> <p>Asynchronous version of the <code>start_ixp_extraction</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.start_ixp_extraction_validation","title":"start_ixp_extraction_validation","text":"<pre><code>start_ixp_extraction_validation(\n    extraction_response,\n    action_title,\n    action_catalog=None,\n    action_priority=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Start an IXP extraction validation action without waiting for results (non-blocking).</p> <p>Parameters:</p> Name Type Description Default <code>extraction_response</code> <code>ExtractionResponseIXP</code> <p>The extraction response from the IXP extraction process.</p> required <code>action_title</code> <code>str</code> <p>The title of the validation action.</p> required <code>action_catalog</code> <code>str</code> <p>The catalog of the validation action.</p> <code>None</code> <code>action_priority</code> <code>ActionPriority</code> <p>The priority of the validation action.</p> <code>None</code> <code>action_folder</code> <code>str</code> <p>The folder of the validation action.</p> <code>None</code> <code>storage_bucket_name</code> <code>str</code> <p>The name of the storage bucket where validation data will be stored.</p> <code>None</code> <code>storage_bucket_directory_path</code> <code>str</code> <p>The directory path within the storage bucket.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>StartExtractionValidationResponse</code> <code>StartExtractionValidationResponse</code> <p>Contains the operation_id, document_id, project_id, and tag.</p> <p>Examples:</p> <pre><code>start_operation_response = service.start_ixp_extraction_validation(\n    action_title=\"Validate IXP Extraction\",\n    action_priority=ActionPriority.HIGH,\n    action_catalog=\"DefaultCatalog\",\n    action_folder=\"Validations\",\n    storage_bucket_name=\"my-storage-bucket\",\n    storage_bucket_directory_path=\"validations/ixp\",\n    extraction_response=extraction_response,\n)\n# start_operation_response can be used to poll for validation results later\n</code></pre>"},{"location":"core/documents_models/#uipath.platform.documents.DocumentsService.start_ixp_extraction_validation_async","title":"start_ixp_extraction_validation_async  <code>async</code>","text":"<pre><code>start_ixp_extraction_validation_async(\n    extraction_response,\n    action_title,\n    action_catalog=None,\n    action_priority=None,\n    action_folder=None,\n    storage_bucket_name=None,\n    storage_bucket_directory_path=None,\n)\n</code></pre> <p>Asynchronous version of the <code>start_ixp_extraction_validation</code> method.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ExtractionResponse","title":"ExtractionResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing the response from a document extraction process.</p> <p>Attributes:</p> Name Type Description <code>extraction_result</code> <code>ExtractionResult</code> <p>The result of the extraction process.</p> <code>project_id</code> <code>str</code> <p>The ID of the project associated with the extraction.</p> <code>tag</code> <code>str</code> <p>The tag associated with the published model version.</p> <code>document_type_id</code> <code>str</code> <p>The ID of the document type associated with the extraction.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ExtractionResponseIXP","title":"ExtractionResponseIXP","text":"<p>               Bases: <code>ExtractionResponse</code></p> <p>A model representing the response from a document extraction process for IXP projects.</p> <p>Attributes:</p> Name Type Description <code>data_projection</code> <code>list[FieldGroupValueProjection]</code> <p>A simplified projection of the extracted data.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ExtractionResult","title":"ExtractionResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing the result of a document extraction process.</p>"},{"location":"core/documents_models/#uipath.platform.documents.FieldGroupValueProjection","title":"FieldGroupValueProjection","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing a projection of a field group value in a document extraction result.</p>"},{"location":"core/documents_models/#uipath.platform.documents.FieldType","title":"FieldType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Field types supported by Document Understanding service.</p>"},{"location":"core/documents_models/#uipath.platform.documents.FieldValueProjection","title":"FieldValueProjection","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing a projection of a field value in a document extraction result.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ProjectType","title":"ProjectType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Project types available and supported by Documents Service.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ProjectType.IXP","title":"IXP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>IXP = 'IXP'\n</code></pre> <p>Represents an IXP project type.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ProjectType.MODERN","title":"MODERN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MODERN = 'Modern'\n</code></pre> <p>Represents a DU Modern project type.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ProjectType.PRETRAINED","title":"PRETRAINED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PRETRAINED = 'Pretrained'\n</code></pre> <p>Represents a Pretrained project type.</p>"},{"location":"core/documents_models/#uipath.platform.documents.Reference","title":"Reference","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing a reference within a document.</p>"},{"location":"core/documents_models/#uipath.platform.documents.StartExtractionResponse","title":"StartExtractionResponse","text":"<p>               Bases: <code>StartOperationResponse</code></p> <p>A model representing the response from starting an extraction operation.</p>"},{"location":"core/documents_models/#uipath.platform.documents.StartExtractionValidationResponse","title":"StartExtractionValidationResponse","text":"<p>               Bases: <code>StartOperationResponse</code></p> <p>A model representing the response from starting an extraction validation operation.</p>"},{"location":"core/documents_models/#uipath.platform.documents.StartOperationResponse","title":"StartOperationResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing the response from starting an operation.</p> <p>Attributes:</p> Name Type Description <code>operation_id</code> <code>str</code> <p>The ID of the extraction operation, used to poll for results.</p> <code>document_id</code> <code>str</code> <p>The ID of the digitized document.</p> <code>project_id</code> <code>str</code> <p>The ID of the project.</p> <code>tag</code> <code>str</code> <p>The tag of the published project version.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ValidateClassificationAction","title":"ValidateClassificationAction","text":"<p>               Bases: <code>ValidationAction</code></p> <p>A model representing a validation action for document classification.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ValidateExtractionAction","title":"ValidateExtractionAction","text":"<p>               Bases: <code>ValidationAction</code></p> <p>A model representing a validation action for document extraction.</p>"},{"location":"core/documents_models/#uipath.platform.documents.ValidationAction","title":"ValidationAction","text":"<p>               Bases: <code>BaseModel</code></p> <p>A model representing a validation action for a document.</p> <p>Attributes:</p> Name Type Description <code>action_data</code> <code>dict</code> <p>The data associated with the validation action.</p> <code>action_status</code> <code>str</code> <p>The status of the validation action. Possible values can be found in the official documentation.</p> <code>project_id</code> <code>str</code> <p>The ID of the project associated with the validation action.</p> <code>tag</code> <code>str</code> <p>The tag associated with the published model version.</p> <code>operation_id</code> <code>str</code> <p>The operation ID associated with the validation action.</p>"},{"location":"core/entities/","title":"Entities","text":""},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService","title":"EntitiesService","text":"<p>Service for managing UiPath Data Service entities.</p> <p>Entities are database tables in UiPath Data Service that can store structured data for automation processes.</p> See Also <p>https://docs.uipath.com/data-service/automation-cloud/latest/user-guide/introduction</p>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.delete_records","title":"delete_records","text":"<pre><code>delete_records(entity_key, record_ids)\n</code></pre> <p>Delete multiple records from an entity in a single batch operation.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>record_ids</code> <code>list[str]</code> <p>List of record IDs (GUIDs) to delete.</p> required <p>Returns:</p> Name Type Description <code>EntityRecordsBatchResponse</code> <code>EntityRecordsBatchResponse</code> <p>Response containing successful and failed record operations. - success_records: List of successfully deleted EntityRecord objects - failure_records: List of EntityRecord objects that failed to delete</p> <p>Examples:</p> <p>Delete specific records by ID::</p> <pre><code># Delete records by their IDs\nrecord_ids = [\n    \"12345678-1234-1234-1234-123456789012\",\n    \"87654321-4321-4321-4321-210987654321\",\n]\n\nresponse = entities_service.delete_records(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    record_ids\n)\n\nprint(f\"Deleted: {len(response.success_records)}\")\nprint(f\"Failed: {len(response.failure_records)}\")\n</code></pre> <p>Delete records matching a condition::</p> <pre><code># Get all records\nrecords = entities_service.list_records(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n\n# Filter records to delete (e.g., inactive customers)\nids_to_delete = [\n    record.id for record in records\n    if not getattr(record, 'is_active', True)\n]\n\nif ids_to_delete:\n    response = entities_service.delete_records(\n        \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n        ids_to_delete\n    )\n    print(f\"Deleted {len(response.success_records)} inactive records\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.delete_records_async","title":"delete_records_async  <code>async</code>","text":"<pre><code>delete_records_async(entity_key, record_ids)\n</code></pre> <p>Asynchronously delete multiple records from an entity in a single batch operation.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>record_ids</code> <code>list[str]</code> <p>List of record IDs (GUIDs) to delete.</p> required <p>Returns:</p> Name Type Description <code>EntityRecordsBatchResponse</code> <code>EntityRecordsBatchResponse</code> <p>Response containing successful and failed record operations. - success_records: List of successfully deleted EntityRecord objects - failure_records: List of EntityRecord objects that failed to delete</p> <p>Examples:</p> <p>Delete specific records by ID::</p> <pre><code># Delete records by their IDs\nrecord_ids = [\n    \"12345678-1234-1234-1234-123456789012\",\n    \"87654321-4321-4321-4321-210987654321\",\n]\n\nresponse = await entities_service.delete_records_async(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    record_ids\n)\n\nprint(f\"Deleted: {len(response.success_records)}\")\nprint(f\"Failed: {len(response.failure_records)}\")\n</code></pre> <p>Delete records matching a condition::</p> <pre><code># Get all records\nrecords = await entities_service.list_records_async(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n\n# Filter records to delete (e.g., inactive customers)\nids_to_delete = [\n    record.id for record in records\n    if not getattr(record, 'is_active', True)\n]\n\nif ids_to_delete:\n    response = await entities_service.delete_records_async(\n        \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n        ids_to_delete\n    )\n    print(f\"Deleted {len(response.success_records)} inactive records\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.insert_records","title":"insert_records","text":"<pre><code>insert_records(entity_key, records, schema=None)\n</code></pre> <p>Insert multiple records into an entity in a single batch operation.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>records</code> <code>list[Any]</code> <p>List of records to insert. Each record should be an object with attributes matching the entity's field names.</p> required <code>schema</code> <code>Type[Any] | None</code> <p>Optional schema class for validation. When provided, validates that each record in the response matches the schema structure.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>EntityRecordsBatchResponse</code> <code>EntityRecordsBatchResponse</code> <p>Response containing successful and failed record operations. - success_records: List of successfully inserted EntityRecord objects - failure_records: List of EntityRecord objects that failed to insert</p> <p>Examples:</p> <p>Insert records without schema::</p> <pre><code>class Customer:\n    def __init__(self, name, email, age):\n        self.name = name\n        self.email = email\n        self.age = age\n\ncustomers = [\n    Customer(\"John Doe\", \"john@example.com\", 30),\n    Customer(\"Jane Smith\", \"jane@example.com\", 25),\n]\n\nresponse = entities_service.insert_records(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    customers\n)\n\nprint(f\"Inserted: {len(response.success_records)}\")\nprint(f\"Failed: {len(response.failure_records)}\")\n</code></pre> <p>Insert with schema validation::</p> <pre><code>class CustomerSchema:\n    name: str\n    email: str\n    age: int\n\nclass Customer:\n    def __init__(self, name, email, age):\n        self.name = name\n        self.email = email\n        self.age = age\n\ncustomers = [Customer(\"Alice Brown\", \"alice@example.com\", 28)]\n\nresponse = entities_service.insert_records(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    customers,\n    schema=CustomerSchema\n)\n\n# Access inserted records with validated structure\nfor record in response.success_records:\n    print(f\"Inserted: {record.name} (ID: {record.id})\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.insert_records_async","title":"insert_records_async  <code>async</code>","text":"<pre><code>insert_records_async(entity_key, records, schema=None)\n</code></pre> <p>Asynchronously insert multiple records into an entity in a single batch operation.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>records</code> <code>list[Any]</code> <p>List of records to insert. Each record should be an object with attributes matching the entity's field names.</p> required <code>schema</code> <code>Type[Any] | None</code> <p>Optional schema class for validation. When provided, validates that each record in the response matches the schema structure.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>EntityRecordsBatchResponse</code> <code>EntityRecordsBatchResponse</code> <p>Response containing successful and failed record operations. - success_records: List of successfully inserted EntityRecord objects - failure_records: List of EntityRecord objects that failed to insert</p> <p>Examples:</p> <p>Insert records without schema::</p> <pre><code>class Customer:\n    def __init__(self, name, email, age):\n        self.name = name\n        self.email = email\n        self.age = age\n\ncustomers = [\n    Customer(\"John Doe\", \"john@example.com\", 30),\n    Customer(\"Jane Smith\", \"jane@example.com\", 25),\n]\n\nresponse = await entities_service.insert_records_async(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    customers\n)\n\nprint(f\"Inserted: {len(response.success_records)}\")\nprint(f\"Failed: {len(response.failure_records)}\")\n</code></pre> <p>Insert with schema validation::</p> <pre><code>class CustomerSchema:\n    name: str\n    email: str\n    age: int\n\nclass Customer:\n    def __init__(self, name, email, age):\n        self.name = name\n        self.email = email\n        self.age = age\n\ncustomers = [Customer(\"Alice Brown\", \"alice@example.com\", 28)]\n\nresponse = await entities_service.insert_records_async(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    customers,\n    schema=CustomerSchema\n)\n\n# Access inserted records with validated structure\nfor record in response.success_records:\n    print(f\"Inserted: {record.name} (ID: {record.id})\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.list_entities","title":"list_entities","text":"<pre><code>list_entities()\n</code></pre> <p>List all entities in Data Service.</p> <p>Returns:</p> Type Description <code>list[Entity]</code> <p>List[Entity]: A list of all entities with their metadata and field definitions. Each entity includes name, display name, fields, record count, and storage information.</p> <p>Examples:</p> <p>List all entities::</p> <pre><code># Get all entities in the Data Service\nentities = entities_service.list_entities()\nfor entity in entities:\n    print(f\"{entity.display_name} ({entity.name})\")\n</code></pre> <p>Find entities with RBAC enabled::</p> <pre><code>entities = entities_service.list_entities()\n\n# Filter to entities with row-based access control\nrbac_entities = [\n    e for e in entities\n    if e.is_rbac_enabled\n]\n</code></pre> <p>Summary report::</p> <pre><code>entities = entities_service.list_entities()\n\ntotal_records = sum(e.record_count or 0 for e in entities)\ntotal_storage = sum(e.storage_size_in_mb or 0 for e in entities)\n\nprint(f\"Total entities: {len(entities)}\")\nprint(f\"Total records: {total_records}\")\nprint(f\"Total storage: {total_storage:.2f} MB\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.list_entities_async","title":"list_entities_async  <code>async</code>","text":"<pre><code>list_entities_async()\n</code></pre> <p>Asynchronously list all entities in the Data Service.</p> <p>Returns:</p> Type Description <code>list[Entity]</code> <p>List[Entity]: A list of all entities with their metadata and field definitions. Each entity includes name, display name, fields, record count, and storage information.</p> <p>Examples:</p> <p>List all entities::</p> <pre><code># Get all entities in the Data Service\nentities = await entities_service.list_entities_async()\nfor entity in entities:\n    print(f\"{entity.display_name} ({entity.name})\")\n</code></pre> <p>Find entities with RBAC enabled::</p> <pre><code>entities = await entities_service.list_entities_async()\n\n# Filter to entities with row-based access control\nrbac_entities = [\n    e for e in entities\n    if e.is_rbac_enabled\n]\n</code></pre> <p>Summary report::</p> <pre><code>entities = await entities_service.list_entities_async()\n\ntotal_records = sum(e.record_count or 0 for e in entities)\ntotal_storage = sum(e.storage_size_in_mb or 0 for e in entities)\n\nprint(f\"Total entities: {len(entities)}\")\nprint(f\"Total records: {total_records}\")\nprint(f\"Total storage: {total_storage:.2f} MB\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.list_records","title":"list_records","text":"<pre><code>list_records(\n    entity_key, schema=None, start=None, limit=None\n)\n</code></pre> <p>List records from an entity with optional pagination and schema validation.</p> <p>The schema parameter enables type-safe access to entity records by validating the data against a user-defined class with type annotations. When provided, each record is validated against the schema's field definitions before being returned.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>schema</code> <code>Type[Any] | None</code> <p>Optional schema class for validation. This should be a Python class with type-annotated fields that match the entity's structure.</p> <p>Field Validation Rules: - Required fields: Use standard type annotations (e.g., <code>name: str</code>) - Optional fields: Use <code>Optional</code> or union with None (e.g., <code>age: Optional[int]</code> or <code>age: int | None</code>) - Field names must match the entity's field names (case-sensitive) - The 'Id' field is automatically validated and does not need to be included</p> <p>Example schema class::</p> <pre><code>class CustomerRecord:\n    name: str  # Required field\n    email: str  # Required field\n    age: Optional[int]  # Optional field\n    phone: str | None  # Optional field (Python 3.10+ syntax)\n</code></pre> <p>Benefits of using schema: - Type safety: Ensures records match expected structure - Early validation: Catches data issues before processing - Documentation: Schema serves as clear contract for record structure - IDE support: Enables better autocomplete and type checking</p> <p>When schema validation fails, a <code>ValueError</code> is raised with details about the validation error (e.g., missing required fields, type mismatches).</p> <code>None</code> <code>start</code> <code>int | None</code> <p>Starting index for pagination (0-based).</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Maximum number of records to return.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[EntityRecord]</code> <p>List[EntityRecord]: A list of entity records. Each record contains an 'id' field and all other fields from the entity. Fields can be accessed as attributes or dictionary keys on the EntityRecord object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If schema validation fails for any record, including cases where required fields are missing or field types don't match the schema.</p> <p>Examples:</p> <p>Basic usage without schema::</p> <pre><code># Retrieve all records from an entity\nrecords = entities_service.list_records(\"Customers\")\nfor record in records:\n    print(record.id)\n</code></pre> <p>With pagination::</p> <pre><code># Get first 50 records\nrecords = entities_service.list_records(\"Customers\", start=0, limit=50)\n</code></pre> <p>With schema validation::</p> <pre><code>class CustomerRecord:\n    name: str\n    email: str\n    age: Optional[int]\n    is_active: bool\n\n# Records are validated against CustomerRecord schema\nrecords = entities_service.list_records(\n    \"Customers\",\n    schema=CustomerRecord\n)\n\n# Safe to access fields knowing they match the schema\nfor record in records:\n    print(f\"{record.name}: {record.email}\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.list_records_async","title":"list_records_async  <code>async</code>","text":"<pre><code>list_records_async(\n    entity_key, schema=None, start=None, limit=None\n)\n</code></pre> <p>Asynchronously list records from an entity with optional pagination and schema validation.</p> <p>The schema parameter enables type-safe access to entity records by validating the data against a user-defined class with type annotations. When provided, each record is validated against the schema's field definitions before being returned.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>schema</code> <code>Type[Any] | None</code> <p>Optional schema class for validation. This should be a Python class with type-annotated fields that match the entity's structure.</p> <p>Field Validation Rules: - Required fields: Use standard type annotations (e.g., <code>name: str</code>) - Optional fields: Use <code>Optional</code> or union with None (e.g., <code>age: Optional[int]</code> or <code>age: int | None</code>) - Field names must match the entity's field names (case-sensitive) - The 'Id' field is automatically validated and does not need to be included</p> <p>Example schema class::</p> <pre><code>class CustomerRecord:\n    name: str  # Required field\n    email: str  # Required field\n    age: Optional[int]  # Optional field\n    phone: str | None  # Optional field (Python 3.10+ syntax)\n</code></pre> <p>Benefits of using schema: - Type safety: Ensures records match expected structure - Early validation: Catches data issues before processing - Documentation: Schema serves as clear contract for record structure - IDE support: Enables better autocomplete and type checking</p> <p>When schema validation fails, a <code>ValueError</code> is raised with details about the validation error (e.g., missing required fields, type mismatches).</p> <code>None</code> <code>start</code> <code>int | None</code> <p>Starting index for pagination (0-based).</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Maximum number of records to return.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[EntityRecord]</code> <p>List[EntityRecord]: A list of entity records. Each record contains an 'id' field and all other fields from the entity. Fields can be accessed as attributes or dictionary keys on the EntityRecord object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If schema validation fails for any record, including cases where required fields are missing or field types don't match the schema.</p> <p>Examples:</p> <p>Basic usage without schema::</p> <pre><code># Retrieve all records from an entity\nrecords = await entities_service.list_records_async(\"Customers\")\nfor record in records:\n    print(record.id)\n</code></pre> <p>With pagination::</p> <pre><code># Get first 50 records\nrecords = await entities_service.list_records_async(\"Customers\", start=0, limit=50)\n</code></pre> <p>With schema validation::</p> <pre><code>class CustomerRecord:\n    name: str\n    email: str\n    age: Optional[int]\n    is_active: bool\n\n# Records are validated against CustomerRecord schema\nrecords = await entities_service.list_records_async(\n    \"Customers\",\n    schema=CustomerRecord\n)\n\n# Safe to access fields knowing they match the schema\nfor record in records:\n    print(f\"{record.name}: {record.email}\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.retrieve","title":"retrieve","text":"<pre><code>retrieve(entity_key)\n</code></pre> <p>Retrieve an entity by its key.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <p>Returns:</p> Name Type Description <code>Entity</code> <code>Entity</code> <p>The entity with all its metadata and field definitions, including: - name: Entity name - display_name: Human-readable display name - fields: List of field metadata (field names, types, constraints) - record_count: Number of records in the entity - storage_size_in_mb: Storage size used by the entity</p> <p>Examples:</p> <p>Basic usage::</p> <pre><code># Retrieve entity metadata\nentity = entities_service.retrieve(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\nprint(f\"Entity: {entity.display_name}\")\nprint(f\"Records: {entity.record_count}\")\n</code></pre> <p>Inspecting entity fields::</p> <pre><code>entity = entities_service.retrieve(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n\n# List all fields and their types\nfor field in entity.fields:\n    print(f\"{field.name} ({field.sql_type.name})\")\n    print(f\"  Required: {field.is_required}\")\n    print(f\"  Primary Key: {field.is_primary_key}\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(entity_key)\n</code></pre> <p>Asynchronously retrieve an entity by its key.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <p>Returns:</p> Name Type Description <code>Entity</code> <code>Entity</code> <p>The entity with all its metadata and field definitions, including: - name: Entity name - display_name: Human-readable display name - fields: List of field metadata (field names, types, constraints) - record_count: Number of records in the entity - storage_size_in_mb: Storage size used by the entity</p> <p>Examples:</p> <p>Basic usage::</p> <pre><code># Retrieve entity metadata\nentity = await entities_service.retrieve_async(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\nprint(f\"Entity: {entity.display_name}\")\nprint(f\"Records: {entity.record_count}\")\n</code></pre> <p>Inspecting entity fields::</p> <pre><code>entity = await entities_service.retrieve_async(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n\n# List all fields and their types\nfor field in entity.fields:\n    print(f\"{field.name} ({field.sql_type.name})\")\n    print(f\"  Required: {field.is_required}\")\n    print(f\"  Primary Key: {field.is_primary_key}\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.update_records","title":"update_records","text":"<pre><code>update_records(entity_key, records, schema=None)\n</code></pre> <p>Update multiple records in an entity in a single batch operation.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>records</code> <code>list[Any]</code> <p>List of records to update. Each record must have an 'Id' field and should be a Pydantic model with <code>model_dump()</code> method or similar object.</p> required <code>schema</code> <code>Type[Any] | None</code> <p>Optional schema class for validation. When provided, validates that each record in the request and response matches the schema structure.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>EntityRecordsBatchResponse</code> <code>EntityRecordsBatchResponse</code> <p>Response containing successful and failed record operations. - success_records: List of successfully updated EntityRecord objects - failure_records: List of EntityRecord objects that failed to update</p> <p>Examples:</p> <p>Update records::</p> <pre><code># First, retrieve records to update\nrecords = entities_service.list_records(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n\n# Modify the records\nfor record in records:\n    if record.name == \"John Doe\":\n        record.age = 31\n\n# Update the modified records\nresponse = entities_service.update_records(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    records\n)\n\nprint(f\"Updated: {len(response.success_records)}\")\nprint(f\"Failed: {len(response.failure_records)}\")\n</code></pre> <p>Update with schema validation::</p> <pre><code>class CustomerSchema:\n    name: str\n    email: str\n    age: int\n\n# Retrieve and update\nrecords = entities_service.list_records(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    schema=CustomerSchema\n)\n\n# Modify specific records\nfor record in records:\n    if record.age &lt; 30:\n        record.is_active = True\n\nresponse = entities_service.update_records(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    records,\n    schema=CustomerSchema\n)\n\nfor record in response.success_records:\n    print(f\"Updated: {record.name}\")\n</code></pre>"},{"location":"core/entities/#uipath.platform.entities._entities_service.EntitiesService.update_records_async","title":"update_records_async  <code>async</code>","text":"<pre><code>update_records_async(entity_key, records, schema=None)\n</code></pre> <p>Asynchronously update multiple records in an entity in a single batch operation.</p> <p>Parameters:</p> Name Type Description Default <code>entity_key</code> <code>str</code> <p>The unique key/identifier of the entity.</p> required <code>records</code> <code>list[Any]</code> <p>List of records to update. Each record must have an 'Id' field and should be a Pydantic model with <code>model_dump()</code> method or similar object.</p> required <code>schema</code> <code>Type[Any] | None</code> <p>Optional schema class for validation. When provided, validates that each record in the request and response matches the schema structure.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>EntityRecordsBatchResponse</code> <code>EntityRecordsBatchResponse</code> <p>Response containing successful and failed record operations. - success_records: List of successfully updated EntityRecord objects - failure_records: List of EntityRecord objects that failed to update</p> <p>Examples:</p> <p>Update records::</p> <pre><code># First, retrieve records to update\nrecords = await entities_service.list_records_async(\"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n\n# Modify the records\nfor record in records:\n    if record.name == \"John Doe\":\n        record.age = 31\n\n# Update the modified records\nresponse = await entities_service.update_records_async(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    records\n)\n\nprint(f\"Updated: {len(response.success_records)}\")\nprint(f\"Failed: {len(response.failure_records)}\")\n</code></pre> <p>Update with schema validation::</p> <pre><code>class CustomerSchema:\n    name: str\n    email: str\n    age: int\n\n# Retrieve and update\nrecords = await entities_service.list_records_async(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    schema=CustomerSchema\n)\n\n# Modify specific records\nfor record in records:\n    if record.age &lt; 30:\n        record.is_active = True\n\nresponse = await entities_service.update_records_async(\n    \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    records,\n    schema=CustomerSchema\n)\n\nfor record in response.success_records:\n    print(f\"Updated: {record.name}\")\n</code></pre>"},{"location":"core/environment_variables/","title":"Environment Variables","text":"<p>Environment variables are configuration values stored at the operating system level that can be accessed by applications and scripts. They provide a flexible way to configure application behavior without hardcoding values in your source code.</p> <p>Environment variables are loaded in the following order (highest to lowest priority):</p> <ol> <li><code>.env</code> file in the current directory</li> <li>System environment variables</li> <li>Default values in code</li> </ol> <p>Example: <pre><code># .env file\nUIPATH_FOLDER_PATH=/default/path\n\n# System environment\nexport UIPATH_FOLDER_PATH=/system/path\n</code></pre></p> <p>Warning</p> <p>When deploying your agent to production, ensure that all required environment variables (such as API keys and custom configurations) are properly configured in your process settings. This step is crucial for the successful operation of your published package.</p>"},{"location":"core/environment_variables/#design","title":"Design","text":"<p>Create a <code>.env</code> file in your project's root directory to manage environment variables locally. When using the <code>uipath auth</code> or <code>uipath new my-agent</code> commands, this file is automatically created.</p> <p>The <code>uipath auth</code> command automatically populates this file with essential variables:</p> <ul> <li><code>UIPATH_URL</code>: Your UiPath Orchestrator instance URL</li> <li><code>UIPATH_ACCESS_TOKEN</code>: Authentication token for API access</li> </ul>"},{"location":"core/environment_variables/#folder-configuration","title":"Folder Configuration","text":"<p>Most UiPath services operate within a specific folder context. Configure your folder context using either:</p> <ul> <li><code>UIPATH_FOLDER_PATH</code>: The full path to your target folder</li> <li><code>UIPATH_FOLDER_KEY</code>: The unique identifier for your target folder</li> </ul> <p>To obtain the folder path, right-click on the folder in UiPath Orchestrator and select \"Copy folder path\" from the context menu.</p> <p> </p>"},{"location":"core/environment_variables/#telemetry","title":"Telemetry","text":"<p>To help us improve the developer experience, the CLI collects basic usage data about command invocations. For more details about UiPath's privacy practices, please review the privacy statement.</p> <p>Telemetry is enabled by default. You can opt out by setting the <code>UIPATH_TELEMETRY_ENABLED</code> environment variable to <code>false</code> in your <code>.env</code> file:</p> <pre><code>UIPATH_TELEMETRY_ENABLED=false\n</code></pre>"},{"location":"core/environment_variables/#runtime","title":"Runtime","text":"<p>When executing processes or starting jobs, you can configure environment variables through the UiPath Orchestrator interface. For sensitive information like API keys and secrets, we strongly recommend using secret assets instead of environment variables. Secret assets provide enhanced security and better management capabilities.</p>"},{"location":"core/environment_variables/#secret-assets","title":"Secret Assets","text":"<p>To use a secret asset in your environment variables, reference it using the following format:</p> <pre><code>NAME=%ASSETS/your-secret-asset-name%\n</code></pre> <p> </p>"},{"location":"core/environment_variables/#sensitive-variables","title":"Sensitive Variables","text":"<p>If you must use environment variables for sensitive information (not recommended), variables containing <code>API_KEY</code> or <code>SECRET</code> in their names will have their values masked as <code>****</code> in the interface for security purposes.</p> <p> </p>"},{"location":"core/environment_variables/#log-level","title":"Log Level","text":"<p>The <code>LOG_LEVEL</code> environment variable controls the verbosity of logging in the Orchestrator UI's Log tab during runtime execution. This setting determines which log messages are displayed in the interface.</p> Level Description TRACE Most detailed logging level, shows all possible information DEBUG Detailed information for debugging purposes INFORMATION General operational information WARNING Warning messages for potentially harmful situations ERROR Error events that might still allow the application to continue CRITICAL Critical events that may lead to application failure NONE No logging <p>The default value is <code>INFORMATION</code></p>"},{"location":"core/environment_variables/#builtin-variables","title":"Builtin Variables","text":"<p>The runtime environment automatically includes certain variables (such as <code>UIPATH_FOLDER_KEY</code>, <code>UIPATH_ROBOT_KEY</code>), eliminating the need for manual configuration.</p>"},{"location":"core/getting_started/","title":"Getting Started","text":""},{"location":"core/getting_started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li><code>pip</code> or <code>uv</code> package manager</li> <li>A UiPath Cloud Platform account with appropriate permissions</li> </ul>"},{"location":"core/getting_started/#getting-started-with-the-cli","title":"Getting Started with the CLI","text":"Linux, macOS, Windows BashWindows PowerShell mkdir uipath_coded_processcd uipath_coded_process New-Item -ItemType Directory -Path uipath_coded_processSet-Location uipath_coded_process uvpip # Initialize a new uv project in the current directoryuv init . --python 3.11# Create a new virtual environment# By default, uv creates a virtual environment in a directory called .venvuv venvUsing CPython 3.11 interpreter at: [PATH]Creating virtual environment at: .venvActivate with: source .venv/bin/activate# Activate the virtual environment# For Windows PowerShell: .venv\\Scripts\\Activate.ps1# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Install the uipath packageuv add uipath# Verify the uipath installationuipath --versionuipath version 2.0.29 # Create a new virtual environmentpython -m venv .venv# Activate the virtual environment# For Windows PowerShell: .venv\\Scripts\\Activate.ps1# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Upgrade pip to the latest versionpython -m pip install --upgrade pip# Install the uipath packagepip install uipath# Verify the uipath installationuipath --versionuipath version 2.0.29"},{"location":"core/getting_started/#telemetry","title":"Telemetry","text":"<p>To help us improve the developer experience, the CLI collects basic usage data about commands invocation. For more details about UiPath's privacy practices, please review the privacy statement.</p>"},{"location":"core/getting_started/#disabling-telemetry-data","title":"Disabling telemetry data","text":"<p>Telemetry is enabled by default, yet it is possible to opt-out by setting to <code>false</code> the <code>UIPATH_TELEMETRY_ENABLED</code> environment variable.</p>"},{"location":"core/getting_started/#authentication","title":"Authentication","text":"<p>To debug your script locally and publish your project, you need to authenticate with UiPath:</p> uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful. <p>This command opens a new browser window for authentication. If you encounter any issues, copy the URL from the terminal and paste it into your browser. After authentication, select your tenant by entering its corresponding number in the terminal.</p> <p>Upon successful authentication, your project will contain a <code>.env</code> file with your access token, UiPath URL, and other configuration details.</p>"},{"location":"core/getting_started/#writing-your-code","title":"Writing Your Code","text":"<p>Open <code>main.py</code> in your code editor. You can start with this example code: <pre><code>from dataclasses import dataclass\n\n\n@dataclass\nclass EchoIn:\n    message: str\n    repeat: int | None = 1\n    prefix: str | None = None\n\n\n@dataclass\nclass EchoOut:\n    message: str\n\n\ndef main(input: EchoIn) -&gt; EchoOut:\n    result = []\n    for _ in range(input.repeat or 1):\n        line = input.message\n        if input.prefix:\n            line = f\"{input.prefix}: {line}\"\n        result.append(line)\n\n    return EchoOut(message=\"\\n\".join(result))\n</code></pre></p>"},{"location":"core/getting_started/#initializing-the-uipath-project","title":"Initializing the UiPath Project","text":"<p>Before running <code>uipath init</code>, you need to create a <code>uipath.json</code> file that specifies which functions to expose. Create a <code>uipath.json</code> file in your project directory with the following content: <pre><code>{\n  \"functions\": {\n    \"main\": \"main.py:main\"\n  }\n}\n</code></pre></p> <p>The <code>functions</code> object maps function names to their locations in the format <code>&lt;file&gt;:&lt;function_name&gt;</code>.</p> <p>Now, run the initialization command:</p> uipath init\u280b Initializing UiPath project ...\u2713  Created 'entry-points.json' file.\u2713  Created 'bindings.json' file. <p>Warning</p> <p>The <code>uipath init</code> command executes your <code>main.py</code> file to analyze its structure and collect information about inputs and outputs.</p> <p>This command generates two files:</p> <ul> <li><code>entry-points.json</code>: Contains the input/output schema for your functions</li> <li><code>bindings.json</code>: Allows you to configure overridable resource bindings.</li> </ul> # Debug your projectuipath run main '{\"message\": \"test\"}'[2025-04-11 10:13:58,857][INFO] {'message': 'test'} <p>Warning</p> <p>Depending on the shell you are using, it may be necessary to escape the input json:</p> Bash/ZSH/PowerShellWindows CMDWindows PowerShell <pre><code>uipath run main '{\"message\": \"test\"}'\n</code></pre> <pre><code>uipath run main \"{\"\"message\"\": \"\"test\"\"}\"\n</code></pre> <pre><code>uipath run main '{\\\"message\\\":\\\"test\\\"}'\n</code></pre>"},{"location":"core/getting_started/#packaging-and-publishing","title":"Packaging and Publishing","text":"<p>Before packaging your project, add your details to the <code>pyproject.toml</code> file. Add the following line below the <code>description</code> field: <pre><code>authors = [{ name = \"Your Name\", email = \"your.email@uipath.com\" }]\n</code></pre></p> <p>Then, package your project:</p> uipath pack\u280b Packaging project ...Name       : uipath_coded_processVersion    : 0.1.0Description: Add your description hereAuthors    : Your Name\u2713  Project successfully packaged. <p>Finally, publish your package:</p> uipath publish\u280b Fetching available package feeds...\ud83d\udc47 Select package feed:  0: Orchestrator Tenant Processes Feed  1: Orchestrator Personal Workspace FeedSelect feed number: 0Selected feed: Orchestrator Tenant Processes Feed\u2838 Publishing most recent package: uipath_coded_process.0.1.0.nupkg ...\u2713  Package published successfully! <p>After selecting your publishing destination (tenant or personal workspace), you'll see details about your package and a confirmation message.</p>"},{"location":"core/getting_started/#integrating-with-the-uipath-platform","title":"Integrating with the UiPath Platform","text":"<p>Create a new project (separate from the one you just packaged and published) following the same steps as above. This new project will invoke your previous process using the UiPath SDK.</p> <p>Open <code>main.py</code> in your code editor and add the following code: <pre><code>from uipath.platform import UiPath\n\n\ndef main():\n    sdk = UiPath()\n    sdk.processes.invoke(\n        \"uipath_coded_process\",\n        input_arguments={\n            \"message\": \"Hello, World!\",\n            \"repeat\": 3,\n            \"prefix\": \"[Echo]\"\n        },\n        folder_path=\"PROCESS_FOLDER_PATH_HERE\"\n    )\n</code></pre></p> <p>Warning</p> <p>An agent can invoke itself if needed, but this must be done with caution. Be mindful that using the same name for invocation may lead to unintentional loops. To prevent recursion issues, implement safeguards like exit conditions.</p>"},{"location":"core/getting_started/#verifying-the-execution","title":"Verifying the Execution","text":"uipath run main.py <p>Open your browser and navigate to UiPath. Go to the specified folder, where you'll see a new job for <code>uipath_coded_process</code> has been executed. The output will be: <pre><code>[Echo]: Hello, World! Echo: Hello, World! Echo: Hello, World!\n</code></pre></p>"},{"location":"core/guardrails/","title":"Guardrails","text":""},{"location":"core/guardrails/#uipath.platform.guardrails._guardrails_service.GuardrailsService","title":"GuardrailsService","text":"<p>Service for validating text against UiPath Guardrails.</p> <p>This service provides an interface for evaluating built-in guardrails such as:</p> <ul> <li>PII detection</li> <li>Prompt injection detection</li> </ul> <p>Deterministic and custom guardrails are not yet supported.</p> <p>Version Availability</p> <p>This service is available starting from uipath version 2.2.12.</p>"},{"location":"core/guardrails/#uipath.platform.guardrails._guardrails_service.GuardrailsService.evaluate_guardrail","title":"evaluate_guardrail","text":"<pre><code>evaluate_guardrail(input_data, guardrail)\n</code></pre> <p>Validate input text using the provided guardrail.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>str | dict[str, Any]</code> <p>The text or structured data to validate. Dictionaries will be converted to a string before validation.</p> required <code>guardrail</code> <code>BuiltInValidatorGuardrail</code> <p>A guardrail instance used for validation.</p> required <p>Returns:</p> Name Type Description <code>GuardrailValidationResult</code> <code>GuardrailValidationResult</code> <p>The outcome of the guardrail evaluation.</p>"},{"location":"core/jobs/","title":"Jobs","text":""},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService","title":"JobsService","text":"<p>Service for managing API payloads and job inbox interactions.</p> <p>A job represents a single execution of an automation - it is created when you start   a process and contains information about that specific run, including its status,   start time, and any input/output data.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.create_attachment","title":"create_attachment","text":"<pre><code>create_attachment(\n    *,\n    name,\n    content=None,\n    source_path=None,\n    job_key=None,\n    category=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Create and upload an attachment, optionally linking it to a job.</p> <p>This method handles creating an attachment from a file or memory data. If a job key is provided or available in the execution context, the attachment will be created in UiPath and linked to the job. If no job is available, the file will be saved to a temporary storage folder.</p> Note <p>The local storage functionality (when no job is available) is intended for local development and debugging purposes only.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the attachment file.</p> required <code>content</code> <code>str | bytes | None</code> <p>The content to upload (string or bytes).</p> <code>None</code> <code>source_path</code> <code>str | Path | None</code> <p>The local path of the file to upload.</p> <code>None</code> <code>job_key</code> <code>str | UUID | None</code> <p>The key of the job to link the attachment to.</p> <code>None</code> <code>category</code> <code>str | None</code> <p>Optional category for the attachment in the context of the job.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>UUID</code> <p>uuid.UUID: The unique identifier for the created attachment, regardless of whether it was uploaded to UiPath or stored locally.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither content nor source_path is provided, or if both are provided.</p> <code>Exception</code> <p>If the upload fails.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\n# Create attachment from file and link to job\nattachment_id = client.jobs.create_attachment(\n    name=\"document.pdf\",\n    source_path=\"path/to/local/document.pdf\",\n    job_key=\"38073051\"\n)\nprint(f\"Created and linked attachment: {attachment_id}\")\n\n# Create attachment from memory content (no job available - saves to temp storage)\nattachment_id = client.jobs.create_attachment(\n    name=\"report.txt\",\n    content=\"This is a text report\"\n)\nprint(f\"Created attachment: {attachment_id}\")\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.create_attachment_async","title":"create_attachment_async  <code>async</code>","text":"<pre><code>create_attachment_async(\n    *,\n    name,\n    content=None,\n    source_path=None,\n    job_key=None,\n    category=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Create and upload an attachment asynchronously, optionally linking it to a job.</p> <p>This method asynchronously handles creating an attachment from a file or memory data. If a job key is provided or available in the execution context, the attachment will be created in UiPath and linked to the job. If no job is available, the file will be saved to a temporary storage folder.</p> Note <p>The local storage functionality (when no job is available) is intended for local development and debugging purposes only.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the attachment file.</p> required <code>content</code> <code>str | bytes | None</code> <p>The content to upload (string or bytes).</p> <code>None</code> <code>source_path</code> <code>str | Path | None</code> <p>The local path of the file to upload.</p> <code>None</code> <code>job_key</code> <code>str | UUID | None</code> <p>The key of the job to link the attachment to.</p> <code>None</code> <code>category</code> <code>str | None</code> <p>Optional category for the attachment in the context of the job.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>UUID</code> <p>uuid.UUID: The unique identifier for the created attachment, regardless of whether it was uploaded to UiPath or stored locally.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither content nor source_path is provided, or if both are provided.</p> <code>Exception</code> <p>If the upload fails.</p> <p>Examples:</p> <pre><code>import asyncio\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nasync def main():\n    # Create attachment from file and link to job\n    attachment_id = await client.jobs.create_attachment_async(\n        name=\"document.pdf\",\n        source_path=\"path/to/local/document.pdf\",\n        job_key=\"38073051\"\n    )\n    print(f\"Created and linked attachment: {attachment_id}\")\n\n    # Create attachment from memory content (no job available - saves to temp storage)\n    attachment_id = await client.jobs.create_attachment_async(\n        name=\"report.txt\",\n        content=\"This is a text report\"\n    )\n    print(f\"Created attachment: {attachment_id}\")\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.exists","title":"exists","text":"<pre><code>exists(job_key, *, folder_key=None, folder_path=None)\n</code></pre> <p>Check if job exists.</p> <p>Parameters:</p> Name Type Description Default <code>job_key</code> <code>str</code> <p>Job UUID key</p> required <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if job exists, False otherwise</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; if sdk.jobs.exists(job_key=\"ee9327fd-237d-419e-86ef-9946b34461e3\"):\n...     print(\"Job found\")\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.exists_async","title":"exists_async  <code>async</code>","text":"<pre><code>exists_async(job_key, *, folder_key=None, folder_path=None)\n</code></pre> <p>Async version of exists().</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.extract_output","title":"extract_output","text":"<pre><code>extract_output(job)\n</code></pre> <p>Get the actual output data, downloading from attachment if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job instance to fetch output data from.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Parsed output arguments as dictionary, or None if no output</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.extract_output_async","title":"extract_output_async  <code>async</code>","text":"<pre><code>extract_output_async(job)\n</code></pre> <p>Asynchronously fetch the actual output data, downloading from attachment if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Job</code> <p>The job instance to fetch output data from.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Parsed output arguments as dictionary, or None if no output</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.link_attachment","title":"link_attachment","text":"<pre><code>link_attachment(\n    *,\n    attachment_key,\n    job_key,\n    category=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Link an attachment to a job.</p> <p>This method links an existing attachment to a specific job.</p> <p>Parameters:</p> Name Type Description Default <code>attachment_key</code> <code>UUID</code> <p>The key of the attachment to link.</p> required <code>job_key</code> <code>UUID</code> <p>The key of the job to link the attachment to.</p> required <code>category</code> <code>str | None</code> <p>Optional category for the attachment in the context of this job.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the link operation fails.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.link_attachment_async","title":"link_attachment_async  <code>async</code>","text":"<pre><code>link_attachment_async(\n    *,\n    attachment_key,\n    job_key,\n    category=None,\n    folder_key=None,\n    folder_path=None,\n)\n</code></pre> <p>Link an attachment to a job asynchronously.</p> <p>This method asynchronously links an existing attachment to a specific job.</p> <p>Parameters:</p> Name Type Description Default <code>attachment_key</code> <code>UUID</code> <p>The key of the attachment to link.</p> required <code>job_key</code> <code>UUID</code> <p>The key of the job to link the attachment to.</p> required <code>category</code> <code>str | None</code> <p>Optional category for the attachment in the context of this job.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the link operation fails.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.list","title":"list","text":"<pre><code>list(\n    *,\n    folder_path=None,\n    folder_key=None,\n    filter=None,\n    orderby=None,\n    skip=0,\n    top=100,\n)\n</code></pre> <p>List jobs using OData API with offset-based pagination.</p> <p>Returns a single page of results with pagination metadata.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>str | None</code> <p>Folder path to filter jobs</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key (mutually exclusive with folder_path)</p> <code>None</code> <code>filter</code> <code>str | None</code> <p>OData $filter expression (e.g., \"State eq 'Successful'\")</p> <code>None</code> <code>orderby</code> <code>str | None</code> <p>OData $orderby expression (e.g., \"CreationTime desc\")</p> <code>None</code> <code>skip</code> <code>int</code> <p>Number of items to skip (default 0, max 10000)</p> <code>0</code> <code>top</code> <code>int</code> <p>Maximum items per page (default 100, max 1000)</p> <code>100</code> <p>Returns:</p> Type Description <code>PagedResult[Job]</code> <p>PagedResult[Job]: Page of jobs with pagination metadata</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If skip or top parameters are invalid</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = sdk.jobs.list(top=100)\n&gt;&gt;&gt; for job in result.items:\n...     print(job.key, job.state)\n&gt;&gt;&gt; print(f\"Has more: {result.has_more}\")\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.list_async","title":"list_async  <code>async</code>","text":"<pre><code>list_async(\n    *,\n    folder_path=None,\n    folder_key=None,\n    filter=None,\n    orderby=None,\n    skip=0,\n    top=100,\n)\n</code></pre> <p>Async version of list() with offset-based pagination.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.list_attachments","title":"list_attachments","text":"<pre><code>list_attachments(\n    *, job_key, folder_key=None, folder_path=None\n)\n</code></pre> <p>List attachments associated with a specific job.</p> <p>This method retrieves all attachments linked to a job by its key.</p> <p>Parameters:</p> Name Type Description Default <code>job_key</code> <code>UUID</code> <p>The key of the job to retrieve attachments for.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List[str]: A list of attachment IDs associated with the job.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the retrieval fails.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.list_attachments_async","title":"list_attachments_async  <code>async</code>","text":"<pre><code>list_attachments_async(\n    *, job_key, folder_key=None, folder_path=None\n)\n</code></pre> <p>List attachments associated with a specific job asynchronously.</p> <p>This method asynchronously retrieves all attachments linked to a job by its key.</p> <p>Parameters:</p> Name Type Description Default <code>job_key</code> <code>UUID</code> <p>The key of the job to retrieve attachments for.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List[str]: A list of attachment IDs associated with the job.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the retrieval fails.</p> <p>Examples:</p> <pre><code>import asyncio\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nasync def main():\n    attachments = await client.jobs.list_attachments_async(\n        job_key=uuid.UUID(\"123e4567-e89b-12d3-a456-426614174000\")\n    )\n    for attachment_id in attachments:\n        print(f\"Attachment ID: {attachment_id}\")\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.restart","title":"restart","text":"<pre><code>restart(*, job_key, folder_path=None, folder_key=None)\n</code></pre> <p>Restart a completed or failed job.</p> <p>Parameters:</p> Name Type Description Default <code>job_key</code> <code>str</code> <p>Job UUID key to restart</p> required <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Job</code> <code>Job</code> <p>The restarted job</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; restarted_job = sdk.jobs.restart(job_key=\"ee9327fd-237d-419e-86ef-9946b34461e3\")\n&gt;&gt;&gt; print(restarted_job.state)\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.restart_async","title":"restart_async  <code>async</code>","text":"<pre><code>restart_async(\n    *, job_key, folder_path=None, folder_key=None\n)\n</code></pre> <p>Async version of restart().</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.resume","title":"resume","text":"<pre><code>resume(\n    *,\n    inbox_id=None,\n    job_id=None,\n    folder_key=None,\n    folder_path=None,\n    payload,\n)\n</code></pre> <p>Sends a payload to resume a paused job waiting for input, identified by its inbox ID.</p> <p>Parameters:</p> Name Type Description Default <code>inbox_id</code> <code>str | None</code> <p>The inbox ID of the job.</p> <code>None</code> <code>job_id</code> <code>str | None</code> <p>The job ID of the job.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>payload</code> <code>Any</code> <p>The payload to deliver.</p> required"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.resume_async","title":"resume_async  <code>async</code>","text":"<pre><code>resume_async(\n    *,\n    inbox_id=None,\n    job_id=None,\n    folder_key=None,\n    folder_path=None,\n    payload,\n)\n</code></pre> <p>Asynchronously sends a payload to resume a paused job waiting for input, identified by its inbox ID.</p> <p>Parameters:</p> Name Type Description Default <code>inbox_id</code> <code>str | None</code> <p>The inbox ID of the job. If not provided, the execution context will be used to retrieve the inbox ID.</p> <code>None</code> <code>job_id</code> <code>str | None</code> <p>The job ID of the job.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>payload</code> <code>Any</code> <p>The payload to deliver.</p> required <p>Examples:</p> <pre><code>import asyncio\n\nfrom uipath.platform import UiPath\n\nsdk = UiPath()\n\n\nasync def main():  # noqa: D103\n    payload = await sdk.jobs.resume_async(job_id=\"38073051\", payload=\"The response\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    job_key,\n    *,\n    folder_key=None,\n    folder_path=None,\n    process_name=None,\n)\n</code></pre> <p>Retrieve a job identified by its key.</p> <p>Parameters:</p> Name Type Description Default <code>job_key</code> <code>str</code> <p>The job unique identifier.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder in which the job was executed.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder in which the job was executed.</p> <code>None</code> <code>process_name</code> <code>str | None</code> <p>process name hint for resource override</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Job</code> <code>Job</code> <p>The retrieved job.</p> <p>Raises:</p> Type Description <code>LookupError</code> <p>If the job with the specified key is not found.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nsdk = UiPath()\njob = sdk.jobs.retrieve(job_key=\"ee9327fd-237d-419e-86ef-9946b34461e3\", folder_path=\"Shared\")\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.retrieve_api_payload","title":"retrieve_api_payload","text":"<pre><code>retrieve_api_payload(inbox_id)\n</code></pre> <p>Fetch payload data for API triggers.</p> <p>Parameters:</p> Name Type Description Default <code>inbox_id</code> <code>str</code> <p>The Id of the inbox to fetch the payload for.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value field from the API response payload.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.retrieve_api_payload_async","title":"retrieve_api_payload_async  <code>async</code>","text":"<pre><code>retrieve_api_payload_async(inbox_id)\n</code></pre> <p>Asynchronously fetch payload data for API triggers.</p> <p>Parameters:</p> Name Type Description Default <code>inbox_id</code> <code>str</code> <p>The Id of the inbox to fetch the payload for.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value field from the API response payload.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(\n    job_key,\n    *,\n    folder_key=None,\n    folder_path=None,\n    process_name=None,\n)\n</code></pre> <p>Asynchronously retrieve a job identified by its key.</p> <p>Parameters:</p> Name Type Description Default <code>job_key</code> <code>str</code> <p>The job unique identifier.</p> required <code>folder_key</code> <code>str | None</code> <p>The key of the folder in which the job was executed.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder in which the job was executed.</p> <code>None</code> <code>process_name</code> <code>str | None</code> <p>process name hint for resource override</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Job</code> <code>Job</code> <p>The retrieved job.</p> <p>Raises:</p> Type Description <code>LookupError</code> <p>If the job with the specified key is not found.</p> <p>Examples:</p> <pre><code>import asyncio\n\nfrom uipath.platform import UiPath\n\nsdk = UiPath()\n\n\nasync def main():  # noqa: D103\n    job = await sdk.jobs.retrieve_async(job_key=\"ee9327fd-237d-419e-86ef-9946b34461e3\", folder_path=\"Shared\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.stop","title":"stop","text":"<pre><code>stop(\n    *,\n    job_keys,\n    strategy=\"SoftStop\",\n    folder_path=None,\n    folder_key=None,\n)\n</code></pre> <p>Stop one or more jobs with specified strategy.</p> <p>This method uses bulk resolution to efficiently stop multiple jobs, preventing N+1 query issues. Requests are automatically chunked for large job lists to avoid URL length constraints.</p> <p>Parameters:</p> Name Type Description Default <code>job_keys</code> <code>list[str]</code> <p>List of job UUID keys to stop</p> required <code>strategy</code> <code>str</code> <p>Stop strategy - \"SoftStop\" (graceful) or \"Kill\" (force)</p> <code>'SoftStop'</code> <code>folder_path</code> <code>str | None</code> <p>Folder path</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Folder key</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any job key is not a valid UUID format</p> <code>LookupError</code> <p>If any job keys are not found</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sdk.jobs.stop(job_keys=[\"ee9327fd-237d-419e-86ef-9946b34461e3\"])\n&gt;&gt;&gt; sdk.jobs.stop(job_keys=[\"key1\", \"key2\"], strategy=\"Kill\")\n</code></pre> Note <p>Large batches are automatically chunked (50 keys per request) to avoid URL length limits. The method supports stopping hundreds of jobs efficiently.</p>"},{"location":"core/jobs/#uipath.platform.orchestrator._jobs_service.JobsService.stop_async","title":"stop_async  <code>async</code>","text":"<pre><code>stop_async(\n    *,\n    job_keys,\n    strategy=\"SoftStop\",\n    folder_path=None,\n    folder_key=None,\n)\n</code></pre> <p>Async version of stop().</p>"},{"location":"core/llm_gateway/","title":"LLM Gateway","text":"<p>UiPath LLM Gateway Services.</p> <p>This module provides services for interacting with UiPath's LLM (Large Language Model) Gateway, offering both OpenAI-compatible and normalized API interfaces for chat completions and embeddings.</p> <p>The module includes: - UiPathOpenAIService: OpenAI-compatible API for chat completions and embeddings - UiPathLlmChatService: UiPath's normalized API with advanced features like tool calling - ChatModels: Constants for available chat models - EmbeddingModels: Constants for available embedding models</p> <p>Classes:</p> Name Description <code>ChatModels</code> <p>Container for supported chat model identifiers</p> <code>EmbeddingModels</code> <p>Container for supported embedding model identifiers</p> <code>UiPathOpenAIService</code> <p>Service using OpenAI-compatible API format</p> <code>UiPathLlmChatService</code> <p>Service using UiPath's normalized API format</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.ChatModels","title":"ChatModels","text":"<p>Available chat models for LLM Gateway services.</p> <p>This class provides constants for the supported chat models that can be used with both UiPathOpenAIService and UiPathLlmChatService.</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.EmbeddingModels","title":"EmbeddingModels","text":"<p>Available embedding models for LLM Gateway services.</p> <p>This class provides constants for the supported embedding models that can be used with the embeddings functionality.</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.UiPathLlmChatService","title":"UiPathLlmChatService","text":"<p>Service for calling UiPath's normalized LLM Gateway API.</p> <p>This service provides access to Large Language Model capabilities through UiPath's normalized LLM Gateway API. Unlike the OpenAI-compatible service, this service uses UiPath's standardized API format and supports advanced features like tool calling, function calling, and more sophisticated conversation control.</p> <p>The normalized API provides a consistent interface across different underlying model providers and includes enhanced features for enterprise use cases.</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.UiPathLlmChatService.chat_completions","title":"chat_completions  <code>async</code>","text":"<pre><code>chat_completions(\n    messages,\n    model=ChatModels.gpt_4_1_mini_2025_04_14,\n    max_tokens=4096,\n    temperature=0,\n    n=1,\n    frequency_penalty=0,\n    presence_penalty=0,\n    top_p=1,\n    top_k=None,\n    tools=None,\n    tool_choice=None,\n    response_format=None,\n    api_version=NORMALIZED_API_VERSION,\n)\n</code></pre> <p>Generate chat completions using UiPath's normalized LLM Gateway API.</p> <p>This method provides advanced conversational AI capabilities with support for tool calling, function calling, and sophisticated conversation control parameters. It uses UiPath's normalized API format for consistent behavior across different model providers.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>List[Dict[str, str]]</code> <p>List of message dictionaries with 'role' and 'content' keys. The supported roles are 'system', 'user', and 'assistant'. System messages set the behavior/context, user messages are from the human, and assistant messages are from the AI.</p> required <code>model</code> <code>str</code> <p>The model to use for chat completion. Defaults to ChatModels.gpt_4_1_mini_2025_04_14. Available models are defined in the ChatModels class.</p> <code>gpt_4_1_mini_2025_04_14</code> <code>max_tokens</code> <code>int</code> <p>Maximum number of tokens to generate in the response. Defaults to 4096. Higher values allow longer responses.</p> <code>4096</code> <code>temperature</code> <code>float</code> <p>Temperature for sampling, between 0 and 1. Lower values (closer to 0) make output more deterministic and focused, higher values make it more creative and random. Defaults to 0.</p> <code>0</code> <code>n</code> <code>int</code> <p>Number of chat completion choices to generate for each input. Defaults to 1. Higher values generate multiple alternative responses.</p> <code>1</code> <code>frequency_penalty</code> <code>float</code> <p>Penalty for token frequency between -2.0 and 2.0. Positive values reduce repetition of frequent tokens. Defaults to 0.</p> <code>0</code> <code>presence_penalty</code> <code>float</code> <p>Penalty for token presence between -2.0 and 2.0. Positive values encourage discussion of new topics. Defaults to 0.</p> <code>0</code> <code>top_p</code> <code>float</code> <p>Nucleus sampling parameter between 0 and 1. Controls diversity by considering only the top p probability mass. Defaults to 1.</p> <code>1</code> <code>top_k</code> <code>int</code> <p>Nucleus sampling parameter. Controls diversity by considering only the top k most probable tokens. Defaults to None.</p> <code>None</code> <code>tools</code> <code>Optional[List[ToolDefinition]]</code> <p>List of tool definitions that the model can call. Tools enable the model to perform actions or retrieve information beyond text generation. Defaults to None.</p> <code>None</code> <code>tool_choice</code> <code>Optional[ToolChoice]</code> <p>Controls which tools the model can call. Can be \"auto\" (model decides), \"none\" (no tools), or a specific tool choice. Defaults to None.</p> <code>None</code> <code>response_format</code> <code>Optional[Union[Dict[str, Any], type[BaseModel]]]</code> <p>An object specifying the format that the model must output. Can be either: - A dictionary with response format configuration (traditional format) - A Pydantic BaseModel class (automatically converted to JSON schema) Used to enable JSON mode or other structured outputs. Defaults to None.</p> <code>None</code> <code>api_version</code> <code>str</code> <p>The normalized API version to use. Defaults to NORMALIZED_API_VERSION.</p> <code>NORMALIZED_API_VERSION</code> <p>Returns:</p> Name Type Description <code>ChatCompletion</code> <p>The chat completion response containing the generated message(s), tool calls (if any), usage statistics, and other metadata.</p> <p>Examples:</p> <pre><code># Basic conversation\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"What is the weather like today?\"}\n]\nresponse = await service.chat_completions(messages)\n\n# Conversation with tool calling\ntools = [\n    ToolDefinition(\n        function=FunctionDefinition(\n            name=\"get_weather\",\n            description=\"Get current weather for a location\",\n            parameters=ParametersDefinition(\n                type=\"object\",\n                properties={\n                    \"location\": PropertyDefinition(\n                        type=\"string\",\n                        description=\"City name\"\n                    )\n                },\n                required=[\"location\"]\n            )\n        )\n    )\n]\nresponse = await service.chat_completions(\n    messages,\n    tools=tools,\n    tool_choice=\"auto\",\n    max_tokens=500\n)\n\n# Advanced parameters for creative writing\nresponse = await service.chat_completions(\n    messages,\n    temperature=0.8,\n    top_p=0.9,\n    frequency_penalty=0.3,\n    presence_penalty=0.2,\n    n=3  # Generate 3 alternative responses\n)\n\n# Using Pydantic model for structured response\nfrom pydantic import BaseModel\n\nclass Country(BaseModel):\n    name: str\n    capital: str\n    languages: list[str]\n\nresponse = await service.chat_completions(\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond with structured JSON.\"},\n        {\"role\": \"user\", \"content\": \"Tell me about Canada.\"}\n    ],\n    response_format=Country,  # Pass BaseModel directly\n    max_tokens=1000\n)\n)\n</code></pre> Note <p>This service uses UiPath's normalized API format which provides consistent behavior across different underlying model providers and enhanced enterprise features.</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.UiPathOpenAIService","title":"UiPathOpenAIService","text":"<p>Service for calling UiPath's LLM Gateway using OpenAI-compatible API.</p> <p>This service provides access to Large Language Model capabilities through UiPath's LLM Gateway, including chat completions and text embeddings. It uses the OpenAI-compatible API format and is suitable for applications that need direct OpenAI API compatibility.</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.UiPathOpenAIService.chat_completions","title":"chat_completions  <code>async</code>","text":"<pre><code>chat_completions(\n    messages,\n    model=ChatModels.gpt_4_1_mini_2025_04_14,\n    max_tokens=4096,\n    temperature=0,\n    response_format=None,\n    api_version=API_VERSION,\n)\n</code></pre> <p>Generate chat completions using UiPath's LLM Gateway service.</p> <p>This method provides conversational AI capabilities by sending a series of messages to a language model and receiving a generated response. It supports multi-turn conversations and various OpenAI-compatible models.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>List[Dict[str, str]]</code> <p>List of message dictionaries with 'role' and 'content' keys. The supported roles are 'system', 'user', and 'assistant'. System messages set the behavior/context, user messages are from the human, and assistant messages are from the AI.</p> required <code>model</code> <code>str</code> <p>The model to use for chat completion. Defaults to ChatModels.gpt_4_1_mini_2025_04_14. Available models are defined in the ChatModels class.</p> <code>gpt_4_1_mini_2025_04_14</code> <code>max_tokens</code> <code>int</code> <p>Maximum number of tokens to generate in the response. Defaults to 4096. Higher values allow longer responses.</p> <code>4096</code> <code>temperature</code> <code>float</code> <p>Temperature for sampling, between 0 and 1. Lower values (closer to 0) make output more deterministic and focused, higher values make it more creative and random. Defaults to 0.</p> <code>0</code> <code>response_format</code> <code>Optional[Union[Dict[str, Any], type[BaseModel]]]</code> <p>An object specifying the format that the model must output. Can be either: - A dictionary with response format configuration (traditional format) - A Pydantic BaseModel class (automatically converted to JSON schema) Used to enable JSON mode or other structured outputs. Defaults to None.</p> <code>None</code> <code>api_version</code> <code>str</code> <p>The API version to use. Defaults to API_VERSION.</p> <code>API_VERSION</code> <p>Returns:</p> Name Type Description <code>ChatCompletion</code> <p>The chat completion response containing the generated message, usage statistics, and other metadata.</p> <p>Examples:</p> <pre><code># Simple conversation\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful Python programming assistant.\"},\n    {\"role\": \"user\", \"content\": \"How do I read a file in Python?\"}\n]\nresponse = await service.chat_completions(messages)\n\n# Multi-turn conversation with more tokens\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"What is machine learning?\"},\n    {\"role\": \"assistant\", \"content\": \"Machine learning is a subset of AI...\"},\n    {\"role\": \"user\", \"content\": \"Can you give me a practical example?\"}\n]\nresponse = await service.chat_completions(\n    messages,\n    max_tokens=200,\n    temperature=0.3\n)\n\n# Using Pydantic model for structured response\nfrom pydantic import BaseModel\n\nclass Country(BaseModel):\n    name: str\n    capital: str\n    languages: list[str]\n\nresponse = await service.chat_completions(\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond with structured JSON.\"},\n        {\"role\": \"user\", \"content\": \"Tell me about Canada.\"}\n    ],\n    response_format=Country,  # Pass BaseModel directly\n    max_tokens=1000\n)\n</code></pre> Note <p>The conversation history can be included to provide context to the model. Each message should have both 'role' and 'content' keys. When using a Pydantic BaseModel as response_format, it will be automatically converted to the appropriate JSON schema format for the LLM Gateway.</p>"},{"location":"core/llm_gateway/#uipath.platform.chat._llm_gateway_service.UiPathOpenAIService.embeddings","title":"embeddings  <code>async</code>","text":"<pre><code>embeddings(\n    input,\n    embedding_model=EmbeddingModels.text_embedding_ada_002,\n    openai_api_version=API_VERSION,\n)\n</code></pre> <p>Generate text embeddings using UiPath's LLM Gateway service.</p> <p>This method converts input text into dense vector representations that can be used for semantic search, similarity calculations, and other NLP tasks.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The input text to embed. Can be a single sentence, paragraph, or document that you want to convert to embeddings.</p> required <code>embedding_model</code> <code>str</code> <p>The embedding model to use. Defaults to EmbeddingModels.text_embedding_ada_002. Available models are defined in the EmbeddingModels class.</p> <code>text_embedding_ada_002</code> <code>openai_api_version</code> <code>str</code> <p>The OpenAI API version to use. Defaults to API_VERSION.</p> <code>API_VERSION</code> <p>Returns:</p> Name Type Description <code>TextEmbedding</code> <p>The embedding response containing the vector representation of the input text along with metadata.</p> <p>Examples:</p> <pre><code># Basic embedding\nembedding = await service.embeddings(\"Hello, world!\")\n\n# Using a specific model\nembedding = await service.embeddings(\n    \"This is a longer text to embed\",\n    embedding_model=EmbeddingModels.text_embedding_3_large\n)\n</code></pre>"},{"location":"core/processes/","title":"Processes","text":""},{"location":"core/processes/#uipath.platform.orchestrator._processes_service.ProcessesService","title":"ProcessesService","text":"<p>Service for managing and executing UiPath automation processes.</p> <p>Processes (also known as automations or workflows) are the core units of automation in UiPath, representing sequences of activities that perform specific business tasks.</p>"},{"location":"core/processes/#uipath.platform.orchestrator._processes_service.ProcessesService.invoke","title":"invoke","text":"<pre><code>invoke(\n    name,\n    input_arguments=None,\n    *,\n    folder_key=None,\n    folder_path=None,\n    attachments=None,\n    **kwargs,\n)\n</code></pre> <p>Start execution of a process by its name.</p> <p>Related Activity: Invoke Process</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the process to execute.</p> required <code>input_arguments</code> <code>dict[str, Any] | None</code> <p>The input arguments to pass to the process.</p> <code>None</code> <code>attachments</code> <code>list | None</code> <p>List of Attachment objects to pass to the process.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Job</code> <code>Job</code> <p>The job execution details.</p> <p>Examples:</p> <pre><code>from uipath.platform import UiPath\n\nclient = UiPath()\n\nclient.processes.invoke(name=\"MyProcess\")\n</code></pre> <pre><code># if you want to execute the process in a specific folder\n# another one than the one set in the SDK config\nfrom uipath.platform import UiPath\n\nclient = UiPath()\n\nclient.processes.invoke(name=\"MyProcess\", folder_path=\"my-folder-key\")\n</code></pre>"},{"location":"core/processes/#uipath.platform.orchestrator._processes_service.ProcessesService.invoke_async","title":"invoke_async  <code>async</code>","text":"<pre><code>invoke_async(\n    name,\n    input_arguments=None,\n    *,\n    folder_key=None,\n    folder_path=None,\n    attachments=None,\n    **kwargs,\n)\n</code></pre> <p>Asynchronously start execution of a process by its name.</p> <p>Related Activity: Invoke Process</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the process to execute.</p> required <code>input_arguments</code> <code>dict[str, Any] | None</code> <p>The input arguments to pass to the process.</p> <code>None</code> <code>attachments</code> <code>list | None</code> <p>List of Attachment objects to pass to the process.</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>The key of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>The path of the folder to execute the process in. Override the default one set in the SDK config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Job</code> <code>Job</code> <p>The job execution details.</p> <p>Examples:</p> <pre><code>import asyncio\n\nfrom uipath.platform import UiPath\n\nsdk = UiPath()\n\nasync def main():\n    job = await sdk.processes.invoke_async(\"testAppAction\")\n    print(job)\n\nasyncio.run(main())\n</code></pre>"},{"location":"core/queues/","title":"Queues","text":""},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService","title":"QueuesService","text":"<p>Service for managing UiPath queues and queue items.</p> <p>Queues are a fundamental component of UiPath automation that enable distributed and scalable processing of work items.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.complete_transaction_item","title":"complete_transaction_item","text":"<pre><code>complete_transaction_item(transaction_key, result)\n</code></pre> <p>Completes a transaction item with the specified result.</p> <p>Parameters:</p> Name Type Description Default <code>transaction_key</code> <code>str</code> <p>Unique identifier of the transaction to complete.</p> required <code>result</code> <code>dict[str, Any] | TransactionItemResult</code> <p>Result data for the transaction, either as a dictionary or TransactionItemResult instance.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response confirming the transaction completion.</p> <p>Related Activity: Set Transaction Status</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.complete_transaction_item_async","title":"complete_transaction_item_async  <code>async</code>","text":"<pre><code>complete_transaction_item_async(transaction_key, result)\n</code></pre> <p>Asynchronously completes a transaction item with the specified result.</p> <p>Parameters:</p> Name Type Description Default <code>transaction_key</code> <code>str</code> <p>Unique identifier of the transaction to complete.</p> required <code>result</code> <code>dict[str, Any] | TransactionItemResult</code> <p>Result data for the transaction, either as a dictionary or TransactionItemResult instance.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response confirming the transaction completion.</p> <p>Related Activity: Set Transaction Status</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.create_item","title":"create_item","text":"<pre><code>create_item(item)\n</code></pre> <p>Creates a new queue item in the Orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>dict[str, Any] | QueueItem</code> <p>Queue item data, either as a dictionary or QueueItem instance.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the created queue item details.</p> <p>Related Activity: Add Queue Item</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.create_item_async","title":"create_item_async  <code>async</code>","text":"<pre><code>create_item_async(item)\n</code></pre> <p>Asynchronously creates a new queue item in the Orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>dict[str, Any] | QueueItem</code> <p>Queue item data, either as a dictionary or QueueItem instance.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the created queue item details.</p> <p>Related Activity: Add Queue Item</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.create_items","title":"create_items","text":"<pre><code>create_items(items, queue_name, commit_type)\n</code></pre> <p>Creates multiple queue items in bulk.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict[str, Any] | QueueItem]</code> <p>List of queue items to create, each either a dictionary or QueueItem instance.</p> required <code>queue_name</code> <code>str</code> <p>Name of the target queue.</p> required <code>commit_type</code> <code>CommitType</code> <p>Type of commit operation to use for the bulk operation.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the bulk operation result.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.create_items_async","title":"create_items_async  <code>async</code>","text":"<pre><code>create_items_async(items, queue_name, commit_type)\n</code></pre> <p>Asynchronously creates multiple queue items in bulk.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict[str, Any] | QueueItem]</code> <p>List of queue items to create, each either a dictionary or QueueItem instance.</p> required <code>queue_name</code> <code>str</code> <p>Name of the target queue.</p> required <code>commit_type</code> <code>CommitType</code> <p>Type of commit operation to use for the bulk operation.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the bulk operation result.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.create_transaction_item","title":"create_transaction_item","text":"<pre><code>create_transaction_item(item, no_robot=False)\n</code></pre> <p>Creates a new transaction item in a queue.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>dict[str, Any] | TransactionItem</code> <p>Transaction item data, either as a dictionary or TransactionItem instance.</p> required <code>no_robot</code> <code>bool</code> <p>If True, the transaction will not be associated with a robot. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the transaction item details.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.create_transaction_item_async","title":"create_transaction_item_async  <code>async</code>","text":"<pre><code>create_transaction_item_async(item, no_robot=False)\n</code></pre> <p>Asynchronously creates a new transaction item in a queue.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>dict[str, Any] | TransactionItem</code> <p>Transaction item data, either as a dictionary or TransactionItem instance.</p> required <code>no_robot</code> <code>bool</code> <p>If True, the transaction will not be associated with a robot. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the transaction item details.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.list_items","title":"list_items","text":"<pre><code>list_items()\n</code></pre> <p>Retrieves a list of queue items from the Orchestrator.</p> <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the list of queue items.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.list_items_async","title":"list_items_async  <code>async</code>","text":"<pre><code>list_items_async()\n</code></pre> <p>Asynchronously retrieves a list of queue items from the Orchestrator.</p> <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response containing the list of queue items.</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.update_progress_of_transaction_item","title":"update_progress_of_transaction_item","text":"<pre><code>update_progress_of_transaction_item(\n    transaction_key, progress\n)\n</code></pre> <p>Updates the progress of a transaction item.</p> <p>Parameters:</p> Name Type Description Default <code>transaction_key</code> <code>str</code> <p>Unique identifier of the transaction.</p> required <code>progress</code> <code>str</code> <p>Progress message to set.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response confirming the progress update.</p> <p>Related Activity: Set Transaction Progress</p>"},{"location":"core/queues/#uipath.platform.orchestrator._queues_service.QueuesService.update_progress_of_transaction_item_async","title":"update_progress_of_transaction_item_async  <code>async</code>","text":"<pre><code>update_progress_of_transaction_item_async(\n    transaction_key, progress\n)\n</code></pre> <p>Asynchronously updates the progress of a transaction item.</p> <p>Parameters:</p> Name Type Description Default <code>transaction_key</code> <code>str</code> <p>Unique identifier of the transaction.</p> required <code>progress</code> <code>str</code> <p>Progress message to set.</p> required <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>HTTP response confirming the progress update.</p> <p>Related Activity: Set Transaction Progress</p>"},{"location":"core/release_notes/","title":"\ud83d\udea8 Breaking Changes for UiPath Python SDK (v2.2.0+)","text":"<p>Release Date: November 26, 2025</p> <p>Version 2.2.0 of the UiPath Python SDK introduces several breaking changes affecting both the SDK and CLI.</p>"},{"location":"core/release_notes/#breaking-changes","title":"Breaking Changes","text":""},{"location":"core/release_notes/#1-minimum-python-version-311-required","title":"1. Minimum Python Version: 3.11+ Required","text":"<p>What's changing: Python 3.10 is no longer supported for <code>uipath-python</code>, <code>uipath-langchain-python</code>, <code>uipath-llamaindex-python</code>.</p> <p>Action required: Upgrade to Python 3.11 or higher.</p>"},{"location":"core/release_notes/#2-import-path-change","title":"2. Import Path Change","text":"<p>What's changing: The <code>UiPath</code> class has moved from <code>uipath</code> to <code>uipath.platform</code>.</p> <p>Action required: Update your imports:</p> <pre><code># Before\nfrom uipath import UiPath\nfrom uipath.models import Job, Asset, Queue\nfrom uipath.models import Entity \n\n# After\nfrom uipath.platform import UiPath, Job, Asset, Queue\n\nclient = UiPath(...)\n</code></pre>"},{"location":"core/release_notes/#3-transition-to-langchain-v1-for-uipath-langchain-only","title":"3. Transition to LangChain v1 (for <code>uipath-langchain</code> only)","text":"<p>What's changing: Minimum required versions are now LangChain 1.0.0+ and LangGraph 1.0.0+</p> <p>Action required: Review and update your code according to the LangChain v1 Migration Guide.</p> <p>Note: This only applies if you're using the <code>uipath-langchain</code> package.</p>"},{"location":"core/release_notes/#4-configuration-architecture-redesign","title":"4. Configuration Architecture Redesign","text":"<p>We've restructured how UiPath projects define and manage their resources:</p> <p><code>uipath.json</code> - Configuration File (Updated Purpose) - Previously contained entrypoints and bindings; now serves as a streamlined configuration file - For pure Python scripts, define entrypoints in the <code>functions</code> section:   <pre><code>{\n  \"functions\": {\n    \"entrypoint1\": \"src/main.py:\",\n    \"entrypoint2\": \"src/graph.py:runtime\"\n  }\n}\n</code></pre> - For LangGraph graphs, define entrypoints in <code>langgraph.json</code> (same as before) - For LlamaIndex workflows, define entrypoints in <code>llamaindex.json</code> (same as before)</p> <p><code>bindings.json</code> - Manual Binding Definitions (New) - Overridable resources (bindings) now stored in a separate file - Bindings are no longer automatically inferred from code - Must be manually defined by the user for now (we're working on an interactive configurator to simplify this process)</p> <p><code>entry-points.json</code> - I/O Schema (New) - Contains the input/output schema for your entrypoints - Automatically inferred from code based on entrypoints defined in <code>llamaindex.json</code>/<code>langgraph.json</code>/<code>uipath.json</code></p>"},{"location":"core/release_notes/#migration-guide","title":"Migration Guide","text":""},{"location":"core/release_notes/#stay-on-v21x","title":"Stay on v2.1.x","text":"<p>To avoid these breaking changes and keep your current setup, pin your dependency in <code>pyproject.toml</code>:</p> <pre><code>\"uipath&gt;=2.1.x,&lt;2.2.0\"\n</code></pre> <p>For <code>uipath-langchain</code> users: To stay on the current version without LangChain v1: <pre><code>\"uipath-langchain&gt;=0.0.x,&lt;0.1.0\"\n</code></pre></p>"},{"location":"core/release_notes/#migrate-to-v220","title":"Migrate to v2.2.0+","text":"<ol> <li>Upgrade to v2.2.0+</li> </ol> <p>Update the dependencies in <code>pyproject.toml</code> with:    <pre><code>\"uipath&gt;=2.2.x,&lt;2.3.0\"\n</code></pre></p> <p>Bounding the version to &lt;2.3.0 prevents future breaking changes</p> <p>For <code>uipath-langchain</code> users:     To migrate to LangChain v1:    <pre><code>\"uipath-langchain&gt;=0.1.0,&lt;0.2.0\"\n</code></pre> For <code>uipath-langchain</code>/<code>uipath-llamaindex</code> users:    Make sure to also reference <code>uipath</code> in your <code>pyproject.toml</code> - future versions will no longer reference the main <code>uipath</code> CLI package as a dependency.</p> <ol> <li>Upgrade the Python version to 3.11+</li> </ol> <p>In <code>pyproject.toml</code> specify the required Python version by adding or updating the following field:    <pre><code>requires-python = \"&gt;=3.11\"\n</code></pre></p> <ol> <li>Update imports</li> </ol> <p>Change <code>from uipath import UiPath</code> to <code>from uipath.platform import UiPath</code>.</p> <ol> <li>Review LangChain v1 changes (if using <code>uipath-langchain</code>)</li> </ol> <p>Review the LangChain v1 Migration Guide and update your code accordingly.</p> <ol> <li>Update configuration files</li> </ol> <ul> <li>Define your entrypoints in <code>scripts</code> within <code>uipath.json</code> (not applicable if you already use <code>langgraph.json</code>/<code>llamaindex.json</code>)</li> <li>Run <code>uipath init</code> to automatically generate the <code>entry-points.json</code> I/O schema from your configuration</li> <li>Create <code>bindings.json</code> and manually define all overridable resources</li> <li>Important: If you update your script/agent code, run <code>uipath init</code> again to regenerate the I/O schema</li> </ul> <p>For questions or issues, please open a ticket: UiPath Python SDK Submit Issue</p>"},{"location":"core/resource_catalog/","title":"Resource Catalog","text":""},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService","title":"ResourceCatalogService","text":"<p>Service for searching and discovering UiPath resources across folders.</p> <p>The Resource Catalog Service provides a centralized way to search and retrieve UiPath resources (assets, queues, processes, storage buckets, etc.) across tenant and folder scopes. It enables programmatic discovery of resources with flexible filtering by resource type, name, and folder location.</p> See Also <p>https://docs.uipath.com/orchestrator/standalone/2024.10/user-guide/about-resource-catalog-service</p> <p>Version Availability</p> <p>This service is available starting from uipath version 2.1.168.</p>"},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService.list","title":"list","text":"<pre><code>list(\n    *,\n    resource_types=None,\n    resource_sub_types=None,\n    folder_path=None,\n    folder_key=None,\n    page_size=_DEFAULT_PAGE_SIZE,\n)\n</code></pre> <p>Get tenant scoped resources and folder scoped resources (accessible to the user).</p> <p>If no folder identifier is provided (path or key) only tenant resources will be retrieved. This method automatically handles pagination and yields resources one by one.</p> <p>Parameters:</p> Name Type Description Default <code>resource_types</code> <code>list[ResourceType] | None</code> <p>Optional list of resource types to filter by</p> <code>None</code> <code>resource_sub_types</code> <code>list[str] | None</code> <p>Optional list of resource subtypes to filter by</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Optional folder path to scope the results</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Optional folder key to scope the results</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of resources to fetch per API call (default: 20, max: 100)</p> <code>_DEFAULT_PAGE_SIZE</code> <p>Yields:</p> Name Type Description <code>Resource</code> <code>Resource</code> <p>Each resource matching the criteria</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get all resources\n&gt;&gt;&gt; for resource in uipath.resource_catalog.list():\n...     print(f\"{resource.name}: {resource.resource_type}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Get specific resource types\n&gt;&gt;&gt; assets = list(uipath.resource_catalog.list(\n...     resource_types=[ResourceType.ASSET],\n... ))\n</code></pre> <pre><code>&gt;&gt;&gt; # Get resources within a specific folder\n&gt;&gt;&gt; for resource in uipath.resource_catalog.list(\n...     folder_path=\"/Shared/Finance\",\n...     resource_types=[ResourceType.ASSET],\n...     resource_sub_types=[\"number\"]\n... ):\n...     print(resource.name)\n</code></pre>"},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService.list_async","title":"list_async  <code>async</code>","text":"<pre><code>list_async(\n    *,\n    resource_types=None,\n    resource_sub_types=None,\n    folder_path=None,\n    folder_key=None,\n    page_size=_DEFAULT_PAGE_SIZE,\n)\n</code></pre> <p>Asynchronously get tenant scoped resources and folder scoped resources (accessible to the user).</p> <p>If no folder identifier is provided (path or key) only tenant resources will be retrieved. This method automatically handles pagination and yields resources one by one.</p> <p>Parameters:</p> Name Type Description Default <code>resource_types</code> <code>list[ResourceType] | None</code> <p>Optional list of resource types to filter by</p> <code>None</code> <code>resource_sub_types</code> <code>list[str] | None</code> <p>Optional list of resource subtypes to filter by</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Optional folder path to scope the results</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Optional folder key to scope the results</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of resources to fetch per API call (default: 20, max: 100)</p> <code>_DEFAULT_PAGE_SIZE</code> <p>Yields:</p> Name Type Description <code>Resource</code> <code>AsyncIterator[Resource]</code> <p>Each resource matching the criteria</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get all resources\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.list_async():\n...     print(f\"{resource.name}: {resource.resource_type}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Get specific resource types\n&gt;&gt;&gt; assets = []\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.list_async(\n...     resource_types=[ResourceType.ASSET],\n... ):\n...     assets.append(resource)\n</code></pre> <pre><code>&gt;&gt;&gt; # Get resources within a specific folder\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.list_async(\n...     folder_path=\"/Shared/Finance\",\n...     resource_types=[ResourceType.ASSET],\n...     resource_sub_types=[\"number\"]\n... ):\n...     print(resource.name)\n</code></pre>"},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService.list_by_type","title":"list_by_type","text":"<pre><code>list_by_type(\n    *,\n    resource_type,\n    name=None,\n    resource_sub_types=None,\n    folder_path=None,\n    folder_key=None,\n    page_size=_DEFAULT_PAGE_SIZE,\n)\n</code></pre> <p>Get resources of a specific type (tenant scoped or folder scoped).</p> <p>If no folder identifier is provided (path or key) only tenant resources will be retrieved. This method automatically handles pagination and yields resources one by one.</p> <p>Parameters:</p> Name Type Description Default <code>resource_type</code> <code>ResourceType</code> <p>The specific resource type to filter by</p> required <code>name</code> <code>str | None</code> <p>Optional name filter for resources</p> <code>None</code> <code>resource_sub_types</code> <code>list[str] | None</code> <p>Optional list of resource subtypes to filter by</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Optional folder path to scope the results</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Optional folder key to scope the results</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of resources to fetch per API call (default: 20, max: 100)</p> <code>_DEFAULT_PAGE_SIZE</code> <p>Yields:</p> Name Type Description <code>Resource</code> <code>Resource</code> <p>Each resource matching the criteria</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get all assets\n&gt;&gt;&gt; for resource in uipath.resource_catalog.list_by_type(resource_type=ResourceType.ASSET):\n...     print(f\"{resource.name}: {resource.resource_sub_type}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Get assets with a specific name pattern\n&gt;&gt;&gt; assets = list(uipath.resource_catalog.list_by_type(\n...     resource_type=ResourceType.ASSET,\n...     name=\"config\"\n... ))\n</code></pre> <pre><code>&gt;&gt;&gt; # Get assets within a specific folder with subtype filter\n&gt;&gt;&gt; for resource in uipath.resource_catalog.list_by_type(\n...     resource_type=ResourceType.ASSET,\n...     folder_path=\"/Shared/Finance\",\n...     resource_sub_types=[\"number\"]\n... ):\n...     print(resource.name)\n</code></pre>"},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService.list_by_type_async","title":"list_by_type_async  <code>async</code>","text":"<pre><code>list_by_type_async(\n    *,\n    resource_type,\n    name=None,\n    resource_sub_types=None,\n    folder_path=None,\n    folder_key=None,\n    page_size=_DEFAULT_PAGE_SIZE,\n)\n</code></pre> <p>Asynchronously get resources of a specific type (tenant scoped or folder scoped).</p> <p>If no folder identifier is provided (path or key) only tenant resources will be retrieved. This method automatically handles pagination and yields resources one by one.</p> <p>Parameters:</p> Name Type Description Default <code>resource_type</code> <code>ResourceType</code> <p>The specific resource type to filter by</p> required <code>name</code> <code>str | None</code> <p>Optional name filter for resources</p> <code>None</code> <code>resource_sub_types</code> <code>list[str] | None</code> <p>Optional list of resource subtypes to filter by</p> <code>None</code> <code>folder_path</code> <code>str | None</code> <p>Optional folder path to scope the results</p> <code>None</code> <code>folder_key</code> <code>str | None</code> <p>Optional folder key to scope the results</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of resources to fetch per API call (default: 20, max: 100)</p> <code>_DEFAULT_PAGE_SIZE</code> <p>Yields:</p> Name Type Description <code>Resource</code> <code>AsyncIterator[Resource]</code> <p>Each resource matching the criteria</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Get all assets asynchronously\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.list_by_type_async(resource_type=ResourceType.ASSET):\n...     print(f\"{resource.name}: {resource.resource_sub_type}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Get assets with a specific name pattern\n&gt;&gt;&gt; assets = []\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.list_by_type_async(\n...     resource_type=ResourceType.ASSET,\n...     name=\"config\"\n... ):\n...     assets.append(resource)\n</code></pre> <pre><code>&gt;&gt;&gt; # Get assets within a specific folder with subtype filter\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.list_by_type_async(\n...     resource_type=ResourceType.ASSET,\n...     folder_path=\"/Shared/Finance\",\n...     resource_sub_types=[\"number\"]\n... ):\n...     print(resource.name)\n</code></pre>"},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService.search","title":"search","text":"<pre><code>search(\n    *,\n    name=None,\n    resource_types=None,\n    resource_sub_types=None,\n    page_size=_DEFAULT_PAGE_SIZE,\n)\n</code></pre> <p>Search for tenant scoped resources and folder scoped resources (accessible to the user).</p> <p>This method automatically handles pagination and yields resources one by one.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional name filter for resources</p> <code>None</code> <code>resource_types</code> <code>list[ResourceType] | None</code> <p>Optional list of resource types to filter by</p> <code>None</code> <code>resource_sub_types</code> <code>list[str] | None</code> <p>Optional list of resource subtypes to filter by</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of resources to fetch per API call (default: 20, max: 100)</p> <code>_DEFAULT_PAGE_SIZE</code> <p>Yields:</p> Name Type Description <code>Resource</code> <code>Resource</code> <p>Each resource matching the search criteria</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Search for all resources with \"invoice\" in the name\n&gt;&gt;&gt; for resource in uipath.resource_catalog.search(name=\"invoice\"):\n...     print(f\"{resource.name}: {resource.resource_type}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Search for specific resource types\n&gt;&gt;&gt; for resource in uipath.resource_catalog.search(\n...     resource_types=[ResourceType.ASSET]\n... ):\n...     print(resource.name)\n</code></pre>"},{"location":"core/resource_catalog/#uipath.platform.resource_catalog._resource_catalog_service.ResourceCatalogService.search_async","title":"search_async  <code>async</code>","text":"<pre><code>search_async(\n    *,\n    name=None,\n    resource_types=None,\n    resource_sub_types=None,\n    page_size=_DEFAULT_PAGE_SIZE,\n)\n</code></pre> <p>Asynchronously search for tenant scoped resources and folder scoped resources (accessible to the user).</p> <p>This method automatically handles pagination and yields resources one by one.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional name filter for resources</p> <code>None</code> <code>resource_types</code> <code>list[ResourceType] | None</code> <p>Optional list of resource types to filter by</p> <code>None</code> <code>resource_sub_types</code> <code>list[str] | None</code> <p>Optional list of resource subtypes to filter by</p> <code>None</code> <code>page_size</code> <code>int</code> <p>Number of resources to fetch per API call (default: 20, max: 100)</p> <code>_DEFAULT_PAGE_SIZE</code> <p>Yields:</p> Name Type Description <code>Resource</code> <code>AsyncIterator[Resource]</code> <p>Each resource matching the search criteria</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Search for all resources with \"invoice\" in the name\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.search_async(name=\"invoice\"):\n...     print(f\"{resource.name}: {resource.resource_type}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Search for specific resource types\n&gt;&gt;&gt; async for resource in uipath.resource_catalog.search_async(\n...     resource_types=[ResourceType.ASSET]\n... ):\n...     print(resource.name)\n</code></pre>"},{"location":"core/tasks/","title":"Tasks","text":""},{"location":"core/tasks/#uipath.platform.action_center._tasks_service.TasksService","title":"TasksService","text":"<p>Service for managing UiPath Action Center tasks.</p> <p>Tasks are task-based automation components that can be integrated into applications and processes. They represent discrete units of work that can be triggered and monitored through the UiPath API.</p> <p>This service provides methods to create and retrieve tasks, supporting both app-specific and generic tasks. It inherits folder context management capabilities from FolderContext.</p> <p>Reference: https://docs.uipath.com/automation-cloud/docs/actions</p>"},{"location":"core/tasks/#uipath.platform.action_center._tasks_service.TasksService.create","title":"create","text":"<pre><code>create(\n    title,\n    data=None,\n    *,\n    app_name=None,\n    app_key=None,\n    app_folder_path=None,\n    app_folder_key=None,\n    assignee=None,\n    recipient=None,\n    priority=None,\n    labels=None,\n    is_actionable_message_enabled=None,\n    actionable_message_metadata=None,\n    source_name=\"Agent\",\n)\n</code></pre> <p>Creates a new task synchronously.</p> <p>This method creates a new action task in UiPath Orchestrator. The action can be either app-specific (using app_name or app_key) or a generic action.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The title of the action</p> required <code>data</code> <code>dict[str, Any] | None</code> <p>Optional dictionary containing input data for the action</p> <code>None</code> <code>app_name</code> <code>str | None</code> <p>The name of the application (if creating an app-specific action)</p> <code>None</code> <code>app_key</code> <code>str | None</code> <p>The key of the application (if creating an app-specific action)</p> <code>None</code> <code>app_folder_path</code> <code>str | None</code> <p>Optional folder path for the action</p> <code>None</code> <code>app_folder_key</code> <code>str | None</code> <p>Optional folder key for the action</p> <code>None</code> <code>assignee</code> <code>str | None</code> <p>Optional username or email to assign the task to</p> <code>None</code> <code>priority</code> <code>str | None</code> <p>Optional priority of the task</p> <code>None</code> <code>labels</code> <code>list[str] | None</code> <p>Optional list of labels for the task</p> <code>None</code> <code>is_actionable_message_enabled</code> <code>bool | None</code> <p>Optional boolean indicating  whether actionable notifications are enabled for this task</p> <code>None</code> <code>actionable_message_metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata for the action</p> <code>None</code> <code>source_name</code> <code>str</code> <p>The name of the source that created the task. Defaults to 'Agent'.</p> <code>'Agent'</code> <p>Returns:</p> Name Type Description <code>Action</code> <code>Task</code> <p>The created action object</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If neither app_name nor app_key is provided for app-specific actions</p>"},{"location":"core/tasks/#uipath.platform.action_center._tasks_service.TasksService.create_async","title":"create_async  <code>async</code>","text":"<pre><code>create_async(\n    title,\n    data=None,\n    *,\n    app_name=None,\n    app_key=None,\n    app_folder_path=None,\n    app_folder_key=None,\n    assignee=None,\n    recipient=None,\n    priority=None,\n    labels=None,\n    is_actionable_message_enabled=None,\n    actionable_message_metadata=None,\n    source_name=\"Agent\",\n)\n</code></pre> <p>Creates a new action asynchronously.</p> <p>This method creates a new action task in UiPath Orchestrator. The action can be either app-specific (using app_name or app_key) or a generic action.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The title of the action</p> required <code>data</code> <code>dict[str, Any] | None</code> <p>Optional dictionary containing input data for the action</p> <code>None</code> <code>app_name</code> <code>str | None</code> <p>The name of the application (if creating an app-specific action)</p> <code>None</code> <code>app_key</code> <code>str | None</code> <p>The key of the application (if creating an app-specific action)</p> <code>None</code> <code>app_folder_path</code> <code>str | None</code> <p>Optional folder path for the action</p> <code>None</code> <code>app_folder_key</code> <code>str | None</code> <p>Optional folder key for the action</p> <code>None</code> <code>assignee</code> <code>str | None</code> <p>Optional username or email to assign the task to</p> <code>None</code> <code>priority</code> <code>str | None</code> <p>Optional priority of the task</p> <code>None</code> <code>labels</code> <code>list[str] | None</code> <p>Optional list of labels for the task</p> <code>None</code> <code>is_actionable_message_enabled</code> <code>bool | None</code> <p>Optional boolean indicating whether actionable notifications are enabled for this task</p> <code>None</code> <code>actionable_message_metadata</code> <code>dict[str, Any] | None</code> <p>Optional metadata for the action</p> <code>None</code> <code>source_name</code> <code>str</code> <p>The name of the source that created the task. Defaults to 'Agent'.</p> <code>'Agent'</code> <p>Returns:</p> Name Type Description <code>Action</code> <code>Task</code> <p>The created action object</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If neither app_name nor app_key is provided for app-specific actions</p>"},{"location":"core/tasks/#uipath.platform.action_center._tasks_service.TasksService.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    action_key,\n    app_folder_path=\"\",\n    app_folder_key=\"\",\n    app_name=None,\n)\n</code></pre> <p>Retrieves a task by its key synchronously.</p> <p>Parameters:</p> Name Type Description Default <code>action_key</code> <code>str</code> <p>The unique identifier of the task to retrieve</p> required <code>app_folder_path</code> <code>str</code> <p>Optional folder path for the task</p> <code>''</code> <code>app_folder_key</code> <code>str</code> <p>Optional folder key for the task</p> <code>''</code> <code>app_name</code> <code>str | None</code> <p>app name hint for resource override</p> <code>None</code> <p>Returns:     Task: The retrieved task object</p>"},{"location":"core/tasks/#uipath.platform.action_center._tasks_service.TasksService.retrieve_async","title":"retrieve_async  <code>async</code>","text":"<pre><code>retrieve_async(\n    action_key,\n    app_folder_path=\"\",\n    app_folder_key=\"\",\n    app_name=None,\n)\n</code></pre> <p>Retrieves a task by its key asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>action_key</code> <code>str</code> <p>The unique identifier of the task to retrieve</p> required <code>app_folder_path</code> <code>str</code> <p>Optional folder path for the task</p> <code>''</code> <code>app_folder_key</code> <code>str</code> <p>Optional folder key for the task</p> <code>''</code> <code>app_name</code> <code>str | None</code> <p>app name hint for resource override</p> <code>None</code> <p>Returns:     Task: The retrieved task object</p>"},{"location":"core/traced/","title":"Tracing","text":"<p>The <code>traced()</code> decorator enables automatic tracing of function calls, inputs, and outputs. It is designed to help you monitor, debug, and audit your code by capturing detailed information about function executions, including arguments, return values, and exceptions.</p> <p>You can view the traces of an Orchestrator job by going to the Jobs page, click a job, a side panel will open, and they will be available under the <code>Trace</code> tab. These can also be seen in UiPath Maestro when your agent is part of a larger process orchestration.</p>"},{"location":"core/traced/#usage","title":"Usage","text":"<p>Apply the <code>@traced()</code> decorator to any function (sync, async, generator, or async generator) to automatically record its execution as a trace span.</p> <pre><code>from uipath.tracing import traced\n\n@traced()\ndef my_function(x, y):\n    return x + y\n\n@traced(name=\"custom_span\", run_type=\"my_type\")\nasync def my_async_function(a, b):\n    return a * b\n</code></pre>"},{"location":"core/traced/#parameters","title":"Parameters","text":"Parameter Type Description name Optional[str] Custom name for the trace span. Defaults to the function name. run_type Optional[str] Category for the run (e.g., \"uipath\"). Useful for filtering traces. span_type Optional[str] Custom type for the span. Defaults to function type (sync/async/generator). input_processor Optional[Callable[[dict], dict]] Function to process/transform inputs before recording. Receives a dict of arguments. output_processor Optional[Callable[[Any], Any]] Function to process/transform outputs before recording. Receives the function's return value. hide_input bool If True, input data is redacted in the trace for privacy/security. hide_output bool If True, output data is redacted in the trace for privacy/security."},{"location":"core/traced/#input-and-output-processors","title":"Input and Output Processors","text":"<p>Processors allow you to mask, redact, or transform sensitive data before it is recorded in the trace. For example:</p> <pre><code>def mask_inputs(inputs):\n    inputs = inputs.copy()\n    if 'password' in inputs:\n        inputs['password'] = '***REDACTED***'\n    return inputs\n\ndef anonymize_output(output):\n    if isinstance(output, dict) and 'email' in output:\n        output = output.copy()\n        output['email'] = 'anonymous@example.com'\n    return output\n\n@traced(input_processor=mask_inputs, output_processor=anonymize_output)\ndef login(user, password):\n    # ...\n    return {\"email\": user + \"@example.com\"}\n</code></pre>"},{"location":"core/traced/#privacy-controls","title":"Privacy Controls","text":"<ul> <li>Set <code>hide_input=True</code> to prevent input data from being logged.</li> <li>Set <code>hide_output=True</code> to prevent output data from being logged.</li> </ul> <pre><code>@traced(hide_input=True, hide_output=True)\ndef sensitive_operation(secret):\n    ...\n</code></pre>"},{"location":"core/traced/#supported-function-types","title":"Supported Function Types","text":"<ul> <li>Regular functions (sync/async)</li> <li>Generator functions (sync/async)</li> </ul>"},{"location":"core/traced/#example-with-plain-python-agents","title":"Example with plain python agents","text":"<p>When used with plain python agents please call <code>wait_for_tracers()</code> at the end of the script to ensure all traces are sent, if this is not called the agent could end without sending all the traces.</p> <pre><code>from uipath.tracing import traced, wait_for_tracers\n\n@traced(name=\"process_payment\", run_type=\"payment\", hide_input=True)\ndef process_payment(card_number, amount):\n    # Sensitive input will not be logged\n    return {\"status\": \"success\", \"amount\": amount}\n\n@traced()\ndef main():\n    process_payment()\n\ndef main_wait_traces():\n    try:\n        main()\n    finally:\n        # this needs to be called after the last `traced` function is done\n        # to ensure the trace associated with main is saved\n        wait_for_tracers()\n\nif __name__ == \"__main__\":\n    main_wait_traces()\n</code></pre>"},{"location":"core/traced/#example-with-langchain-agents","title":"Example with langchain agents","text":"<p>When using <code>uipath-langchain</code> there is no need to call wait_for_tracers our framework will ensure that is called.</p> <pre><code>@traced()\ndef my_custom_traced_function(input: str) -&gt; str:\n    return { \"x\": \"some-output\" }\n</code></pre> <p>You can also use <code>@traceable()</code> attribute from langchain, but we recommend using <code>@traced()</code> attribute instead.</p> <pre><code>@traceable()\n# @traced()  ---&gt; do not use both at the same time or it will duplicate spans.\ndef my_custom_traced_function(input: str) -&gt; str:\n    return { \"x\": \"some-output\" }\n</code></pre>"},{"location":"eval/","title":"Agent Evaluations","text":"<p>The UiPath SDK provides a comprehensive evaluation framework for assessing agent performance and behavior. This framework enables you to systematically measure and validate agent outputs, execution trajectories, and tool usage patterns.</p>"},{"location":"eval/#overview","title":"Overview","text":"<p>The evaluation framework consists of two main categories of evaluators, organized by what they evaluate:</p>"},{"location":"eval/#output-based-evaluators","title":"Output-Based Evaluators","text":"<p>These evaluators assess the final output/result produced by an agent:</p> <ul> <li>Contains Evaluator: Checks if the output contains specific text</li> <li>Exact Match Evaluator: Verifies exact string matching</li> <li>JSON Similarity Evaluator: Measures structural similarity between JSON outputs</li> <li>LLM Judge Output Evaluator: Uses LLM for semantic output evaluation and quality assessment</li> </ul>"},{"location":"eval/#trajectory-based-evaluators","title":"Trajectory-Based Evaluators","text":"<p>These evaluators assess the execution path, decision-making process, and tool usage patterns during agent execution:</p> <ul> <li>Tool Call Order Evaluator: Validates the sequence in which tools are called</li> <li>Tool Call Count Evaluator: Verifies the frequency of tool calls</li> <li>Tool Call Args Evaluator: Checks tool call arguments for correctness</li> <li>Tool Call Output Evaluator: Validates the outputs returned by tool calls</li> <li>LLM Judge Trajectory Evaluator: Evaluates agent execution trajectories and decision-making with LLM judgment</li> </ul>"},{"location":"eval/#custom-evaluators","title":"Custom Evaluators","text":"<p>When built-in evaluators don't meet your specific needs, you can create custom evaluators with your own logic.</p> <p>Custom evaluators enable:</p> <ul> <li>Domain-specific validation: Implement validation logic tailored to your industry or use case</li> <li>Complex scoring algorithms: Use specialized algorithms like Jaccard similarity, Levenshtein distance, or custom metrics</li> <li>Tool call inspection: Extract and validate data from specific tool calls in the agent trace</li> <li>Integration with external systems: Connect to databases, APIs, or other validation services</li> </ul> <p>See Custom Python Evaluators for detailed implementation guide, including:</p> <ul> <li>Creating evaluator classes with proper type annotations</li> <li>Implementing custom evaluation criteria and configuration</li> <li>Extracting data from agent traces and tool calls</li> <li>Registering evaluators with the CLI</li> <li>Complete examples and best practices</li> </ul>"},{"location":"eval/#core-concepts","title":"Core Concepts","text":""},{"location":"eval/#evaluation-criteria","title":"Evaluation Criteria","text":"<p>Each evaluator uses specific criteria to define what should be evaluated. Criteria can be specified per test case or set as defaults in the evaluator configuration.</p>"},{"location":"eval/#evaluation-results","title":"Evaluation Results","text":"<p>Evaluators return a score (typically between 0 and 1) along with structured justification details. The justification type is determined by the evaluator's generic type parameter <code>J</code> and is always a <code>BaseEvaluatorJustification</code> subclass. The base class provides <code>expected</code> and <code>actual</code> fields, while specific evaluators extend it with additional fields (e.g., <code>LLMJudgeJustification</code> adds a <code>justification</code> field, <code>JsonSimilarityJustification</code> adds <code>matched_leaves</code>/<code>total_leaves</code>).</p>"},{"location":"eval/#configuration","title":"Configuration","text":"<p>Each evaluator has a configuration class that defines:</p> <ul> <li>name: The evaluator's identifier</li> <li>default_evaluation_criteria: Default criteria if not specified per test</li> <li>Evaluator-specific settings (e.g., <code>case_sensitive</code>, <code>strict</code>, <code>temperature</code>)</li> </ul>"},{"location":"eval/#getting-started","title":"Getting Started","text":"<p>To use an evaluator, you typically:</p> <ol> <li>Import the evaluator class</li> <li>Create an evaluator instance with configuration</li> <li>Call the <code>evaluate()</code> method with agent execution data and criteria</li> </ol> <pre><code>from uipath.eval.evaluators import ExactMatchEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Sample agent execution (this should be replaced with your agent run data)\nagent_execution = AgentExecution(\n    agent_input={\"query\": \"Greet the world\"},\n    agent_output={\"result\": \"hello, world!\"},\n    agent_trace=[],\n)\n\n# Create evaluator\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-1\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"case_sensitive\": False,\n        \"target_output_key\": \"result\",\n    }\n)\n\n# Evaluate\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"result\": \"Hello, World!\"}}\n)\n\nprint(f\"Score: {result.score}\")\n</code></pre>"},{"location":"eval/#best-practices","title":"Best Practices","text":"<ol> <li>Choose the right category:</li> </ol> <ul> <li>Use Output-Based Evaluators to validate what the agent produces (final results)</li> <li>Use Trajectory-Based Evaluators to validate how the agent achieves results (decision-making and tool usage)</li> </ul> <ol> <li>Select appropriate evaluators within categories:</li> </ol> <ul> <li>For outputs: Use deterministic evaluators (exact match, contains, JSON similarity) for predictable outputs and LLM judges for semantic/quality assessment</li> <li>For trajectories: Use tool call evaluators for specific validations and LLM judges for holistic behavior assessment</li> </ul> <ol> <li> <p>Combine multiple evaluators: Use different evaluators together for comprehensive evaluation (e.g., exact match for output + tool call order for trajectory)</p> </li> <li> <p>Set appropriate thresholds: Define minimum acceptable scores based on your use case</p> </li> <li> <p>Evaluate both outputs and trajectories: For complex agents, validate both what they produce and how they produce it</p> </li> <li> <p>Create custom evaluators when needed: If built-in evaluators don't cover your use case, implement custom evaluators with domain-specific logic</p> </li> </ol>"},{"location":"eval/#running-evaluations","title":"Running Evaluations","text":"<p>The UiPath SDK provides a CLI command to run evaluations against your agents. The evaluation framework automatically discovers your agent and evaluation sets, or you can specify them explicitly.</p>"},{"location":"eval/#basic-usage","title":"Basic Usage","text":"<pre><code># Auto-discover entrypoint and evaluation set\nuipath eval\n\n# Specify entrypoint and evaluation set\nuipath eval &lt;entrypoint&gt; &lt;eval-set-path&gt;\n\n# Run with parallel workers\nuipath eval --workers 4\n\n# Save results to file\nuipath eval --output-file results.json\n\n# Run specific evaluation IDs\nuipath eval --eval-ids \"['eval-1', 'eval-2']\"\n\n# Disable reporting to Studio Web\nuipath eval --no-report\n</code></pre>"},{"location":"eval/#command-options","title":"Command Options","text":"Option Type Description <code>entrypoint</code> Positional Path to agent script (optional, auto-discovered if not specified) <code>eval_set</code> Positional Path to evaluation set JSON file (optional, auto-discovered if not specified) <code>--eval-ids</code> List Specific evaluation IDs to run from the eval set <code>--eval-set-run-id</code> String Custom evaluation run ID (UUID generated if not provided) <code>--workers</code> Integer Number of parallel workers (default: 1) <code>--output-file</code> Path File path to save evaluation results <code>--no-report</code> Flag Disable reporting results to Studio Web"},{"location":"eval/#evaluation-sets","title":"Evaluation Sets","text":"<p>Evaluation sets are JSON files that define test cases and specify which evaluators to use:</p> <pre><code>{\n  \"version\": \"1.0\",\n  \"id\": \"my-eval-set\",\n  \"evaluatorRefs\": [\"exact-match-1\", \"MyCustomEvaluator\"],\n  \"evaluationItems\": [\n    {\n      \"id\": \"test-1\",\n      \"agentInput\": {\"query\": \"What is 2+2?\"},\n      \"evaluations\": [\n        {\n          \"evaluatorId\": \"exact-match-1\",\n          \"evaluationCriteria\": {\n            \"expectedOutput\": {\"result\": \"4\"}\n          }\n        },\n        {\n          \"evaluatorId\": \"MyCustomEvaluator\",\n          \"evaluationCriteria\": {\n            \"expectedValues\": [\"value1\", \"value2\"]\n          }\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"eval/#results","title":"Results","text":"<p>Evaluation results include:</p> <ul> <li>Score: Numeric score (typically 0.0 to 1.0) or boolean pass/fail</li> <li>Details: Structured justification for the evaluation (e.g., <code>BaseEvaluatorJustification</code> with <code>expected</code>/<code>actual</code> for deterministic evaluators, <code>JsonSimilarityJustification</code> with <code>matched_leaves</code>/<code>total_leaves</code>, or <code>LLMJudgeJustification</code> with <code>expected</code>/<code>actual</code>/<code>justification</code> for LLM judges)</li> <li>Metrics: Token usage, latency, and other execution metrics</li> <li>Trace: Full execution trace including tool calls and outputs</li> </ul> <p>Results can be viewed in:</p> <ul> <li>Console output: Real-time progress and summary</li> <li>Output file: JSON file with detailed results (use <code>--output-file</code>)</li> <li>Studio Web: Automatically reported if running in a Studio project (unless <code>--no-report</code> is specified)</li> </ul>"},{"location":"eval/#reference-documentation","title":"Reference Documentation","text":"<p>See the individual evaluator pages for detailed information on configuration, usage, and examples.</p>"},{"location":"eval/contains/","title":"Contains Evaluator","text":"<p>The Contains Evaluator checks whether the agent's output contains a specific search text. This is useful for validating that certain keywords, phrases, or patterns appear in the output without requiring an exact match.</p>"},{"location":"eval/contains/#overview","title":"Overview","text":"<p>Evaluator ID: <code>contains</code></p> <p>Use Cases:</p> <ul> <li>Verify specific keywords or phrases appear in output</li> <li>Check for presence of expected content</li> <li>Test that error messages or warnings contain specific text</li> <li>Validate outputs include required information</li> </ul> <p>Returns: Binary score (1.0 if found, 0.0 if not found) with <code>BaseEvaluatorJustification</code> details containing <code>expected</code> and <code>actual</code></p>"},{"location":"eval/contains/#configuration","title":"Configuration","text":"<p>Agent Output Structure</p> <p><code>agent_output</code> must always be a dictionary. When comparing, the value (or specific field via <code>target_output_key</code>) is converted to a string before checking if it contains the search text.</p>"},{"location":"eval/contains/#containsevaluatorconfig","title":"ContainsEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"ContainsEvaluator\"</code> The evaluator's name <code>case_sensitive</code> <code>bool</code> <code>False</code> Whether comparison is case-sensitive <code>negated</code> <code>bool</code> <code>False</code> If True, passes when text is NOT found <code>target_output_key</code> <code>str</code> <code>\"*\"</code> Specific key to extract from output (use \"*\" for entire output) <code>default_evaluation_criteria</code> <code>ContainsEvaluationCriteria or None</code> <code>None</code> Default criteria if not specified per test"},{"location":"eval/contains/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/contains/#containsevaluationcriteria","title":"ContainsEvaluationCriteria","text":"Parameter Type Description <code>search_text</code> <code>str</code> The text to search for in the output"},{"location":"eval/contains/#examples","title":"Examples","text":""},{"location":"eval/contains/#basic-usage","title":"Basic Usage","text":"<pre><code>from uipath.eval.evaluators import ContainsEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Sample agent execution\nagent_execution = AgentExecution(\n    agent_input={\"query\": \"What is the capital of France?\"},\n    agent_output={\"response\": \"The capital of France is Paris.\"},\n    agent_trace=[],\n)\n\n# Create evaluator - extracts \"response\" field for comparison\nevaluator = ContainsEvaluator(\n    id=\"contains-check\",\n    config={\n        \"name\": \"ContainsEvaluator\",\n        \"case_sensitive\": False,\n        \"target_output_key\": \"response\"  # Extract the \"response\" field\n    }\n)\n\n# Evaluate - searches in the \"response\" field value\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"search_text\": \"Paris\"}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/contains/#case-sensitive-search","title":"Case-Sensitive Search","text":"<pre><code># Sample agent execution\nagent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"message\": \"Hello World\"},\n    agent_trace=[],\n)\n\nevaluator = ContainsEvaluator(\n    id=\"contains-case-sensitive\",\n    config={\n        \"name\": \"ContainsEvaluator\",\n        \"case_sensitive\": True,\n        \"target_output_key\": \"message\"  # Extract the \"message\" field\n    }\n)\n\n# This will fail because of case mismatch\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"search_text\": \"hello\"}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 0.0\n</code></pre>"},{"location":"eval/contains/#negated-search","title":"Negated Search","text":"<p>Use negation to ensure specific text is NOT present:</p> <pre><code># Sample agent execution\nagent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"status\": \"Success: Operation completed\"},\n    agent_trace=[],\n)\n\nevaluator = ContainsEvaluator(\n    id=\"contains-negated\",\n    config={\n        \"name\": \"ContainsEvaluator\",\n        \"negated\": True,\n        \"target_output_key\": \"status\"  # Extract the \"status\" field\n    }\n)\n\n# Passes because \"error\" is NOT found\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"search_text\": \"error\"}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/contains/#target-specific-output-field","title":"Target Specific Output Field","text":"<pre><code># Sample agent execution\nagent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\n        \"status\": \"success\",\n        \"message\": \"User profile updated successfully\"\n    },\n    agent_trace=[],\n)\n\nevaluator = ContainsEvaluator(\n    id=\"contains-targeted\",\n    config={\n        \"name\": \"ContainsEvaluator\",\n        \"target_output_key\": \"message\"\n    }\n)\n\n# Only searches within the \"message\" field\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"search_text\": \"updated\"}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/contains/#result-details","title":"Result Details","text":"<p>The evaluator returns a <code>NumericEvaluationResult</code> with:</p> <ul> <li>score (<code>float</code>): 1.0 if search text is found, 0.0 otherwise (inverted when <code>negated=True</code>)</li> <li>details (<code>BaseEvaluatorJustification</code>): Structured justification containing:<ul> <li><code>expected</code> (<code>str</code>): The search text (after case normalization if applicable)</li> <li><code>actual</code> (<code>str</code>): The actual output value (after case normalization if applicable)</li> </ul> </li> </ul>"},{"location":"eval/contains/#best-practices","title":"Best Practices","text":"<ol> <li>Use case-insensitive matching by default to make tests more robust</li> <li>Combine with other evaluators for comprehensive validation</li> <li>Use negated mode to ensure error messages or sensitive data are NOT present</li> <li>Target specific fields when evaluating structured outputs to reduce false positives</li> <li>Remember substring matching - this evaluator uses substring search, not full-text search</li> </ol>"},{"location":"eval/contains/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Exact Match Evaluator: For exact string matching</li> <li>JSON Similarity Evaluator: For structural comparison</li> <li>LLM Judge Output Evaluator: For semantic similarity</li> </ul>"},{"location":"eval/custom_evaluators/","title":"Custom Python Evaluators","text":"<p>Custom Python Evaluators enable you to implement domain-specific evaluation logic tailored to your agent's unique requirements. When the built-in evaluators don't cover your specific use case, you can create custom evaluators with full control over the evaluation criteria and scoring logic.</p>"},{"location":"eval/custom_evaluators/#overview","title":"Overview","text":"<p>Use Cases:</p> <ul> <li>Domain-specific validation (e.g., healthcare data compliance, financial calculations)</li> <li>Complex multi-step verification logic</li> <li>Custom data extraction and comparison from tool calls</li> <li>Specialized scoring algorithms (e.g., Jaccard similarity, Levenshtein distance)</li> <li>Integration with external validation systems</li> </ul> <p>Returns: Any <code>EvaluationResult</code> type (<code>NumericEvaluationResult</code>, <code>BooleanEvaluationResult</code>, or <code>ErrorEvaluationResult</code>)</p>"},{"location":"eval/custom_evaluators/#project-structure","title":"Project Structure","text":"<p>Custom evaluators must follow this directory structure:</p> <pre><code>your-project/\n\u251c\u2500\u2500 evals/\n\u2502   \u251c\u2500\u2500 evaluators/\n\u2502   \u2502   \u251c\u2500\u2500 custom/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 your_evaluator.py       # Your evaluator implementation\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 another_evaluator.py    # Additional custom evaluators\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 types/                  # Auto-generated type schemas\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 your-evaluator-types.json\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 another-evaluator-types.json\n\u2502   \u2502   \u251c\u2500\u2500 your-evaluator.json         # Auto-generated evaluator config\n\u2502   \u2502   \u2514\u2500\u2500 another-evaluator.json\n\u2502   \u2514\u2500\u2500 eval_sets/\n\u2502       \u2514\u2500\u2500 your_eval_set.json\n\u2514\u2500\u2500 ...\n</code></pre> <p>Required Structure</p> <ul> <li>Custom evaluator files must be placed in <code>evals/evaluators/custom/</code> directory</li> <li>Each file should contain one or more evaluator classes inheriting from <code>BaseEvaluator</code></li> <li>The directory structure is enforced by the CLI tooling</li> </ul>"},{"location":"eval/custom_evaluators/#creating-a-custom-evaluator","title":"Creating a Custom Evaluator","text":""},{"location":"eval/custom_evaluators/#step-1-generate-template","title":"Step 1: Generate Template","text":"<p>Use the CLI to create a new evaluator template:</p> <pre><code>uipath add evaluator my-custom-evaluator\n</code></pre> <p>This creates <code>evals/evaluators/custom/my_custom_evaluator.py</code> with a template structure.</p>"},{"location":"eval/custom_evaluators/#step-2-implement-evaluation-logic","title":"Step 2: Implement Evaluation Logic","text":"<p>A custom evaluator consists of three main components:</p>"},{"location":"eval/custom_evaluators/#1-evaluation-criteria-class","title":"1. Evaluation Criteria Class","text":"<p>Define the criteria that will be used to evaluate agent executions. This should contain only test-specific data like expected outputs:</p> <pre><code>from pydantic import Field\nfrom uipath.eval.evaluators import BaseEvaluationCriteria\n\nclass MyEvaluationCriteria(BaseEvaluationCriteria):\n    \"\"\"Criteria for my custom evaluator.\"\"\"\n\n    expected_values: list[str] = Field(default_factory=list)\n</code></pre>"},{"location":"eval/custom_evaluators/#2-evaluator-configuration-class","title":"2. Evaluator Configuration Class","text":"<p>Define configuration options for your evaluator. This should contain behavioral settings like thresholds, modes, etc.:</p> <pre><code>from uipath.eval.evaluators import BaseEvaluatorConfig\n\nclass MyEvaluatorConfig(BaseEvaluatorConfig[MyEvaluationCriteria]):\n    \"\"\"Configuration for my custom evaluator.\"\"\"\n\n    name: str = \"MyCustomEvaluator\"\n    threshold: float = 0.8  # Minimum score to consider passing\n    case_sensitive: bool = False  # Whether comparison is case-sensitive\n    # Optional: set default criteria\n    # default_evaluation_criteria: MyEvaluationCriteria | None = None\n</code></pre>"},{"location":"eval/custom_evaluators/#3-evaluator-implementation-class","title":"3. Evaluator Implementation Class","text":"<p>Implement the core evaluation logic:</p> <pre><code>from uipath.eval.evaluators import BaseEvaluator\nfrom uipath.eval.evaluators.base_evaluator import BaseEvaluatorJustification\nfrom uipath.eval.models import AgentExecution, NumericEvaluationResult\n\nclass MyCustomEvaluator(\n    BaseEvaluator[MyEvaluationCriteria, MyEvaluatorConfig, BaseEvaluatorJustification]\n):\n    \"\"\"Custom evaluator with domain-specific logic.\n\n    This evaluator performs custom validation on agent outputs\n    by comparing extracted data against expected values.\n    \"\"\"\n\n    async def evaluate(\n        self,\n        agent_execution: AgentExecution,\n        evaluation_criteria: MyEvaluationCriteria\n    ) -&gt; NumericEvaluationResult:\n        \"\"\"Evaluate the agent execution against criteria.\n\n        Args:\n            agent_execution: The agent execution containing:\n                - agent_input: Input received by the agent\n                - agent_output: Output produced by the agent\n                - agent_trace: OpenTelemetry spans with execution trace\n                - simulation_instructions: Simulation instructions\n            evaluation_criteria: Criteria to evaluate against\n\n        Returns:\n            EvaluationResult with score and details\n        \"\"\"\n        # Extract data from agent execution\n        actual_values = self._extract_values(agent_execution)\n        expected_values = evaluation_criteria.expected_values\n\n        # Apply case sensitivity from config\n        if not self.evaluator_config.case_sensitive:\n            actual_values = [v.lower() for v in actual_values]\n            expected_values = [v.lower() for v in expected_values]\n\n        # Compute score\n        score = self._compute_similarity(actual_values, expected_values)\n\n        # Check against threshold from config\n        passed = score &gt;= self.evaluator_config.threshold\n\n        return NumericEvaluationResult(\n            score=score,\n            details=self.validate_justification({\n                \"expected\": str(expected_values),\n                \"actual\": str(actual_values),\n            }),\n        )\n\n    def _extract_values(self, agent_execution: AgentExecution) -&gt; list[str]:\n        \"\"\"Extract values from agent execution (implement your logic).\"\"\"\n        # Your custom extraction logic here\n        return []\n\n    def _compute_similarity(\n        self, actual: list[str], expected: list[str]\n    ) -&gt; float:\n        \"\"\"Compute similarity score (implement your logic).\"\"\"\n        # Your custom scoring logic here\n        return 0.0\n\n    @classmethod\n    def get_evaluator_id(cls) -&gt; str:\n        \"\"\"Get the unique evaluator identifier.\n\n        Returns:\n            The evaluator ID (must be unique across all evaluators)\n        \"\"\"\n        return \"MyCustomEvaluator\"\n</code></pre>"},{"location":"eval/custom_evaluators/#step-3-register-the-evaluator","title":"Step 3: Register the Evaluator","text":"<p>Register your evaluator to generate the configuration files:</p> <pre><code>uipath register evaluator my_custom_evaluator.py\n</code></pre> <p>This command:</p> <ol> <li>Validates your evaluator implementation</li> <li>Generates <code>evals/evaluators/custom/types/my-custom-evaluator-types.json</code> with type schemas</li> <li>Creates <code>evals/evaluators/my-custom-evaluator.json</code> with evaluator configuration</li> </ol> <p>The generated configuration file will contain:</p> <pre><code>{\n  \"version\": \"1.0\",\n  \"id\": \"MyCustomEvaluator\",\n  \"evaluatorTypeId\": \"file://types/my-custom-evaluator-types.json\",\n  \"evaluatorSchema\": \"file://my_custom_evaluator.py:MyCustomEvaluator\",\n  \"description\": \"Custom evaluator with domain-specific logic...\",\n  \"evaluatorConfig\": {\n    \"name\": \"MyCustomEvaluator\",\n    \"threshold\": 0.8,\n    \"caseSensitive\": false\n  }\n}\n</code></pre> <p>Evaluator Schema Format</p> <ul> <li><code>evaluatorTypeId</code>: Format is <code>file://types/&lt;kebab-case-name&gt;-types.json</code> - points to the generated type schema</li> <li><code>evaluatorSchema</code>: Format is <code>file://&lt;filename&gt;.py:&lt;ClassName&gt;</code> - tells the runtime where to load your custom evaluator class from</li> </ul> <p>The <code>file://</code> prefix indicates these are local file references that will be resolved relative to the <code>evals/evaluators/custom/</code> directory.</p>"},{"location":"eval/custom_evaluators/#step-4-use-in-evaluation-sets","title":"Step 4: Use in Evaluation Sets","text":"<p>Reference your custom evaluator in evaluation sets:</p> <pre><code>{\n  \"version\": \"1.0\",\n  \"id\": \"my-eval-set\",\n  \"evaluatorRefs\": [\"MyCustomEvaluator\"],\n  \"evaluationItems\": [\n    {\n      \"id\": \"test-1\",\n      \"agentInput\": {\"query\": \"Process data\"},\n      \"evaluations\": [\n        {\n          \"evaluatorId\": \"MyCustomEvaluator\",\n          \"evaluationCriteria\": {\n            \"expectedValues\": [\"value1\", \"value2\"]\n          }\n        }\n      ]\n    }\n  ]\n}\n</code></pre> <p>Criteria vs Config</p> <ul> <li>evaluationCriteria: Test-specific data (e.g., <code>expectedValues</code>) - varies per test case</li> <li>evaluatorConfig: Behavioral settings (e.g., <code>threshold</code>, <code>caseSensitive</code>) - set once in the evaluator JSON file</li> </ul>"},{"location":"eval/custom_evaluators/#working-with-agent-traces","title":"Working with Agent Traces","text":"<p>Custom evaluators often need to extract information from tool calls in the agent execution trace. The SDK provides helper functions for common operations.</p>"},{"location":"eval/custom_evaluators/#extracting-tool-calls","title":"Extracting Tool Calls","text":"<pre><code>from uipath.eval._helpers.evaluators_helpers import extract_tool_calls\n\ndef _process_tool_calls(self, agent_execution: AgentExecution) -&gt; list[str]:\n    \"\"\"Extract and process tool calls from the execution trace.\"\"\"\n    tool_calls = extract_tool_calls(agent_execution.agent_trace)\n\n    results = []\n    for tool_call in tool_calls:\n        # Access tool name\n        tool_name = tool_call.name\n\n        # Access tool arguments\n        args = tool_call.args or {}\n\n        if tool_name == \"SpecificTool\":\n            # Extract specific data from arguments\n            data = args.get(\"parameter_name\", \"\")\n            results.append(data)\n\n    return results\n</code></pre>"},{"location":"eval/custom_evaluators/#available-helper-functions","title":"Available Helper Functions","text":"<pre><code>from uipath.eval._helpers.evaluators_helpers import (\n    extract_tool_calls,          # Extract tool calls with arguments\n    extract_tool_calls_names,     # Extract just tool names\n    extract_tool_calls_outputs,   # Extract tool outputs\n    trace_to_str,                 # Convert trace to string representation\n)\n</code></pre>"},{"location":"eval/custom_evaluators/#complete-example","title":"Complete Example","text":"<p>Here's a complete example based on real-world usage that compares data patterns using Jaccard similarity:</p> <pre><code>\"\"\"Custom evaluator for pattern comparison.\"\"\"\n\nfrom pydantic import Field\nfrom uipath.eval.evaluators import BaseEvaluator\nfrom uipath.eval.evaluators.base_evaluator import (\n    BaseEvaluationCriteria,\n    BaseEvaluatorConfig,\n    BaseEvaluatorJustification,\n)\nfrom uipath.eval.models import EvaluationResult, NumericEvaluationResult\nfrom uipath.eval.models import AgentExecution\nfrom uipath.eval._helpers.evaluators_helpers import extract_tool_calls\n\n\ndef _compute_jaccard_similarity(expected: list[str], actual: list[str]) -&gt; float:\n    \"\"\"Compute Jaccard similarity (intersection over union).\n\n    Returns 1.0 when both expected and actual are empty (perfect match).\n    \"\"\"\n    expected_set = set(expected) if expected else set()\n    actual_set = set(actual) if actual else set()\n\n    # If both are empty, that's a perfect match\n    if len(expected_set) == 0 and len(actual_set) == 0:\n        return 1.0\n\n    intersection = len(expected_set.intersection(actual_set))\n    union = len(expected_set.union(actual_set))\n    return intersection / union if union &gt; 0 else 0.0\n\n\nclass PatternEvaluatorCriteria(BaseEvaluationCriteria):\n    \"\"\"Evaluation criteria for pattern evaluator.\"\"\"\n\n    expected_output: list[str] = Field(default_factory=list)\n\n\nclass PatternEvaluatorConfig(BaseEvaluatorConfig[PatternEvaluatorCriteria]):\n    \"\"\"Configuration for pattern evaluator.\"\"\"\n\n    name: str = \"PatternComparisonEvaluator\"\n\n\nclass PatternComparisonEvaluator(\n    BaseEvaluator[PatternEvaluatorCriteria, PatternEvaluatorConfig, BaseEvaluatorJustification]\n):\n    \"\"\"Custom evaluator for pattern comparison.\n\n    Extends BaseEvaluator to extract data from specific tool calls and\n    validates patterns found against expected patterns using Jaccard\n    similarity (intersection over union).\n    \"\"\"\n\n    async def evaluate(\n        self,\n        agent_execution: AgentExecution,\n        evaluation_criteria: PatternEvaluatorCriteria\n    ) -&gt; EvaluationResult:\n        \"\"\"Evaluate the pattern comparison.\n\n        Args:\n            agent_execution: The agent execution containing trace data\n            evaluation_criteria: Expected output patterns\n\n        Returns:\n            EvaluationResult with score (0.0 to 1.0) based on Jaccard similarity\n        \"\"\"\n        expected_output = evaluation_criteria.expected_output\n\n        # Extract actual output from tool calls\n        actual_output = self._extract_patterns(agent_execution)\n\n        # Compute score using intersection over union\n        score = _compute_jaccard_similarity(expected_output, actual_output)\n\n        return NumericEvaluationResult(\n            score=score,\n            details=self.validate_justification({\n                \"expected\": str(expected_output),\n                \"actual\": str(actual_output),\n            }),\n        )\n\n    def _extract_patterns(self, agent_execution: AgentExecution) -&gt; list[str]:\n        \"\"\"Extract patterns from tool calls.\n\n        Args:\n            agent_execution: The agent execution containing trace data\n\n        Returns:\n            List of pattern strings found\n        \"\"\"\n        # Extract tool calls with arguments using the helper function\n        tool_calls = extract_tool_calls(agent_execution.agent_trace)\n\n        for tool_call in tool_calls:\n            if tool_call.name == \"DataProcessingTool\":\n                args = tool_call.args or {}\n                file_name = str(args.get(\"FileName\", \"\"))\n                if file_name.startswith(\"PatternData\"):\n                    input_data = str(args.get(\"InputData\", \"\"))\n                    if input_data:\n                        lines = input_data.split(\"\\n\")\n                        # Extract and process patterns (custom logic)\n                        patterns = [line.strip() for line in lines[1:] if line.strip()]\n                        return patterns\n\n        return []\n\n    @classmethod\n    def get_evaluator_id(cls) -&gt; str:\n        \"\"\"Get the evaluator type ID.\n\n        Returns:\n            The evaluator type identifier\n        \"\"\"\n        return \"PatternComparisonEvaluator\"\n</code></pre>"},{"location":"eval/custom_evaluators/#best-practices","title":"Best Practices","text":""},{"location":"eval/custom_evaluators/#1-type-annotations-and-documentation","title":"1. Type Annotations and Documentation","text":"<p>Always include complete type annotations and Google-style docstrings:</p> <pre><code>def _extract_data(\n    self,\n    agent_execution: AgentExecution,\n    tool_name: str\n) -&gt; list[str]:\n    \"\"\"Extract data from specific tool calls.\n\n    Args:\n        agent_execution: The agent execution to process\n        tool_name: The name of the tool to extract data from\n\n    Returns:\n        List of extracted data strings\n\n    Raises:\n        ValueError: If the tool call format is invalid\n    \"\"\"\n    # Implementation\n</code></pre>"},{"location":"eval/custom_evaluators/#2-error-handling","title":"2. Error Handling","text":"<p>Use proper error handling and return meaningful results:</p> <pre><code>from uipath.eval.models import ErrorEvaluationResult\n\nasync def evaluate(\n    self,\n    agent_execution: AgentExecution,\n    evaluation_criteria: MyCriteria\n) -&gt; EvaluationResult:\n    \"\"\"Evaluate with error handling.\"\"\"\n    try:\n        # Your evaluation logic\n        score = self._compute_score(agent_execution)\n        return NumericEvaluationResult(score=score)\n    except Exception as e:\n        return ErrorEvaluationResult(\n            error=f\"Evaluation failed: {str(e)}\"\n        )\n</code></pre>"},{"location":"eval/custom_evaluators/#3-reusable-helper-methods","title":"3. Reusable Helper Methods","text":"<p>Extract common logic into reusable helper methods:</p> <pre><code>def _extract_from_tool(\n    self,\n    agent_execution: AgentExecution,\n    tool_name: str,\n    parameter_name: str\n) -&gt; str:\n    \"\"\"Reusable method to extract parameter from tool calls.\"\"\"\n    tool_calls = extract_tool_calls(agent_execution.agent_trace)\n    for tool_call in tool_calls:\n        if tool_call.name == tool_name:\n            args = tool_call.args or {}\n            return str(args.get(parameter_name, \"\"))\n    return \"\"\n</code></pre>"},{"location":"eval/custom_evaluators/#4-clear-scoring-logic","title":"4. Clear Scoring Logic","text":"<p>Make your scoring logic explicit and well-documented, using config values appropriately:</p> <pre><code>def _compute_score(\n    self,\n    actual: list[str],\n    expected: list[str]\n) -&gt; float:\n    \"\"\"Compute evaluation score.\n\n    Scoring algorithm:\n    - 1.0: Perfect match (all expected items found)\n    - 0.5-0.99: Partial match (some items found)\n    - 0.0: No match (no items found)\n\n    Uses the case_sensitive setting from evaluator config.\n\n    Args:\n        actual: Actual values extracted from execution\n        expected: Expected values from criteria\n\n    Returns:\n        Score between 0.0 and 1.0\n    \"\"\"\n    if not expected:\n        return 1.0 if not actual else 0.0\n\n    # Apply case sensitivity from config\n    if not self.evaluator_config.case_sensitive:\n        actual = [v.lower() for v in actual]\n        expected = [v.lower() for v in expected]\n\n    matches = len(set(actual).intersection(set(expected)))\n    return matches / len(expected)\n</code></pre>"},{"location":"eval/custom_evaluators/#5-detailed-results","title":"5. Detailed Results","text":"<p>Provide detailed information in evaluation results using <code>validate_justification()</code>. This method uses the generic type annotations to coerce your data into the correct justification type:</p> <pre><code># For BaseEvaluatorJustification (recommended) - pass a dict with expected/actual fields\nreturn NumericEvaluationResult(\n    score=score,\n    details=self.validate_justification({\n        \"expected\": str(expected_values),\n        \"actual\": str(actual_values),\n    }),\n)\n\n# For custom BaseEvaluatorJustification subclass - pass a dict with all fields\n# (requires a BaseEvaluatorJustification subclass as J parameter)\nreturn NumericEvaluationResult(\n    score=score,\n    details=self.validate_justification({\n        \"expected\": str(expected_values),\n        \"actual\": str(actual_values),\n        \"matches\": matching_items,\n    }),\n)\n\n# For str justification (not recommended) - pass a plain string\nreturn NumericEvaluationResult(\n    score=score,\n    details=self.validate_justification(\n        f\"Found {len(actual_values)}/{len(expected_values)} expected values\"\n    ),\n)\n</code></pre>"},{"location":"eval/custom_evaluators/#generic-type-parameters","title":"Generic Type Parameters","text":"<p>Custom evaluators use three generic type parameters in the class signature:</p> <pre><code>class MyEvaluator(BaseEvaluator[T, C, J]):\n    \"\"\"\n    T: Evaluation criteria type (subclass of BaseEvaluationCriteria)\n    C: Configuration type (subclass of BaseEvaluatorConfig[T])\n    J: Justification type (BaseEvaluatorJustification, a subclass of it, or str)\n    \"\"\"\n</code></pre> <p>Common patterns:</p> <ul> <li><code>BaseEvaluator[MyCriteria, MyConfig, BaseEvaluatorJustification]</code> - Recommended. Returns base justification with <code>expected</code> and <code>actual</code> fields</li> <li><code>BaseEvaluator[MyCriteria, MyConfig, MyJustification]</code> - Custom justification (subclass of <code>BaseEvaluatorJustification</code>) with additional fields beyond <code>expected</code>/<code>actual</code></li> <li><code>BaseEvaluator[MyCriteria, MyConfig, str]</code> - Simple string justification (not recommended \u2014 prefer typed justifications that carry <code>expected</code>/<code>actual</code> so evaluation results are self-describing)</li> </ul> <p>Prefer typed justifications</p> <p>Using <code>BaseEvaluatorJustification</code> (or a subclass) instead of <code>str</code> ensures every evaluation result contains structured <code>expected</code> and <code>actual</code> fields, making results easier to interpret and aggregate programmatically.</p> <p>The justification type is resolved at runtime from the generic annotations and used by <code>validate_justification()</code> to coerce raw data (dicts or strings) into the correct type. This means evaluators should pass raw data to <code>self.validate_justification()</code> rather than manually instantiating justification types.</p>"},{"location":"eval/custom_evaluators/#testing-custom-evaluators","title":"Testing Custom Evaluators","text":"<p>Test your evaluators locally before registration:</p> <pre><code>import pytest\nfrom uipath.eval.models import AgentExecution\n\n@pytest.mark.asyncio\nasync def test_custom_evaluator() -&gt; None:\n    \"\"\"Test custom evaluator logic.\"\"\"\n    # Create test data\n    agent_execution = AgentExecution(\n        agent_input={\"query\": \"test\"},\n        agent_output={\"result\": \"test output\"},\n        agent_trace=[],\n    )\n\n    # Create evaluator with config\n    evaluator = MyCustomEvaluator(\n        id=\"test-evaluator\",\n        config={\n            \"name\": \"MyCustomEvaluator\",\n            \"threshold\": 0.8,\n            \"case_sensitive\": False,\n        }\n    )\n\n    # Evaluate with criteria\n    criteria = MyEvaluationCriteria(expected_values=[\"value1\"])\n    result = await evaluator.evaluate(agent_execution, criteria)\n\n    # Assert\n    assert result.score &gt;= 0.0\n    assert result.score &lt;= 1.0\n</code></pre>"},{"location":"eval/custom_evaluators/#common-patterns","title":"Common Patterns","text":""},{"location":"eval/custom_evaluators/#pattern-1-extracting-data-from-specific-tools","title":"Pattern 1: Extracting Data from Specific Tools","text":"<pre><code>def _extract_from_specific_tool(\n    self, agent_execution: AgentExecution\n) -&gt; str:\n    \"\"\"Extract data from a specific tool call.\"\"\"\n    tool_calls = extract_tool_calls(agent_execution.agent_trace)\n\n    for tool_call in tool_calls:\n        if tool_call.name == \"TargetTool\":\n            args = tool_call.args or {}\n            return str(args.get(\"target_parameter\", \"\"))\n\n    return \"\"\n</code></pre>"},{"location":"eval/custom_evaluators/#pattern-2-computing-set-based-similarity","title":"Pattern 2: Computing Set-Based Similarity","text":"<pre><code>def _compute_set_similarity(\n    self, actual: list[str], expected: list[str]\n) -&gt; float:\n    \"\"\"Compute similarity using set operations.\"\"\"\n    actual_set = set(actual)\n    expected_set = set(expected)\n\n    if not expected_set:\n        return 1.0 if not actual_set else 0.0\n\n    intersection = len(actual_set.intersection(expected_set))\n    return intersection / len(expected_set)\n</code></pre>"},{"location":"eval/custom_evaluators/#pattern-3-multi-step-validation","title":"Pattern 3: Multi-Step Validation","text":"<pre><code>async def evaluate(\n    self,\n    agent_execution: AgentExecution,\n    evaluation_criteria: MyCriteria\n) -&gt; EvaluationResult:\n    \"\"\"Multi-step validation using config settings.\"\"\"\n    # Step 1: Validate structure (use strict mode from config)\n    if not self._validate_structure(agent_execution, self.evaluator_config.strict):\n        return NumericEvaluationResult(\n            score=0.0,\n            details=self.validate_justification({\n                \"expected\": str(evaluation_criteria.expected_data),\n                \"actual\": \"Invalid structure\",\n            }),\n        )\n\n    # Step 2: Extract data\n    data = self._extract_data(agent_execution)\n\n    # Step 3: Compare and score\n    score = self._compare_data(data, evaluation_criteria.expected_data)\n\n    # Step 4: Check against threshold from config\n    passed = score &gt;= self.evaluator_config.threshold\n\n    return NumericEvaluationResult(\n        score=score,\n        details=self.validate_justification({\n            \"expected\": str(evaluation_criteria.expected_data),\n            \"actual\": str(data),\n        }),\n    )\n</code></pre>"},{"location":"eval/custom_evaluators/#troubleshooting","title":"Troubleshooting","text":""},{"location":"eval/custom_evaluators/#evaluator-not-found","title":"Evaluator Not Found","text":"<p>Error: <code>Could not find '&lt;filename&gt;' in evals/evaluators/custom folder</code></p> <p>Solution: Ensure your evaluator file is in the correct directory:</p> <pre><code># Check file location\nls evals/evaluators/custom/\n\n# File should be: evals/evaluators/custom/my_evaluator.py\n</code></pre>"},{"location":"eval/custom_evaluators/#class-not-inheriting-from-baseevaluator","title":"Class Not Inheriting from BaseEvaluator","text":"<p>Error: <code>Could not find a class inheriting from BaseEvaluator in &lt;filename&gt;</code></p> <p>Solution: Verify your class properly inherits from <code>BaseEvaluator</code>:</p> <pre><code>from uipath.eval.evaluators import BaseEvaluator\n\nclass MyEvaluator(BaseEvaluator[...]):  # \u2713 Correct\n    pass\n\nclass MyEvaluator:  # \u2717 Wrong - missing inheritance\n    pass\n</code></pre>"},{"location":"eval/custom_evaluators/#missing-get_evaluator_id-method","title":"Missing get_evaluator_id Method","text":"<p>Error: <code>Error getting evaluator ID</code></p> <p>Solution: Implement the required <code>get_evaluator_id</code> class method:</p> <pre><code>@classmethod\ndef get_evaluator_id(cls) -&gt; str:\n    \"\"\"Get the evaluator ID.\"\"\"\n    return \"MyUniqueEvaluatorId\"\n</code></pre>"},{"location":"eval/custom_evaluators/#type-inconsistency","title":"Type Inconsistency","text":"<p>Error: <code>Type inconsistency in evaluator: Config expects criteria type X</code></p> <p>Solution: Ensure your config's generic parameter matches your evaluator's criteria type:</p> <pre><code># \u2713 Correct - matching types\nclass MyCriteria(BaseEvaluationCriteria):\n    pass\n\nclass MyConfig(BaseEvaluatorConfig[MyCriteria]):  # Uses MyCriteria\n    pass\n\nclass MyEvaluator(BaseEvaluator[MyCriteria, MyConfig, BaseEvaluatorJustification]):  # Also uses MyCriteria\n    pass\n\n# \u2717 Wrong - mismatched types\nclass MyEvaluator(BaseEvaluator[OtherCriteria, MyConfig, BaseEvaluatorJustification]):  # Mismatch!\n    pass\n</code></pre>"},{"location":"eval/custom_evaluators/#cli-commands-reference","title":"CLI Commands Reference","text":""},{"location":"eval/custom_evaluators/#create-new-evaluator","title":"Create New Evaluator","text":"<pre><code>uipath add evaluator &lt;evaluator-name&gt;\n</code></pre> <p>Creates a new evaluator template in <code>evals/evaluators/custom/</code>.</p>"},{"location":"eval/custom_evaluators/#register-evaluator","title":"Register Evaluator","text":"<pre><code>uipath register evaluator &lt;evaluator-file.py&gt;\n</code></pre> <p>Validates and generates configuration files for the evaluator.</p>"},{"location":"eval/custom_evaluators/#running-your-custom-evaluators","title":"Running Your Custom Evaluators","text":"<p>Once registered, your custom evaluators can be used in evaluation sets just like built-in evaluators. See the Evaluation Overview - Running Evaluations section for details on using the <code>uipath eval</code> command.</p>"},{"location":"eval/custom_evaluators/#related-documentation","title":"Related Documentation","text":"<ul> <li>Evaluation Overview: Understanding the evaluation framework and running evaluations</li> <li>Exact Match Evaluator: Example of a deterministic evaluator</li> <li>Tool Call Args Evaluator: Working with tool call data</li> <li>LLM Judge Output: LLM-based evaluation patterns</li> </ul>"},{"location":"eval/exact_match/","title":"Exact Match Evaluator","text":"<p>The Exact Match Evaluator performs exact string matching between the agent's output and expected output. This is the most strict deterministic evaluator, useful for scenarios where output must match exactly.</p>"},{"location":"eval/exact_match/#overview","title":"Overview","text":"<p>Evaluator ID: <code>exact-match</code></p> <p>Use Cases:</p> <ul> <li>Validate exact responses (e.g., status codes, IDs)</li> <li>Test deterministic outputs</li> <li>Ensure precise formatting is maintained</li> <li>Verify exact data values</li> </ul> <p>Returns: Binary score (1.0 if exact match, 0.0 otherwise) with <code>BaseEvaluatorJustification</code> details containing <code>expected</code> and <code>actual</code></p>"},{"location":"eval/exact_match/#configuration","title":"Configuration","text":"<p>Agent Output Structure</p> <p><code>agent_output</code> must always be a dictionary (e.g., <code>{\"result\": \"value\"}</code>). To evaluate simple values like strings or numbers, wrap them in a dict and use <code>target_output_key</code> to extract the specific field.</p>"},{"location":"eval/exact_match/#exactmatchevaluatorconfig","title":"ExactMatchEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"ExactMatchEvaluator\"</code> The evaluator's name <code>case_sensitive</code> <code>bool</code> <code>False</code> Whether comparison is case-sensitive <code>negated</code> <code>bool</code> <code>False</code> If True, passes when outputs do NOT match <code>target_output_key</code> <code>str</code> <code>\"*\"</code> Specific key to extract from output (use \"*\" for entire output) <code>default_evaluation_criteria</code> <code>OutputEvaluationCriteria or None</code> <code>None</code> Default criteria if not specified per test"},{"location":"eval/exact_match/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/exact_match/#outputevaluationcriteria","title":"OutputEvaluationCriteria","text":"Parameter Type Description <code>expected_output</code> <code>dict[str, Any] or str</code> The expected output to match exactly"},{"location":"eval/exact_match/#examples","title":"Examples","text":""},{"location":"eval/exact_match/#basic-usage","title":"Basic Usage","text":"<pre><code>from uipath.eval.evaluators import ExactMatchEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# agent_output must be a dict\nagent_execution = AgentExecution(\n    agent_input={\"query\": \"What is 2+2?\"},\n    agent_output={\"result\": \"4\"},\n    agent_trace=[]\n)\n\n# Create evaluator - extracts \"result\" field for comparison\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-1\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"case_sensitive\": False,\n        \"target_output_key\": \"result\"  # Extract the \"result\" field\n    }\n)\n\n# Evaluate - compares just the \"result\" field value\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"result\": \"4\"}}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/exact_match/#case-sensitive-matching","title":"Case-Sensitive Matching","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"status\": \"SUCCESS\"},\n    agent_trace=[]\n)\n\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-case\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"case_sensitive\": True,\n        \"target_output_key\": \"status\"  # Extract the \"status\" field\n    }\n)\n\n# Fails due to case mismatch\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"status\": \"success\"}}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 0.0\n\n# This would pass\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"status\": \"SUCCESS\"}}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/exact_match/#matching-structured-outputs","title":"Matching Structured Outputs","text":"<p>When <code>target_output_key</code> is <code>\"*\"</code> (default), the entire output dict is compared:</p> <pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"status\": \"success\", \"code\": 200},\n    agent_trace=[]\n)\n\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-dict\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"target_output_key\": \"*\"  # Compare entire output (default)\n    }\n)\n\n# Entire dict structure must match\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"status\": \"success\", \"code\": 200}}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/exact_match/#target-specific-field","title":"Target Specific Field","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\n        \"result\": \"approved\",\n        \"timestamp\": \"2024-01-01T12:00:00Z\"\n    },\n    agent_trace=[]\n)\n\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-field\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"target_output_key\": \"result\"\n    }\n)\n\n# Only checks the \"result\" field\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"result\": \"approved\"}}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/exact_match/#negated-mode","title":"Negated Mode","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"result\": \"error\"},\n    agent_trace=[]\n)\n\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-negated\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"negated\": True,\n        \"target_output_key\": \"result\"  # Extract the \"result\" field\n    }\n)\n\n# Passes because outputs do NOT match\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\"expected_output\": {\"result\": \"success\"}}\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/exact_match/#using-default-criteria","title":"Using Default Criteria","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"status\": \"OK\"},\n    agent_trace=[]\n)\n\nevaluator = ExactMatchEvaluator(\n    id=\"exact-match-default\",\n    config={\n        \"name\": \"ExactMatchEvaluator\",\n        \"target_output_key\": \"status\",  # Extract the \"status\" field\n        \"default_evaluation_criteria\": {\"expected_output\": {\"status\": \"OK\"}}\n    }\n)\n\n# Use default criteria\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution, evaluation_criteria=None\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/exact_match/#result-details","title":"Result Details","text":"<p>The evaluator returns a <code>NumericEvaluationResult</code> with:</p> <ul> <li>score (<code>float</code>): 1.0 for match, 0.0 for mismatch</li> <li>details (<code>BaseEvaluatorJustification</code>): Structured justification containing:<ul> <li><code>expected</code> (<code>str</code>): The expected output value (after case normalization if applicable)</li> <li><code>actual</code> (<code>str</code>): The actual output value (after case normalization if applicable)</li> </ul> </li> </ul>"},{"location":"eval/exact_match/#best-practices","title":"Best Practices","text":"<ol> <li>Use for deterministic outputs where exact matches are expected</li> <li>Consider case sensitivity based on your use case</li> <li>Use case-insensitive mode by default for more robust tests</li> <li>For structured data, consider using JSON Similarity Evaluator instead</li> <li>Combine with other evaluators for comprehensive testing</li> <li>Be careful with whitespace - exact match includes all whitespace characters</li> </ol>"},{"location":"eval/exact_match/#when-not-to-use","title":"When NOT to Use","text":"<ul> <li>When output can vary slightly but still be correct</li> <li>For natural language outputs (use LLM Judge instead)</li> <li>When comparing complex JSON structures (use JSON Similarity)</li> <li>When partial matches are acceptable (use Contains)</li> </ul>"},{"location":"eval/exact_match/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Contains Evaluator: For partial string matching</li> <li>JSON Similarity Evaluator: For flexible JSON comparison</li> <li>LLM Judge Output Evaluator: For semantic similarity</li> </ul>"},{"location":"eval/json_similarity/","title":"JSON Similarity Evaluator","text":"<p>The JSON Similarity Evaluator performs flexible structural comparison of JSON-like outputs using a tree-based matching algorithm. It recursively traverses the JSON structure as a tree and compares leaf nodes (actual values) with type-specific similarity measures.</p>"},{"location":"eval/json_similarity/#overview","title":"Overview","text":"<p>Evaluator ID: <code>json-similarity</code></p> <p>Use Cases:</p> <ul> <li>Compare complex nested JSON structures</li> <li>Validate API responses with tolerance for minor differences</li> <li>Test structured outputs where exact matches are too strict</li> <li>Measure similarity when numeric values may vary slightly</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 (0-100% similarity)</p>"},{"location":"eval/json_similarity/#configuration","title":"Configuration","text":"<p>Agent Output Structure</p> <p><code>agent_output</code> must always be a dictionary. The evaluator compares dictionary structures recursively, making it ideal for complex nested JSON-like outputs.</p>"},{"location":"eval/json_similarity/#jsonsimilarityevaluatorconfig","title":"JsonSimilarityEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"JsonSimilarityEvaluator\"</code> The evaluator's name <code>target_output_key</code> <code>str</code> <code>\"*\"</code> Specific key to extract from output (use \"*\" for entire output) <code>default_evaluation_criteria</code> <code>OutputEvaluationCriteria or None</code> <code>None</code> Default criteria if not specified per test"},{"location":"eval/json_similarity/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/json_similarity/#outputevaluationcriteria","title":"OutputEvaluationCriteria","text":"Parameter Type Description <code>expected_output</code> <code>dict[str, Any] or str</code> The expected JSON structure to compare against"},{"location":"eval/json_similarity/#how-it-works","title":"How It Works","text":"<p>The evaluator uses a tree-based matching algorithm:</p> <ol> <li>Tree Structure: The JSON/dictionary structure is treated as a tree, with nested objects and arrays forming branches</li> <li>Leaf Comparison: Only leaf nodes (actual values) are compared, using type-specific similarity measures:</li> </ol> <ul> <li>Strings: Levenshtein distance (edit distance) to measure textual similarity</li> <li>Numbers: Absolute difference with tolerance (within 1% considered similar)</li> <li>Booleans: Exact match required (binary comparison)</li> </ul> <ol> <li>Structural Recursion:</li> </ol> <ul> <li>Objects: Recursively traverses and compares all expected keys</li> <li>Arrays: Compares elements by position (index-based matching)</li> </ul> <p>Score Calculation: <code>matched_leaves / total_leaves</code></p> <p>The final score represents the percentage of matching leaf nodes in the tree structure.</p>"},{"location":"eval/json_similarity/#examples","title":"Examples","text":""},{"location":"eval/json_similarity/#basic-json-comparison","title":"Basic JSON Comparison","text":"<pre><code>from uipath.eval.evaluators import JsonSimilarityEvaluator\nfrom uipath.eval.models import AgentExecution\n\nagent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"name\": \"John Doe\", \"age\": 30, \"city\": \"New York\"},\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-1\",\n    config={\n        \"name\": \"JsonSimilarityEvaluator\"\n        # target_output_key defaults to \"*\" - compares entire output dict\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"name\": \"John Doe\", \"age\": 30, \"city\": \"New York\"}\n    }\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0 (perfect match)\nprint(f\"Matched: {result.details.matched_leaves}\")  # 3.0\nprint(f\"Total: {result.details.total_leaves}\")  # 3.0\n</code></pre>"},{"location":"eval/json_similarity/#numeric-tolerance","title":"Numeric Tolerance","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"temperature\": 20.5, \"humidity\": 65},\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-numeric\",\n    config={\"name\": \"JsonSimilarityEvaluator\"}\n)\n\n# Slightly different numbers\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"temperature\": 20.3, \"humidity\": 65}\n    }\n)\n\n# High similarity despite numeric difference\nprint(f\"Score: {result.score}\")  # ~0.99 (very high similarity)\n</code></pre>"},{"location":"eval/json_similarity/#string-similarity","title":"String Similarity","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"status\": \"completed successfully\"},\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-string\",\n    config={\"name\": \"JsonSimilarityEvaluator\"}\n)\n\n# Similar but not exact string\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"status\": \"completed sucessfully\"}  # typo\n    }\n)\n\n# High but not perfect similarity\nprint(f\"Score: {result.score}\")  # ~0.95 (high similarity despite typo)\n</code></pre>"},{"location":"eval/json_similarity/#nested-structures","title":"Nested Structures","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\n        \"user\": {\n            \"name\": \"Alice\",\n            \"profile\": {\n                \"age\": 25,\n                \"location\": \"Paris\"\n            }\n        },\n        \"status\": \"active\"\n    },\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-nested\",\n    config={\"name\": \"JsonSimilarityEvaluator\"}\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\n            \"user\": {\n                \"name\": \"Alice\",\n                \"profile\": {\n                    \"age\": 25,\n                    \"location\": \"Paris\"\n                }\n            },\n            \"status\": \"active\"\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/json_similarity/#array-comparison","title":"Array Comparison","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"items\": [\"apple\", \"banana\", \"orange\"]},\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-array\",\n    config={\"name\": \"JsonSimilarityEvaluator\"}\n)\n\n# Partial match (2 out of 3 correct)\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"items\": [\"apple\", \"banana\", \"grape\"]}\n    }\n)\n\nprint(f\"Score: {result.score}\")  # ~0.67 (2/3 correct)\n</code></pre>"},{"location":"eval/json_similarity/#handling-extra-keys-in-actual-output","title":"Handling Extra Keys in Actual Output","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\n        \"name\": \"Bob\",\n        \"age\": 30,\n        \"extra_field\": \"ignored\"  # Extra field in actual output\n    },\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-extra\",\n    config={\"name\": \"JsonSimilarityEvaluator\"}\n)\n\n# Only expected keys are evaluated\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\n            \"name\": \"Bob\",\n            \"age\": 30\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0 (extra fields ignored)\n</code></pre>"},{"location":"eval/json_similarity/#target-specific-field","title":"Target Specific Field","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\n        \"result\": {\"score\": 95, \"passed\": True},\n        \"metadata\": {\"timestamp\": \"2024-01-01\"}\n    },\n    agent_trace=[]\n)\n\nevaluator = JsonSimilarityEvaluator(\n    id=\"json-sim-targeted\",\n    config={\n        \"name\": \"JsonSimilarityEvaluator\",\n        \"target_output_key\": \"result\"\n    }\n)\n\n# Only compares the \"result\" field\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"result\": {\"score\": 95, \"passed\": True}}\n    }\n)\n\nprint(f\"Score: {result.score}\")  # Output: 1.0\n</code></pre>"},{"location":"eval/json_similarity/#scoring-details","title":"Scoring Details","text":"<p>The evaluator returns a <code>NumericEvaluationResult</code> with:</p> <ul> <li>score (<code>float</code>): Value between 0.0 and 1.0</li> <li>details (<code>JsonSimilarityJustification</code>): Structured justification containing:<ul> <li><code>expected</code> (<code>str</code>): String representation of the expected output</li> <li><code>actual</code> (<code>str</code>): String representation of the actual output</li> <li><code>matched_leaves</code> (<code>float</code>): Number of matching leaf nodes</li> <li><code>total_leaves</code> (<code>float</code>): Total number of leaf nodes compared</li> </ul> </li> </ul>"},{"location":"eval/json_similarity/#score-interpretation","title":"Score Interpretation","text":"Score Range Interpretation 1.0 Perfect match 0.9 - 0.99 Very high similarity (minor differences) 0.7 - 0.89 Good similarity (some differences) 0.5 - 0.69 Moderate similarity (significant differences) 0.0 - 0.49 Low similarity (major differences)"},{"location":"eval/json_similarity/#best-practices","title":"Best Practices","text":"<ol> <li>Use for structured data like JSON, dictionaries, or objects</li> <li>Set score thresholds based on your tolerance for differences (e.g., require score \u2265 0.9)</li> <li>Combine with exact match for critical fields that must match exactly</li> <li>Only expected keys matter - extra keys in actual output are ignored</li> <li>Consider array order - elements are compared by position</li> <li>Useful for API testing where responses may have minor variations</li> </ol>"},{"location":"eval/json_similarity/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use JSON Similarity when: - Comparing complex nested structures - Minor numeric differences are acceptable - String typos shouldn't cause complete failure - You need a granular similarity score</p> <p>Use Exact Match when: - Output must match precisely - No tolerance for any differences - Simple string comparison needed</p> <p>Use LLM Judge when: - Semantic meaning matters more than structure - Natural language comparison needed - Context and intent should be considered</p>"},{"location":"eval/json_similarity/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Exact Match Evaluator: For strict matching</li> <li>Contains Evaluator: For substring matching</li> <li>LLM Judge Output Evaluator: For semantic comparison</li> </ul>"},{"location":"eval/llm_judge_output/","title":"LLM Judge Output Evaluators","text":"<p>LLM Judge Output Evaluators use Language Models to assess the quality and semantic similarity of agent outputs. These evaluators are ideal for scenarios where deterministic comparison is insufficient and human-like judgment is needed.</p>"},{"location":"eval/llm_judge_output/#overview","title":"Overview","text":"<p>There are two variants of LLM Judge Output Evaluators:</p> <ol> <li>LLM Judge Output Evaluator (<code>llm-judge-output-semantic-similarity</code>): General semantic similarity evaluation</li> <li>LLM Judge Strict JSON Similarity Output Evaluator (<code>llm-judge-output-strict-json-similarity</code>): Strict JSON structure comparison with LLM judgment</li> </ol> <p>Use Cases:</p> <ul> <li>Evaluate natural language outputs</li> <li>Assess semantic similarity beyond exact matching</li> <li>Judge output quality based on intent and meaning</li> <li>Validate structured outputs with flexible criteria</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 with <code>LLMJudgeJustification</code> containing <code>expected</code>, <code>actual</code>, and <code>justification</code> fields</p>"},{"location":"eval/llm_judge_output/#llm-service-integration","title":"LLM Service Integration","text":"<p>LLM Judge evaluators require an LLM service to perform evaluations. By default, the evaluators use the UiPathLlmService to handle LLM requests, which automatically integrates with your configured LLM providers through the UiPath platform.</p>"},{"location":"eval/llm_judge_output/#custom-llm-service","title":"Custom LLM Service","text":"<p>You can supply a custom LLM service that supports the following request format:</p> <pre><code>{\n    \"model\": \"model-name\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"system prompt\"},\n        {\"role\": \"user\", \"content\": \"evaluation prompt\"}\n    ],\n    \"response_format\": {\n        \"type\": \"json_schema\",\n        \"json_schema\": {\n            \"name\": \"evaluation_response\",\n            \"schema\": {\n                # JSON schema for structured output\n            }\n        }\n    },\n    \"max_tokens\": 1000,  # or None\n    \"temperature\": 0.0\n}\n</code></pre> <p>The LLM service must:</p> <ul> <li>Accept messages with <code>system</code> and <code>user</code> roles</li> <li>Support structured output via <code>response_format</code> with JSON schema</li> <li>Return responses conforming to the specified schema</li> <li>Handle <code>temperature</code> and <code>max_tokens</code> parameters</li> </ul>"},{"location":"eval/llm_judge_output/#model-selection","title":"Model Selection","text":"<p>When configuring the evaluator, specify the model name according to your LLM service's conventions:</p> <pre><code>evaluator = LLMJudgeOutputEvaluator(\n    id=\"llm-judge-1\",\n    config={\n        \"name\": \"LLMJudgeOutputEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",  # Use your service's model naming\n        \"temperature\": 0.0\n    }\n)\n</code></pre> <p>UiPathLlmService</p> <p>The default <code>UiPathLlmService</code> supports multiple LLM providers configured through the UiPath platform. Model names follow the provider's conventions (e.g., <code>gpt-4o-2024-11-20</code> for OpenAI, <code>claude-3-5-sonnet-20241022</code> for Anthropic).</p>"},{"location":"eval/llm_judge_output/#llm-judge-output-evaluator","title":"LLM Judge Output Evaluator","text":""},{"location":"eval/llm_judge_output/#configuration","title":"Configuration","text":""},{"location":"eval/llm_judge_output/#llmjudgeoutputevaluatorconfig","title":"LLMJudgeOutputEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"LLMJudgeOutputEvaluator\"</code> The evaluator's name <code>prompt</code> <code>str</code> Default user prompt Custom evaluation prompt <code>model</code> <code>str</code> <code>\"\"</code> LLM model to use for judgment <code>temperature</code> <code>float</code> <code>0.0</code> LLM temperature (0.0 for minimal non-determinism) <code>max_tokens</code> <code>int or None</code> <code>None</code> Maximum tokens for LLM response <code>target_output_key</code> <code>str</code> <code>\"*\"</code> Specific key to extract from output <code>default_evaluation_criteria</code> <code>OutputEvaluationCriteria or None</code> <code>None</code> Default criteria"},{"location":"eval/llm_judge_output/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/llm_judge_output/#outputevaluationcriteria","title":"OutputEvaluationCriteria","text":"Parameter Type Description <code>expected_output</code> <code>dict[str, Any] or str</code> The expected output for comparison"},{"location":"eval/llm_judge_output/#prompt-placeholders","title":"Prompt Placeholders","text":"<p>The prompt template supports these placeholders:</p> <ul> <li><code>{{ActualOutput}}</code>: Replaced with the agent's actual output</li> <li><code>{{ExpectedOutput}}</code>: Replaced with the expected output from criteria</li> </ul>"},{"location":"eval/llm_judge_output/#examples","title":"Examples","text":""},{"location":"eval/llm_judge_output/#basic-semantic-similarity","title":"Basic Semantic Similarity","text":"<pre><code>from uipath.eval.evaluators import LLMJudgeOutputEvaluator\nfrom uipath.eval.models import AgentExecution\n\nagent_execution = AgentExecution(\n    agent_input={\"query\": \"What is the capital of France?\"},\n    agent_output={\"answer\": \"Paris is the capital city of France.\"},\n    agent_trace=[]\n)\n\nevaluator = LLMJudgeOutputEvaluator(\n    id=\"llm-judge-1\",\n    config={\n        \"name\": \"LLMJudgeOutputEvaluator\",\n        # Use the UiPathLlmChatService convention for model names; should be changed according to selected service\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"temperature\": 0.0,\n        \"target_output_key\": \"answer\"  # Extract the \"answer\" field\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"answer\": \"The capital of France is Paris.\"}\n    }\n)\n\nprint(f\"Score: {result.score}\")  # e.g., 0.95\nprint(f\"Justification: {result.details.justification}\")  # LLM's reasoning\n</code></pre>"},{"location":"eval/llm_judge_output/#custom-evaluation-prompt","title":"Custom Evaluation Prompt","text":"<pre><code>custom_prompt = \"\"\"\nCompare the actual output with the expected output.\nFocus on semantic meaning and intent rather than exact wording.\n\nActual Output: {{ActualOutput}}\nExpected Output: {{ExpectedOutput}}\n\nProvide a score from 0-100 based on semantic similarity.\n\"\"\"\n\nagent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\"message\": \"The product has been successfully added to your cart.\"},\n    agent_trace=[]\n)\n\nevaluator = LLMJudgeOutputEvaluator(\n    id=\"llm-judge-custom\",\n    config={\n        \"name\": \"LLMJudgeOutputEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"prompt\": custom_prompt,\n        \"temperature\": 0.0,\n        \"target_output_key\": \"message\"  # Extract the \"message\" field\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"message\": \"Item added to shopping cart.\"}\n    }\n)\n\nprint(f\"Score: {result.score}\")\nprint(f\"Justification: {result.details}\")\n</code></pre>"},{"location":"eval/llm_judge_output/#evaluating-natural-language-quality","title":"Evaluating Natural Language Quality","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={\"task\": \"Write a professional email\"},\n    agent_output={\"email\": \"\"\"Dear Customer,\n\nThank you for your inquiry. We have reviewed your request\nand are pleased to inform you that we can accommodate your\nneeds. Please let us know if you have any questions.\n\nBest regards,\nSupport Team\"\"\"},\n    agent_trace=[]\n)\n\nevaluator = LLMJudgeOutputEvaluator(\n    id=\"llm-judge-quality\",\n    config={\n        \"name\": \"LLMJudgeOutputEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"temperature\": 0.0,\n        \"target_output_key\": \"email\"  # Extract the \"email\" field\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\"email\": \"A professional, courteous response addressing the customer's inquiry\"}\n    }\n)\n\nprint(f\"Score: {result.score}\")\nprint(f\"Justification: {result.details}\")\n</code></pre>"},{"location":"eval/llm_judge_output/#llm-judge-strict-json-similarity-output-evaluator","title":"LLM Judge Strict JSON Similarity Output Evaluator","text":"<p>This variant performs per-key matching on JSON structures with penalty-based scoring. The LLM evaluates each top-level key individually and calculates a final score based on key-level matches.</p>"},{"location":"eval/llm_judge_output/#how-it-works","title":"How It Works","text":"<ol> <li>Key Inventory: Identifies all top-level keys in expected and actual outputs</li> <li>Per-Key Matching: For each expected key, checks if it exists in actual output</li> <li>Content Assessment: For matching keys, evaluates content similarity (identical/similar/different)</li> <li>Penalty-Based Scoring: Calculates score using these penalties per key:</li> </ol> <ul> <li>Missing key (not in actual): <code>100/N</code> penalty</li> <li>Wrong key (exists but significantly different content): <code>100/N</code> penalty</li> <li>Similar key (exists with similar content): <code>50/N</code> penalty</li> <li>Identical key (exists with identical content): <code>0</code> penalty</li> <li>Extra key (in actual but not expected): <code>10/N</code> penalty</li> </ul> <p>Where <code>N</code> = total number of expected keys</p> <p>Final Score: <code>100 - total_penalty</code> (scale 0-100)</p>"},{"location":"eval/llm_judge_output/#why-strict","title":"Why \"Strict\"?","text":"<p>Unlike the standard <code>LLMJudgeOutputEvaluator</code> which evaluates semantic similarity holistically, this evaluator:</p> <ul> <li>Enforces structural matching: Each expected key must be present</li> <li>Penalizes missing keys heavily: Same as wrong content (100/N penalty)</li> <li>Evaluates per-key: Independence between key evaluations</li> <li>Deterministic scoring formula: Mechanical calculation based on key-level assessments</li> </ul>"},{"location":"eval/llm_judge_output/#configuration_1","title":"Configuration","text":""},{"location":"eval/llm_judge_output/#llmjudgestrictjsonsimilarityoutputevaluatorconfig","title":"LLMJudgeStrictJSONSimilarityOutputEvaluatorConfig","text":"<p>Same as <code>LLMJudgeOutputEvaluatorConfig</code> but with:</p> <ul> <li>name: <code>\"LLMJudgeStrictJSONSimilarityOutputEvaluator\"</code></li> <li>prompt: Specialized prompt enforcing per-key matching and penalty calculations</li> </ul>"},{"location":"eval/llm_judge_output/#examples_1","title":"Examples","text":""},{"location":"eval/llm_judge_output/#strict-json-structure-evaluation","title":"Strict JSON Structure Evaluation","text":"<pre><code>from uipath.eval.evaluators import LLMJudgeStrictJSONSimilarityOutputEvaluator\n\nevaluator = LLMJudgeStrictJSONSimilarityOutputEvaluator(\n    id=\"llm-json-strict\",\n    config={\n        \"name\": \"LLMJudgeStrictJSONSimilarityOutputEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"temperature\": 0.0\n    }\n)\n\nagent_execution = AgentExecution(\n    agent_input={},\n    agent_output={\n        \"status\": \"success\",\n        \"user_id\": 12345,\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\"\n    },\n    agent_trace=[]\n)\n\nresult = await evaluator.evaluate(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_output\": {\n            \"status\": \"success\",\n            \"user_id\": 12345,\n            \"name\": \"John Doe\",\n            \"email\": \"john@example.com\"\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")\nprint(f\"Justification: {result.details}\")\n</code></pre>"},{"location":"eval/llm_judge_output/#understanding-llm-judge-response","title":"Understanding LLM Judge Response","text":"<p>The LLM returns a structured response:</p> <pre><code># Result structure\n{\n    \"score\": 0.85,  # 0.0 to 1.0 (normalized from 0-100)\n    \"details\": {\n        \"expected\": \"The expected output...\",\n        \"actual\": \"The actual output...\",\n        \"justification\": \"The outputs convey the same meaning...\"  # LLM justification\n    }\n}\n</code></pre>"},{"location":"eval/llm_judge_output/#best-practices","title":"Best Practices","text":"<ol> <li>Use temperature 0.0 for deterministic evaluations</li> <li>Craft clear prompts - Be specific about evaluation criteria</li> <li>Include both placeholders - Always use <code>{{ActualOutput}}</code> and <code>{{ExpectedOutput}}</code></li> <li>Set score thresholds - Define minimum acceptable scores (e.g., \u2265 0.8)</li> <li>Review justifications - Use LLM explanations to understand scores</li> <li>Cost awareness - LLM evaluations use API calls, consider token costs</li> </ol>"},{"location":"eval/llm_judge_output/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use LLM Judge Output when:</p> <ul> <li>Semantic meaning matters more than exact wording</li> <li>Natural language outputs need human-like judgment</li> <li>Context and intent are important</li> <li>Flexible evaluation criteria needed</li> </ul> <p>Use Deterministic Evaluators when: - Exact matches are required - Output format is predictable - Speed and cost are priorities - No ambiguity in correctness</p>"},{"location":"eval/llm_judge_output/#configuration-tips","title":"Configuration Tips","text":""},{"location":"eval/llm_judge_output/#temperature-settings","title":"Temperature Settings","text":"<ul> <li>0.0: Deterministic, consistent results (recommended)</li> <li>0.1: Slight variation for nuanced judgment</li> <li>&gt;0.3: Not recommended (too inconsistent)</li> </ul>"},{"location":"eval/llm_judge_output/#error-handling","title":"Error Handling","text":"<p>The evaluator will raise <code>UiPathEvaluationError</code> if:</p> <ul> <li>LLM service is unavailable</li> <li>Prompt doesn't contain required placeholders</li> <li>LLM response cannot be parsed</li> <li>Model returns invalid JSON</li> </ul>"},{"location":"eval/llm_judge_output/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>LLM Judge Trajectory Evaluator: For evaluating agent execution paths</li> <li>JSON Similarity Evaluator: For deterministic JSON comparison</li> <li>Exact Match Evaluator: For strict string matching</li> <li>Contains Evaluator: For substring matching</li> </ul>"},{"location":"eval/llm_judge_trajectory/","title":"LLM Judge Trajectory Evaluators","text":"<p>LLM Judge Trajectory Evaluators use Language Models to assess the quality of agent execution trajectories - the sequence of decisions and actions an agent takes. These evaluators are good options for validating that agents follow expected execution behaviors when standard trajectory evaluators do not weigh specific mistakes too well or are too hard to configure. However, the recommended practice for most use cases involves acquiring comprehensive trajectory annotations and adopting deterministic trajectory evaluators.</p>"},{"location":"eval/llm_judge_trajectory/#overview","title":"Overview","text":"<p>We provide two variants of LLM Judge Trajectory Evaluators:</p> <ol> <li>LLM Judge Trajectory Evaluator (<code>llm-judge-trajectory-similarity</code>): General trajectory evaluation</li> <li>LLM Judge Trajectory Simulation Evaluator (<code>llm-judge-trajectory-simulation</code>): Specialized for tool simulation scenarios</li> </ol> <p>Use Cases:</p> <ul> <li>Validate agent decision-making processes</li> <li>Ensure agents follow expected execution paths</li> <li>Evaluate tool usage patterns and sequencing</li> <li>Assess agent behavior in complex scenarios</li> <li>Validate tool simulation accuracy (where tool responses are mocked)</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 with <code>LLMJudgeJustification</code> containing <code>expected</code>, <code>actual</code>, and <code>justification</code> fields</p>"},{"location":"eval/llm_judge_trajectory/#llm-service-integration","title":"LLM Service Integration","text":"<p>LLM Judge evaluators require an LLM service to perform evaluations. By default, the evaluators use the UiPathLlmService to handle LLM requests, which automatically integrates with your configured LLM providers through the UiPath platform.</p>"},{"location":"eval/llm_judge_trajectory/#custom-llm-service","title":"Custom LLM Service","text":"<p>You can supply a custom LLM service that supports the following request format:</p> <pre><code>{\n    \"model\": \"model-name\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"system prompt\"},\n        {\"role\": \"user\", \"content\": \"evaluation prompt\"}\n    ],\n    \"response_format\": {\n        \"type\": \"json_schema\",\n        \"json_schema\": {\n            \"name\": \"evaluation_response\",\n            \"schema\": {\n                # JSON schema for structured output\n            }\n        }\n    },\n    \"max_tokens\": 1000,  # or None\n    \"temperature\": 0.0\n}\n</code></pre> <p>The LLM service must:</p> <ul> <li>Accept messages with <code>system</code> and <code>user</code> roles</li> <li>Support structured output via <code>response_format</code> with JSON schema</li> <li>Return responses conforming to the specified schema</li> <li>Handle <code>temperature</code> and <code>max_tokens</code> parameters</li> </ul>"},{"location":"eval/llm_judge_trajectory/#model-selection","title":"Model Selection","text":"<p>When configuring the evaluator, specify the model name according to your LLM service's conventions:</p> <pre><code>evaluator = LLMJudgeTrajectoryEvaluator(\n    id=\"trajectory-judge-1\",\n    config={\n        \"name\": \"LLMJudgeTrajectoryEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",  # Use your service's model naming\n        \"temperature\": 0.0\n    }\n)\n</code></pre> <p>UiPathLlmService</p> <p>The default <code>UiPathLlmService</code> supports multiple LLM providers configured through the UiPath platform. Model names follow the provider's conventions (e.g., <code>gpt-4o-2024-11-20</code> for OpenAI, <code>claude-3-5-sonnet-20241022</code> for Anthropic).</p>"},{"location":"eval/llm_judge_trajectory/#llm-judge-trajectory-evaluator","title":"LLM Judge Trajectory Evaluator","text":""},{"location":"eval/llm_judge_trajectory/#configuration","title":"Configuration","text":""},{"location":"eval/llm_judge_trajectory/#llmjudgetrajectoryevaluatorconfig","title":"LLMJudgeTrajectoryEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"LLMJudgeTrajectoryEvaluator\"</code> The evaluator's name <code>prompt</code> <code>str</code> Default trajectory prompt Custom evaluation prompt <code>model</code> <code>str</code> <code>\"\"</code> LLM model to use for judgment <code>temperature</code> <code>float</code> <code>0.0</code> LLM temperature (0.0 for deterministic) <code>max_tokens</code> <code>int or None</code> <code>None</code> Maximum tokens for LLM response <code>default_evaluation_criteria</code> <code>TrajectoryEvaluationCriteria or None</code> <code>None</code> Default criteria"},{"location":"eval/llm_judge_trajectory/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/llm_judge_trajectory/#trajectoryevaluationcriteria","title":"TrajectoryEvaluationCriteria","text":"Parameter Type Description <code>expected_agent_behavior</code> <code>str</code> Description of the expected agent behavior"},{"location":"eval/llm_judge_trajectory/#prompt-placeholders","title":"Prompt Placeholders","text":"<p>The prompt template supports these placeholders:</p> <ul> <li><code>{{AgentRunHistory}}</code>: The agent's execution trace/trajectory</li> <li><code>{{ExpectedAgentBehavior}}</code>: The expected behavior description</li> <li><code>{{UserOrSyntheticInput}}</code>: The input provided to the agent</li> <li><code>{{SimulationInstructions}}</code>: Tool simulation instructions specifying how tools should respond (for simulation variant only)</li> </ul>"},{"location":"eval/llm_judge_trajectory/#examples","title":"Examples","text":""},{"location":"eval/llm_judge_trajectory/#basic-trajectory-evaluation","title":"Basic Trajectory Evaluation","text":"<pre><code>from uipath.eval.evaluators import LLMJudgeTrajectoryEvaluator\nfrom uipath.eval.models import AgentExecution\n\nagent_execution = AgentExecution(\n    agent_input={\"user_query\": \"Book a flight to Paris\"},\n    agent_output={\"booking_id\": \"FL123\", \"status\": \"confirmed\"},\n    agent_trace=[\n        # Trace contains spans showing the agent's execution path\n        # Each span represents a step in the agent's decision-making\n    ]\n)\n\nevaluator = LLMJudgeTrajectoryEvaluator(\n    id=\"trajectory-judge-1\",\n    config={\n        \"name\": \"LLMJudgeTrajectoryEvaluator\",\n        # Use the UiPathLlmChatService convention for model names; this should be changed according to selected service\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"temperature\": 0.0\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_agent_behavior\": \"\"\"\n        The agent should:\n        1. Search for available flights to Paris\n        2. Present options to the user\n        3. Process the booking\n        4. Confirm the reservation\n        \"\"\"\n    }\n)\n\nprint(f\"Score: {result.score}\")\nprint(f\"Justification: {result.details}\")\n</code></pre>"},{"location":"eval/llm_judge_trajectory/#validating-tool-usage-sequence","title":"Validating Tool Usage Sequence","text":"<pre><code>agent_execution = AgentExecution(\n    agent_input={\"task\": \"Update user profile and send notification\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=[\n        # Spans showing: validate_user -&gt; update_profile -&gt; send_notification\n    ]\n)\n\nevaluator = LLMJudgeTrajectoryEvaluator(\n    id=\"trajectory-tools\",\n    config={\n        \"name\": \"LLMJudgeTrajectoryEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"temperature\": 0.0\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_agent_behavior\": \"\"\"\n        The agent must:\n        1. First validate the user exists\n        2. Update the profile in the database\n        3. Send a confirmation notification\n        This sequence must be followed to ensure data integrity.\n        \"\"\"\n    }\n)\n\nprint(f\"Score: {result.score}\")\nprint(f\"Justification: {result.details}\")\n</code></pre>"},{"location":"eval/llm_judge_trajectory/#custom-evaluation-prompt","title":"Custom Evaluation Prompt","text":"<pre><code>custom_prompt = \"\"\"\nAnalyze the agent's execution path and compare it with the expected behavior.\n\nAgent Run History:\n{{AgentRunHistory}}\n\nExpected Agent Behavior:\n{{ExpectedAgentBehavior}}\n\nUser Input:\n{{UserOrSyntheticInput}}\n\nEvaluate:\n1. Did the agent follow the expected sequence?\n2. Were all necessary steps completed?\n3. Was the decision-making logical and efficient?\n\nProvide a score from 0-100.\n\"\"\"\n\nevaluator = LLMJudgeTrajectoryEvaluator(\n    id=\"trajectory-custom\",\n    config={\n        \"name\": \"LLMJudgeTrajectoryEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"prompt\": custom_prompt,\n        \"temperature\": 0.0\n    }\n)\n\n# ... use evaluator\n</code></pre>"},{"location":"eval/llm_judge_trajectory/#llm-judge-trajectory-simulation-evaluator","title":"LLM Judge Trajectory Simulation Evaluator","text":"<p>This variant is specialized for evaluating agent behavior in tool simulation scenarios, where tool responses are mocked/simulated during agent execution.</p>"},{"location":"eval/llm_judge_trajectory/#what-is-tool-simulation","title":"What is Tool Simulation?","text":"<p>In tool simulation:</p> <ol> <li>Simulation Engine: Mocks tool responses based on simulation instructions</li> <li>Agent Unawareness: The agent doesn't know tool responses are simulated</li> <li>Controlled Testing: Allows testing agent behavior with predictable tool responses</li> <li>Evaluation Focus: Assesses whether the agent behaves correctly given the simulated tool responses</li> </ol> <p>The evaluator checks if: - The simulation was successful (tools responded as instructed) - The agent behaved according to expectations given the simulated responses - The agent's decision-making aligns with expected behavior in the simulated scenario</p>"},{"location":"eval/llm_judge_trajectory/#configuration_1","title":"Configuration","text":""},{"location":"eval/llm_judge_trajectory/#llmjudgetrajectorysimulationevaluatorconfig","title":"LLMJudgeTrajectorySimulationEvaluatorConfig","text":"<p>Same as <code>LLMJudgeTrajectoryEvaluatorConfig</code> but with:</p> <ul> <li>name: <code>\"LLMJudgeTrajectorySimulationEvaluator\"</code></li> <li>prompt: Specialized prompt for tool simulation evaluation that considers:</li> <li>Simulation instructions (how tools should respond)</li> <li>Whether the simulated tool responses matched instructions</li> <li>Agent behavior given the simulated responses</li> </ul>"},{"location":"eval/llm_judge_trajectory/#examples_1","title":"Examples","text":""},{"location":"eval/llm_judge_trajectory/#tool-simulation-trajectory-evaluation","title":"Tool Simulation Trajectory Evaluation","text":"<pre><code>from uipath.eval.evaluators import LLMJudgeTrajectorySimulationEvaluator\n\nagent_execution = AgentExecution(\n    agent_input={\"query\": \"Book a flight to Paris for tomorrow\"},\n    agent_output={\"booking_id\": \"FL123\", \"status\": \"confirmed\"},\n    agent_trace=[\n        # Execution spans showing tool calls and their simulated responses\n    ],\n    simulation_instructions=\"\"\"\n    Simulate the following tool responses:\n    - search_flights tool: Return 3 available flights with prices\n    - book_flight tool: Return booking confirmation with ID \"FL123\"\n    - send_confirmation_email tool: Return success status\n    Mock the tools to respond as if it's a Tuesday in March with normal availability.\n    \"\"\"\n)\n\nevaluator = LLMJudgeTrajectorySimulationEvaluator(\n    id=\"sim-trajectory-1\",\n    config={\n        \"name\": \"LLMJudgeTrajectorySimulationEvaluator\",\n        \"model\": \"gpt-4o-2024-11-20\",\n        \"temperature\": 0.0\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"expected_agent_behavior\": \"\"\"\n        The agent should:\n        1. Call search_flights to find available options\n        2. Present flight options to the user (simulated in conversation)\n        3. Call book_flight with appropriate parameters\n        4. Confirm the booking with the user\n        5. Call send_confirmation_email to notify the user\n        \"\"\"\n    }\n)\n\nprint(f\"Score: {result.score}\")\nprint(f\"Justification: {result.details}\")\n</code></pre>"},{"location":"eval/llm_judge_trajectory/#understanding-agent-traces","title":"Understanding Agent Traces","text":"<p>The <code>agent_trace</code> contains execution spans that show:</p> <ul> <li>Tool calls made by the agent</li> <li>LLM reasoning steps</li> <li>Decision points</li> <li>Action sequences</li> <li>Intermediate results</li> </ul> <p>Example trace structure: <pre><code>agent_trace = [\n    {\n        \"name\": \"search_flights\",\n        \"type\": \"tool\",\n        \"inputs\": {\"destination\": \"Paris\"},\n        \"output\": {\"flights\": [...]}\n    },\n    {\n        \"name\": \"llm_reasoning\",\n        \"type\": \"llm\",\n        \"content\": \"User wants cheapest option...\"\n    },\n    {\n        \"name\": \"book_flight\",\n        \"type\": \"tool\",\n        \"inputs\": {\"flight_id\": \"FL123\"},\n        \"output\": {\"status\": \"confirmed\"}\n    }\n]\n</code></pre></p>"},{"location":"eval/llm_judge_trajectory/#best-practices","title":"Best Practices","text":"<ol> <li>Write clear behavior descriptions - Be specific about expected sequences and decision logic</li> <li>Use temperature 0.0 for consistent evaluations</li> <li>Include context - Provide enough detail in expected behavior</li> <li>Consider partial credit - LLM can give partial scores for mostly correct trajectories</li> <li>Review justifications - Understand why trajectories scored high or low</li> <li>Combine with tool evaluators - Use Tool Call Evaluators for strict ordering requirements</li> </ol>"},{"location":"eval/llm_judge_trajectory/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use LLM Judge Trajectory when: - Decision-making process matters more than just output - Agent behavior patterns need validation - Tool usage sequence is complex but somewhat flexible - Human-like judgment of execution quality is needed</p> <p>Use Tool Call Evaluators when: - Strict tool call sequences must be enforced - Deterministic validation is sufficient - Exact argument values must match - Performance and cost are priorities</p>"},{"location":"eval/llm_judge_trajectory/#configuration-tips","title":"Configuration Tips","text":""},{"location":"eval/llm_judge_trajectory/#temperature-settings","title":"Temperature Settings","text":"<ul> <li>0.0: Deterministic, consistent results (recommended)</li> <li>0.1: Slight variation for nuanced judgment</li> <li>&gt;0.3: Not recommended (too inconsistent)</li> </ul>"},{"location":"eval/llm_judge_trajectory/#evaluation-criteria-guidelines","title":"Evaluation Criteria Guidelines","text":"<p>When writing <code>expected_agent_behavior</code>, include:</p> <ol> <li>Sequential steps: Numbered or ordered list of expected actions</li> <li>Decision points: When the agent should make choices</li> <li>Conditional logic: \"If X, then Y\" scenarios</li> <li>Success criteria: What constitutes good behavior</li> <li>Error handling: How agent should handle failures</li> </ol>"},{"location":"eval/llm_judge_trajectory/#good-example","title":"Good Example","text":"<pre><code>evaluation_criteria = {\n    \"expected_agent_behavior\": \"\"\"\n    The agent should follow this sequence:\n\n    1. Validate user authentication status\n       - If not authenticated, request login\n       - If authenticated, proceed to step 2\n\n    2. Fetch user's order history\n       - Use the get_orders tool with user_id\n\n    3. Identify the problematic order\n       - Search for orders with \"delayed\" status\n\n    4. Provide explanation to user\n       - Include order details and delay reason\n\n    5. Offer resolution\n       - Present refund or expedited shipping options\n\n    The agent should maintain a helpful tone throughout\n    and adapt responses based on user reactions.\n    \"\"\"\n}\n</code></pre>"},{"location":"eval/llm_judge_trajectory/#poor-example-too-vague","title":"Poor Example (Too Vague)","text":"<pre><code>evaluation_criteria = {\n    \"expected_agent_behavior\": \"Help the user with their order problem\"\n}\n</code></pre>"},{"location":"eval/llm_judge_trajectory/#error-handling","title":"Error Handling","text":"<p>The evaluator will raise <code>UiPathEvaluationError</code> if:</p> <ul> <li>LLM service is unavailable</li> <li>Prompt doesn't contain required placeholders</li> <li>Agent trace cannot be converted to readable format</li> <li>LLM response cannot be parsed</li> </ul>"},{"location":"eval/llm_judge_trajectory/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Token usage: Trajectories can be long, increasing token costs</li> <li>Evaluation time: LLM calls take longer than deterministic evaluators</li> <li>Caching: Consider caching evaluations for repeated test runs</li> <li>Batch processing: Evaluate multiple trajectories in parallel when possible</li> </ul>"},{"location":"eval/llm_judge_trajectory/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>LLM Judge Output Evaluator: For evaluating outputs instead of processes</li> <li>Tool Call Order Evaluator: For strict deterministic sequence validation</li> <li>Tool Call Count Evaluator: For validating tool usage frequencies</li> <li>Tool Call Args Evaluator: For validating tool arguments</li> </ul>"},{"location":"eval/tool_call_args/","title":"Tool Call Args Evaluator","text":"<p>The Tool Call Args Evaluator validates that an agent calls tools with the correct arguments. This is essential for ensuring proper data flow, correct API usage, and validating that agents pass the right information to functions.</p>"},{"location":"eval/tool_call_args/#overview","title":"Overview","text":"<p>Evaluator ID: <code>tool-call-args</code></p> <p>Use Cases:</p> <ul> <li>Validate tool parameters are correct</li> <li>Ensure proper data flow between tools</li> <li>Test argument transformation logic</li> <li>Verify API parameter usage</li> <li>Check data type correctness</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 based on argument accuracy</p>"},{"location":"eval/tool_call_args/#configuration","title":"Configuration","text":""},{"location":"eval/tool_call_args/#toolcallargsevaluatorconfig","title":"ToolCallArgsEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"ToolCallArgsEvaluator\"</code> The evaluator's name <code>strict</code> <code>bool</code> <code>False</code> Controls scoring when multiple tools expected: True = all-or-nothing (1.0 or 0.0), False = proportional (ratio of matched tools) <code>subset</code> <code>bool</code> <code>False</code> If True, actual args can be a subset of expected; if False, must match all expected args <code>default_evaluation_criteria</code> <code>ToolCallArgsEvaluationCriteria or None</code> <code>None</code> Default criteria"},{"location":"eval/tool_call_args/#evaluation-modes","title":"Evaluation Modes","text":"Mode Description <code>strict=False, subset=False</code> Proportional scoring (e.g., 2/3 tools matched = 0.66), exact arg matching required <code>strict=True, subset=False</code> All-or-nothing scoring (1.0 or 0.0), exact arg matching required <code>strict=False, subset=True</code> Proportional scoring, expected args must be subset of actual (extra args allowed) <code>strict=True, subset=True</code> All-or-nothing scoring, expected args must be subset of actual (extra args allowed)"},{"location":"eval/tool_call_args/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/tool_call_args/#toolcallargsevaluationcriteria","title":"ToolCallArgsEvaluationCriteria","text":"Parameter Type Description <code>tool_calls</code> <code>list[ToolCall]</code> List of expected tool calls with their arguments"},{"location":"eval/tool_call_args/#toolcall-structure","title":"ToolCall Structure","text":"<pre><code>{\n    \"name\": \"tool_name\",           # Tool name\n    \"args\": {\"key\": \"value\"}  # Expected arguments\n}\n</code></pre>"},{"location":"eval/tool_call_args/#scoring-algorithm","title":"Scoring Algorithm","text":"<p>For each tool call: 1. Match tool calls by name 2. Compare arguments based on mode (strict or JSON similarity) 3. Calculate score based on match quality</p> <p>Final score: Average across all expected tool calls</p>"},{"location":"eval/tool_call_args/#examples","title":"Examples","text":""},{"location":"eval/tool_call_args/#basic-argument-validation","title":"Basic Argument Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\nfrom uipath.eval.evaluators import ToolCallArgsEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Sample agent execution with tool calls and arguments\nmock_spans = [\n    ReadableSpan(\n        name=\"update_user\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"update_user\",\n            \"input.value\": \"{'user_id': 123, 'fields': {'email': 'user@example.com'}, 'notify': True}\",\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"user_id\": 123, \"action\": \"update\"},\n    agent_output={\"status\": \"success\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallArgsEvaluator(\n    id=\"args-check-1\",\n    config={\n        \"name\": \"ToolCallArgsEvaluator\",\n        \"strict\": False,\n        \"subset\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls\": [\n            {\n                \"name\": \"update_user\",\n                \"args\": {\n                    \"user_id\": 123,\n                    \"fields\": {\"email\": \"user@example.com\"},\n                    \"notify\": True\n                }\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (exact match)\nprint(f\"Details: {result.details}\")\n</code></pre>"},{"location":"eval/tool_call_args/#strict-mode-exact-matching","title":"Strict Mode - Exact Matching","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"api_request\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"api_request\",\n            \"input.value\": \"{'endpoint': '/api/users', 'method': 'GET', 'headers': {'Authorization': 'Bearer token123'}}\",\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"action\": \"fetch_users\"},\n    agent_output={\"status\": \"success\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallArgsEvaluator(\n    id=\"args-strict\",\n    config={\n        \"name\": \"ToolCallArgsEvaluator\",\n        \"strict\": True,\n        \"subset\": False\n    }\n)\n\n# Arguments must match exactly\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls\": [\n            {\n                \"name\": \"api_request\",\n                \"args\": {\n                    \"endpoint\": \"/api/users\",\n                    \"method\": \"GET\",\n                    \"headers\": {\"Authorization\": \"Bearer token123\"}\n                }\n            }\n        ]\n    }\n)\n\n# Score is 1.0 only if arguments match exactly\nprint(f\"Score: {result.score}\")  # 1.0\n</code></pre>"},{"location":"eval/tool_call_args/#non-strict-mode-proportional-scoring","title":"Non-Strict Mode - Proportional Scoring","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\nfrom uipath.eval.evaluators import ToolCallArgsEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Agent called 3 tools, but only 2 match the expected args\nmock_spans = [\n    ReadableSpan(\n        name=\"validate_input\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"validate_input\",\n            \"input.value\": \"{'data': {'user_id': 123}}\",  # \u2713 Matches\n        },\n    ),\n    ReadableSpan(\n        name=\"fetch_user\",\n        start_time=1,\n        end_time=2,\n        attributes={\n            \"tool.name\": \"fetch_user\",\n            \"input.value\": \"{'user_id': 999}\",  # \u2717 Wrong ID!\n        },\n    ),\n    ReadableSpan(\n        name=\"update_profile\",\n        start_time=2,\n        end_time=3,\n        attributes={\n            \"tool.name\": \"update_profile\",\n            \"input.value\": \"{'user_id': 123, 'updates': {'name': 'John Doe'}}\",  # \u2713 Matches\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Update user profile\"},\n    agent_output={\"status\": \"updated\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallArgsEvaluator(\n    id=\"args-proportional\",\n    config={\n        \"name\": \"ToolCallArgsEvaluator\",\n        \"strict\": False,  # Proportional scoring\n        \"subset\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls\": [\n            {\n                \"name\": \"validate_input\",\n                \"args\": {\"data\": {\"user_id\": 123}}  # \u2713 Matches\n            },\n            {\n                \"name\": \"fetch_user\",\n                \"args\": {\"user_id\": 123}  # \u2717 Actual was 999\n            },\n            {\n                \"name\": \"update_profile\",\n                \"args\": {\n                    \"user_id\": 123,\n                    \"updates\": {\"name\": \"John Doe\"}  # \u2713 Matches\n                }\n            }\n        ]\n    }\n)\n\n# Score is 2/3 = 0.66 (2 out of 3 tools matched)\nprint(f\"Score: {result.score}\")  # 0.66 (proportional!)\n</code></pre>"},{"location":"eval/tool_call_args/#subset-mode-partial-validation","title":"Subset Mode - Partial Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Agent included extra arguments beyond what we're validating\nmock_spans = [\n    ReadableSpan(\n        name=\"send_email\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"send_email\",\n            \"input.value\": \"{'to': 'user@example.com', 'subject': 'Welcome', 'cc': 'admin@example.com', 'body': 'Welcome to our platform!'}\",\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"action\": \"send_welcome\"},\n    agent_output={\"status\": \"sent\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallArgsEvaluator(\n    id=\"args-subset\",\n    config={\n        \"name\": \"ToolCallArgsEvaluator\",\n        \"strict\": False,\n        \"subset\": True\n    }\n)\n\n# Only validate specific arguments, allow extras\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls\": [\n            {\n                \"name\": \"send_email\",\n                \"args\": {\n                    \"to\": \"user@example.com\",\n                    \"subject\": \"Welcome\"\n                    # Agent can include additional args like \"cc\", \"bcc\", \"body\", etc.\n                }\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (subset matches)\n</code></pre>"},{"location":"eval/tool_call_args/#multiple-tool-calls","title":"Multiple Tool Calls","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Agent called multiple tools in sequence\nmock_spans = [\n    ReadableSpan(\n        name=\"validate_input\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"validate_input\",\n            \"input.value\": \"{'data': {'user_id': 123}}\",\n        },\n    ),\n    ReadableSpan(\n        name=\"fetch_user\",\n        start_time=1,\n        end_time=2,\n        attributes={\n            \"tool.name\": \"fetch_user\",\n            \"input.value\": \"{'user_id': 123}\",\n        },\n    ),\n    ReadableSpan(\n        name=\"update_profile\",\n        start_time=2,\n        end_time=3,\n        attributes={\n            \"tool.name\": \"update_profile\",\n            \"input.value\": \"{'user_id': 123, 'updates': {'name': 'John Doe'}}\",\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Update user profile\"},\n    agent_output={\"status\": \"updated\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallArgsEvaluator(\n    id=\"args-multiple\",\n    config={\n        \"name\": \"ToolCallArgsEvaluator\",\n        \"strict\": False,\n        \"subset\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls\": [\n            {\n                \"name\": \"validate_input\",\n                \"args\": {\"data\": {\"user_id\": 123}}\n            },\n            {\n                \"name\": \"fetch_user\",\n                \"args\": {\"user_id\": 123}\n            },\n            {\n                \"name\": \"update_profile\",\n                \"args\": {\n                    \"user_id\": 123,\n                    \"updates\": {\"name\": \"John Doe\"}\n                }\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (all tools match)\n</code></pre>"},{"location":"eval/tool_call_args/#nested-arguments","title":"Nested Arguments","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"create_order\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"create_order\",\n            \"input.value\": \"{'customer': {'id': 123, 'name': 'John Doe', 'address': {'street': '123 Main St', 'city': 'New York', 'zip': '10001'}}, 'items': [{'product_id': 1, 'quantity': 2}, {'product_id': 2, 'quantity': 1}], 'total': 99.99}\",\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Create order\"},\n    agent_output={\"status\": \"created\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallArgsEvaluator(\n    id=\"args-nested\",\n    config={\n        \"name\": \"ToolCallArgsEvaluator\",\n        \"strict\": False,\n        \"subset\": False\n    }\n)\n\n# Validate complex nested structures\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls\": [\n            {\n                \"name\": \"create_order\",\n                \"args\": {\n                    \"customer\": {\n                        \"id\": 123,\n                        \"name\": \"John Doe\",\n                        \"address\": {\n                            \"street\": \"123 Main St\",\n                            \"city\": \"New York\",\n                            \"zip\": \"10001\"\n                        }\n                    },\n                    \"items\": [\n                        {\"product_id\": 1, \"quantity\": 2},\n                        {\"product_id\": 2, \"quantity\": 1}\n                    ],\n                    \"total\": 99.99\n                }\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (nested structure matches)\n</code></pre>"},{"location":"eval/tool_call_args/#justification-details","title":"Justification Details","text":"<p>The evaluator returns a <code>ToolCallArgsEvaluatorJustification</code> with:</p> <pre><code>{\n    \"explained_tool_calls_args\": {\n        \"update_user_0\": \"Actual: {'user_id': 123, 'status': 'active'}, Expected: {'user_id': 123, 'status': 'active'}, Score: 1.0\",\n        \"send_email_0\": \"Actual: {'to': 'user@example.com', 'subject': 'Hello'}, Expected: {'to': 'user@example.com'}, Score: 1.0\",\n        \"log_event_0\": \"Actual: {'type': 'info', 'message': 'Success'}, Expected: {'type': 'info'}, Score: 1.0\"\n    }\n}\n</code></pre>"},{"location":"eval/tool_call_args/#best-practices","title":"Best Practices","text":"<ol> <li>Use non-strict mode by default - Allows for minor numeric or string variations</li> <li>Use subset mode for flexibility - When some arguments are optional or variable</li> <li>Combine with order validation - Use with Tool Call Order Evaluator</li> <li>Test critical parameters in strict mode - For security, authentication, or business-critical params</li> <li>Validate data types - Ensure strings, numbers, booleans are used correctly</li> <li>Test edge cases - Empty strings, null values, zero, negative numbers</li> <li>Consider partial matches - Non-strict mode gives partial credit for similar values</li> </ol>"},{"location":"eval/tool_call_args/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use Tool Call Args when:</p> <ul> <li>Argument values matter</li> <li>Testing data flow correctness</li> <li>Validating parameter transformation</li> <li>Ensuring API contract compliance</li> </ul> <p>Use Tool Call Order when:</p> <ul> <li>Sequence matters more than arguments</li> <li>Testing workflow steps</li> </ul> <p>Use Tool Call Output when:</p> <ul> <li>Validating what tools return</li> <li>Testing tool response handling</li> </ul> <p>Use JSON Similarity when:</p> <ul> <li>Comparing complex outputs (not tool args)</li> <li>General data structure comparison</li> </ul>"},{"location":"eval/tool_call_args/#limitations","title":"Limitations","text":"<ol> <li>Tool name matching - Must match exact tool names from trace</li> <li>Order matters for multiple calls - First expected call matches first actual call of that name</li> <li>No cross-tool validation - Each tool evaluated independently</li> <li>Case-sensitive - Keys and values are case-sensitive</li> </ol>"},{"location":"eval/tool_call_args/#error-handling","title":"Error Handling","text":"<p>The evaluator handles:</p> <ul> <li>Missing tools: Score 0.0 for that tool</li> <li>Extra tools not in criteria: Ignored</li> <li>Missing arguments: Scored based on mode</li> <li>Type mismatches: Scored based on mode (strict vs non-strict)</li> </ul>"},{"location":"eval/tool_call_args/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Fast evaluation: O(n*m) where n = expected calls, m = actual calls</li> <li>No LLM calls: Deterministic and quick</li> <li>JSON similarity overhead: Slightly slower than exact match</li> </ul>"},{"location":"eval/tool_call_args/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Tool Call Order Evaluator: Validates tool call sequences</li> <li>Tool Call Count Evaluator: Validates tool usage frequencies</li> <li>Tool Call Output Evaluator: Validates tool outputs</li> <li>JSON Similarity Evaluator: For general JSON comparison</li> </ul>"},{"location":"eval/tool_call_count/","title":"Tool Call Count Evaluator","text":"<p>The Tool Call Count Evaluator validates that an agent calls tools the expected number of times. This is useful for ensuring proper tool usage patterns, avoiding redundant calls, and verifying workflow completeness.</p>"},{"location":"eval/tool_call_count/#overview","title":"Overview","text":"<p>Evaluator ID: <code>tool-call-count</code></p> <p>Use Cases:</p> <ul> <li>Ensure tools are called the correct number of times</li> <li>Validate no redundant or missing tool calls</li> <li>Test resource usage efficiency</li> <li>Verify loop and retry logic</li> <li>Check API call frequency</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 based on count accuracy</p>"},{"location":"eval/tool_call_count/#configuration","title":"Configuration","text":""},{"location":"eval/tool_call_count/#toolcallcountevaluatorconfig","title":"ToolCallCountEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"ToolCallCountEvaluator\"</code> The evaluator's name <code>strict</code> <code>bool</code> <code>False</code> Controls scoring: True = all-or-nothing (1.0 or 0.0), False = proportional (ratio of matched counts) <code>default_evaluation_criteria</code> <code>ToolCallCountEvaluationCriteria or None</code> <code>None</code> Default criteria"},{"location":"eval/tool_call_count/#strict-vs-non-strict-mode","title":"Strict vs Non-Strict Mode","text":"<ul> <li>Strict mode (<code>strict=True</code>): All-or-nothing - returns 1.0 if ALL counts match, 0.0 if ANY count doesn't match</li> <li>Non-strict mode (<code>strict=False</code>): Proportional scoring - returns ratio of matched counts (e.g., 2/3 match = 0.66)</li> </ul>"},{"location":"eval/tool_call_count/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/tool_call_count/#toolcallcountevaluationcriteria","title":"ToolCallCountEvaluationCriteria","text":"Parameter Type Description <code>tool_calls_count</code> <code>dict[str, tuple[str, int]]</code> Dictionary mapping tool names to (operator, count) tuples"},{"location":"eval/tool_call_count/#supported-operators","title":"Supported Operators","text":"<ul> <li><code>\"=\"</code> or <code>\"==\"</code>: Exactly equal to count</li> <li><code>\"&gt;\"</code>: Greater than count</li> <li><code>\"&lt;\"</code>: Less than count</li> <li><code>\"&gt;=\"</code>: Greater than or equal to count</li> <li><code>\"&lt;=\"</code>: Less than or equal to count</li> </ul>"},{"location":"eval/tool_call_count/#scoring-algorithm","title":"Scoring Algorithm","text":""},{"location":"eval/tool_call_count/#non-strict-mode","title":"Non-Strict Mode","text":"<pre><code>score = correct_tools / total_expected_tools\n</code></pre> <p>Each tool is evaluated independently: - Correct count match = 1.0 for that tool - Incorrect count = 0.0 for that tool - Final score is average across all tools</p>"},{"location":"eval/tool_call_count/#strict-mode","title":"Strict Mode","text":"<ul> <li>Returns <code>1.0</code> if ALL tools match their count criteria</li> <li>Returns <code>0.0</code> if ANY tool fails its count criteria</li> </ul>"},{"location":"eval/tool_call_count/#examples","title":"Examples","text":""},{"location":"eval/tool_call_count/#basic-count-validation","title":"Basic Count Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\nfrom uipath.eval.evaluators import ToolCallCountEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Sample agent execution with tool calls\nmock_spans = [\n    ReadableSpan(name=\"fetch_data\", start_time=0, end_time=1,\n                 attributes={\"tool.name\": \"fetch_data\"}),\n    ReadableSpan(name=\"process_item\", start_time=1, end_time=2,\n                 attributes={\"tool.name\": \"process_item\"}),\n    ReadableSpan(name=\"process_item\", start_time=2, end_time=3,\n                 attributes={\"tool.name\": \"process_item\"}),\n    ReadableSpan(name=\"process_item\", start_time=3, end_time=4,\n                 attributes={\"tool.name\": \"process_item\"}),\n    ReadableSpan(name=\"process_item\", start_time=4, end_time=5,\n                 attributes={\"tool.name\": \"process_item\"}),\n    ReadableSpan(name=\"process_item\", start_time=5, end_time=6,\n                 attributes={\"tool.name\": \"process_item\"}),\n    ReadableSpan(name=\"send_notification\", start_time=6, end_time=7,\n                 attributes={\"tool.name\": \"send_notification\"}),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Fetch and process data\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"count-check-1\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"fetch_data\": (\"=\", 1),      # Called exactly once\n            \"process_item\": (\"=\", 5),    # Called exactly 5 times\n            \"send_notification\": (\"=\", 1)  # Called exactly once\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (all counts match)\nprint(f\"Details: {result.details}\")\n</code></pre>"},{"location":"eval/tool_call_count/#non-strict-mode-proportional-scoring","title":"Non-Strict Mode - Proportional Scoring","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Agent called fetch_data 1x, process_item 3x (expected 5), send_notification 1x\nmock_spans = [\n    ReadableSpan(\n        name=\"fetch_data\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"fetch_data\"},\n    ),\n]\n# Add 3 process_item calls (but we expect 5)\nfor i in range(3):\n    mock_spans.append(\n        ReadableSpan(\n            name=\"process_item\",\n            start_time=1 + i,\n            end_time=2 + i,\n            attributes={\"tool.name\": \"process_item\"},\n        )\n    )\nmock_spans.append(\n    ReadableSpan(\n        name=\"send_notification\",\n        start_time=4,\n        end_time=5,\n        attributes={\"tool.name\": \"send_notification\"},\n    )\n)\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Fetch and process data\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"count-proportional\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": False  # Proportional scoring\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"fetch_data\": (\"=\", 1),           # \u2713 Matches (1 call)\n            \"process_item\": (\"=\", 5),         # \u2717 Doesn't match (3 calls, expected 5)\n            \"send_notification\": (\"=\", 1)     # \u2713 Matches (1 call)\n        }\n    }\n)\n\n# Score is 2/3 = 0.66 (2 out of 3 counts matched)\nprint(f\"Score: {result.score}\")  # 0.66 (proportional!)\n</code></pre>"},{"location":"eval/tool_call_count/#strict-mode-all-or-nothing","title":"Strict Mode - All or Nothing","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Agent made 2 calls but expected 1\nmock_spans = [\n    ReadableSpan(\n        name=\"authenticate\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"authenticate\"},\n    ),\n    ReadableSpan(\n        name=\"fetch_records\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"fetch_records\"},\n    ),\n    ReadableSpan(\n        name=\"fetch_records\",  # DUPLICATE call\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"fetch_records\"},\n    ),\n    ReadableSpan(\n        name=\"close_connection\",\n        start_time=3,\n        end_time=4,\n        attributes={\"tool.name\": \"close_connection\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Database operation\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"count-strict\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": True  # All-or-nothing scoring\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"authenticate\": (\"=\", 1),      # \u2713 Matches (1 call)\n            \"fetch_records\": (\"=\", 1),     # \u2717 Doesn't match (2 calls)\n            \"close_connection\": (\"=\", 1)   # \u2713 Matches (1 call)\n        }\n    }\n)\n\n# Score is 0.0 because ONE count didn't match (strict mode)\nprint(f\"Score: {result.score}\")  # 0.0 (not 0.66!)\n</code></pre>"},{"location":"eval/tool_call_count/#preventing-redundant-calls","title":"Preventing Redundant Calls","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Only one expensive call\nmock_spans = [\n    ReadableSpan(\n        name=\"expensive_api_call\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"expensive_api_call\"},\n    ),\n    ReadableSpan(\n        name=\"database_query\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"database_query\"},\n    ),\n    ReadableSpan(\n        name=\"database_query\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"database_query\"},\n    ),\n    ReadableSpan(\n        name=\"llm_call\",\n        start_time=3,\n        end_time=4,\n        attributes={\"tool.name\": \"llm_call\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Optimize resource usage\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"prevent-redundant\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": False\n    }\n)\n\n# Ensure expensive operations aren't called too many times\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"expensive_api_call\": (\"&lt;=\", 1),  # Should not be called more than once\n            \"database_query\": (\"&lt;=\", 3),      # At most 3 queries\n            \"llm_call\": (\"&lt;=\", 2)             # At most 2 LLM calls\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (all within limits)\n</code></pre>"},{"location":"eval/tool_call_count/#loop-validation","title":"Loop Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Create 10 process_item, 10 validate_item, 10 save_result calls\nmock_spans = []\nfor i in range(10):\n    mock_spans.extend([\n        ReadableSpan(\n            name=\"process_item\",\n            start_time=i * 3,\n            end_time=i * 3 + 1,\n            attributes={\"tool.name\": \"process_item\"},\n        ),\n        ReadableSpan(\n            name=\"validate_item\",\n            start_time=i * 3 + 1,\n            end_time=i * 3 + 2,\n            attributes={\"tool.name\": \"validate_item\"},\n        ),\n        ReadableSpan(\n            name=\"save_result\",\n            start_time=i * 3 + 2,\n            end_time=i * 3 + 3,\n            attributes={\"tool.name\": \"save_result\"},\n        ),\n    ])\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Process 10 items\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"loop-validation\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": False\n    }\n)\n\n# Verify loop processed correct number of items\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"process_item\": (\"=\", 10),  # Should process 10 items\n            \"validate_item\": (\"=\", 10), # Each item should be validated\n            \"save_result\": (\"=\", 10)    # Each result should be saved\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (all counts correct)\n</code></pre>"},{"location":"eval/tool_call_count/#retry-logic-validation","title":"Retry Logic Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Agent attempted operation 2 times, logged retry, got final result\nmock_spans = [\n    ReadableSpan(\n        name=\"attempt_operation\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"attempt_operation\"},\n    ),\n    ReadableSpan(\n        name=\"log_retry\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"log_retry\"},\n    ),\n    ReadableSpan(\n        name=\"attempt_operation\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"attempt_operation\"},\n    ),\n    ReadableSpan(\n        name=\"final_result\",\n        start_time=3,\n        end_time=4,\n        attributes={\"tool.name\": \"final_result\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Retry operation\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"retry-logic\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": False\n    }\n)\n\n# Verify retry logic doesn't exceed limits\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"attempt_operation\": (\"&lt;=\", 3),  # Max 3 retries\n            \"log_retry\": (\"&gt;=\", 1),          # Should log retries\n            \"final_result\": (\"=\", 1)         # Only one final result\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (retry logic correct)\n</code></pre>"},{"location":"eval/tool_call_count/#ensuring-minimum-calls","title":"Ensuring Minimum Calls","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Agent called all required security checks\nmock_spans = [\n    ReadableSpan(\n        name=\"validate_input\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"validate_input\"},\n    ),\n    ReadableSpan(\n        name=\"check_security\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"check_security\"},\n    ),\n    ReadableSpan(\n        name=\"audit_log\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"audit_log\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Secure operation\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallCountEvaluator(\n    id=\"minimum-calls\",\n    config={\n        \"name\": \"ToolCallCountEvaluator\",\n        \"strict\": False\n    }\n)\n\n# Ensure agent calls important tools\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_count\": {\n            \"validate_input\": (\"&gt;=\", 1),    # Must validate at least once\n            \"check_security\": (\"&gt;=\", 1),    # Security check required\n            \"audit_log\": (\"&gt;\", 0)           # Must create audit logs\n        }\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (minimum calls met)\n</code></pre>"},{"location":"eval/tool_call_count/#justification-details","title":"Justification Details","text":"<p>The evaluator returns a <code>ToolCallCountEvaluatorJustification</code> with:</p> <pre><code>{\n    \"explained_tool_calls_count\": {\n        \"fetch_data\": \"Actual: 1, Expected: 1, Score: 1.0\",\n        \"process_item\": \"Actual: 3, Expected: 5, Score: 0.0\",\n        \"send_notification\": \"Actual: 1, Expected: 1, Score: 1.0\"\n    }\n}\n</code></pre>"},{"location":"eval/tool_call_count/#best-practices","title":"Best Practices","text":"<ol> <li>Use for resource-sensitive operations - Database queries, API calls, expensive computations</li> <li>Combine with order validation - Use with Tool Call Order Evaluator for complete validation</li> <li>Set realistic bounds - Use <code>&lt;=</code> and <code>&gt;=</code> for flexible but bounded behavior</li> <li>Use strict mode sparingly - Non-strict provides better debugging information</li> <li>Consider variability - Use ranges (<code>&gt;=</code>, <code>&lt;=</code>) when exact counts might vary</li> <li>Test efficiency - Ensure agents don't make redundant calls</li> </ol>"},{"location":"eval/tool_call_count/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use Tool Call Count when:</p> <ul> <li>Tool usage frequency matters</li> <li>Testing efficiency and optimization</li> <li>Validating retry logic</li> <li>Ensuring resource constraints</li> </ul> <p>Use Tool Call Order when:</p> <ul> <li>Sequence matters more than count</li> <li>Workflow has specific steps</li> <li>Dependencies exist between tools</li> </ul> <p>Use Tool Call Args when:</p> <ul> <li>Tool parameters need validation</li> <li>Specific argument values matter</li> <li>Testing data flow through tools</li> </ul>"},{"location":"eval/tool_call_count/#limitations","title":"Limitations","text":"<ol> <li>Case-sensitive tool names - Must match exactly</li> <li>No temporal information - Doesn't know when calls happened</li> <li>No context awareness - Doesn't understand why counts differ</li> <li>All tools independent - Each tool evaluated separately</li> </ol>"},{"location":"eval/tool_call_count/#error-handling","title":"Error Handling","text":"<p>The evaluator handles:</p> <ul> <li>Missing tools in actual calls: Count as 0</li> <li>Extra tools not in criteria: Ignored</li> <li>Invalid operators: Raises validation error</li> <li>Negative counts: Raises validation error</li> </ul>"},{"location":"eval/tool_call_count/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Fast evaluation: O(n) where n is number of tools</li> <li>No LLM calls: Deterministic and instant</li> <li>Low memory: Efficient for large call counts</li> </ul>"},{"location":"eval/tool_call_count/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Tool Call Order Evaluator: Validates tool call sequences</li> <li>Tool Call Args Evaluator: Validates tool arguments</li> <li>Tool Call Output Evaluator: Validates tool outputs</li> <li>LLM Judge Trajectory Evaluator: For semantic evaluation</li> </ul>"},{"location":"eval/tool_call_order/","title":"Tool Call Order Evaluator","text":"<p>The Tool Call Order Evaluator validates that an agent calls tools in the expected sequence. This is crucial for workflows where the order of operations matters for correctness, data integrity, or business logic.</p>"},{"location":"eval/tool_call_order/#overview","title":"Overview","text":"<p>Evaluator ID: <code>tool-call-order</code></p> <p>Use Cases:</p> <ul> <li>Validate critical operation sequences (e.g., authenticate before access)</li> <li>Ensure workflow steps follow business logic</li> <li>Test that agents follow prescribed procedures</li> <li>Verify proper data pipeline execution order</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 based on sequence match</p>"},{"location":"eval/tool_call_order/#configuration","title":"Configuration","text":""},{"location":"eval/tool_call_order/#toolcallorderevaluatorconfig","title":"ToolCallOrderEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"ToolCallOrderEvaluator\"</code> The evaluator's name <code>strict</code> <code>bool</code> <code>False</code> If True, requires exact sequence match; if False, uses LCS (Longest Common Subsequence) <code>default_evaluation_criteria</code> <code>ToolCallOrderEvaluationCriteria or None</code> <code>None</code> Default criteria"},{"location":"eval/tool_call_order/#strict-vs-non-strict-mode","title":"Strict vs Non-Strict Mode","text":"<ul> <li>Strict mode (<code>strict=True</code>): Requires exact sequence match, score is 1.0 or 0.0</li> <li>Non-strict mode (<code>strict=False</code>): Uses LCS algorithm, allows partial credit for subsequences</li> </ul>"},{"location":"eval/tool_call_order/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/tool_call_order/#toolcallorderevaluationcriteria","title":"ToolCallOrderEvaluationCriteria","text":"Parameter Type Description <code>tool_calls_order</code> <code>list[str]</code> Ordered list of expected tool names"},{"location":"eval/tool_call_order/#scoring-algorithm","title":"Scoring Algorithm","text":""},{"location":"eval/tool_call_order/#non-strict-mode-lcs-based","title":"Non-Strict Mode (LCS-based)","text":"<p>The score is calculated as:</p> <pre><code>score = length(LCS) / length(expected_sequence)\n</code></pre> <p>Where LCS is the Longest Common Subsequence between expected and actual tool call sequences.</p> <p>Example: - Expected: <code>[\"A\", \"B\", \"C\", \"D\"]</code> - Actual: <code>[\"A\", \"X\", \"B\", \"D\"]</code> - LCS: <code>[\"A\", \"B\", \"D\"]</code> (length 3) - Score: <code>3/4 = 0.75</code></p>"},{"location":"eval/tool_call_order/#strict-mode","title":"Strict Mode","text":"<ul> <li>Returns <code>1.0</code> if sequences match exactly</li> <li>Returns <code>0.0</code> if any difference exists</li> </ul>"},{"location":"eval/tool_call_order/#examples","title":"Examples","text":""},{"location":"eval/tool_call_order/#basic-tool-call-order-validation","title":"Basic Tool Call Order Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\nfrom uipath.eval.evaluators import ToolCallOrderEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Create mock spans representing tool calls in execution trace\nmock_spans = [\n    ReadableSpan(\n        name=\"validate_user\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"validate_user\"},\n    ),\n    ReadableSpan(\n        name=\"check_inventory\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"check_inventory\"},\n    ),\n    ReadableSpan(\n        name=\"create_order\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"create_order\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Process user order\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOrderEvaluator(\n    id=\"order-check-1\",\n    config={\n        \"name\": \"ToolCallOrderEvaluator\",\n        \"strict\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_order\": [\n            \"validate_user\",\n            \"check_inventory\",\n            \"create_order\"\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (perfect match)\nprint(f\"Details: {result.details}\")\n# Details includes: actual order, expected order, and LCS\n</code></pre>"},{"location":"eval/tool_call_order/#strict-order-validation","title":"Strict Order Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Critical security sequence\nmock_spans = [\n    ReadableSpan(\n        name=\"authenticate_user\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"authenticate_user\"},\n    ),\n    ReadableSpan(\n        name=\"verify_permissions\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"verify_permissions\"},\n    ),\n    ReadableSpan(\n        name=\"access_resource\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"access_resource\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Access secured resource\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOrderEvaluator(\n    id=\"order-strict\",\n    config={\n        \"name\": \"ToolCallOrderEvaluator\",\n        \"strict\": True\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_order\": [\n            \"authenticate_user\",\n            \"verify_permissions\",\n            \"access_resource\"\n        ]\n    }\n)\n\n# Score is either 1.0 (perfect match) or 0.0 (any mismatch)\nprint(f\"Score: {result.score}\")  # 1.0\n</code></pre>"},{"location":"eval/tool_call_order/#partial-credit-with-lcs","title":"Partial Credit with LCS","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Actual execution (missing \"sort\")\nmock_spans = [\n    ReadableSpan(\n        name=\"search\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"search\"},\n    ),\n    ReadableSpan(\n        name=\"filter\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"filter\"},\n    ),\n    ReadableSpan(\n        name=\"display\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"display\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Search and display\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOrderEvaluator(\n    id=\"order-lcs\",\n    config={\n        \"name\": \"ToolCallOrderEvaluator\",\n        \"strict\": False  # Use LCS for partial credit\n    }\n)\n\n# Expected sequence\nexpected = [\"search\", \"filter\", \"sort\", \"display\"]\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_order\": expected\n    }\n)\n\n# Score: 3/4 = 0.75 (3 tools in correct order out of 4 expected)\nprint(f\"Score: {result.score}\")  # 0.75\nprint(f\"LCS: {result.details.lcs}\")  # [\"search\", \"filter\", \"display\"]\n</code></pre>"},{"location":"eval/tool_call_order/#database-transaction-sequence","title":"Database Transaction Sequence","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"begin_transaction\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"begin_transaction\"},\n    ),\n    ReadableSpan(\n        name=\"validate_data\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"validate_data\"},\n    ),\n    ReadableSpan(\n        name=\"update_records\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"update_records\"},\n    ),\n    ReadableSpan(\n        name=\"commit_transaction\",\n        start_time=3,\n        end_time=4,\n        attributes={\"tool.name\": \"commit_transaction\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Update database\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOrderEvaluator(\n    id=\"db-transaction\",\n    config={\n        \"name\": \"ToolCallOrderEvaluator\",\n        \"strict\": True  # Transactions must be exact\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_order\": [\n            \"begin_transaction\",\n            \"validate_data\",\n            \"update_records\",\n            \"commit_transaction\"\n        ]\n    }\n)\n\n# Must match exactly for data integrity\nprint(f\"Score: {result.score}\")  # 1.0\n</code></pre>"},{"location":"eval/tool_call_order/#api-integration-workflow","title":"API Integration Workflow","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"get_api_token\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"get_api_token\"},\n    ),\n    ReadableSpan(\n        name=\"fetch_user_data\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"fetch_user_data\"},\n    ),\n    ReadableSpan(\n        name=\"enrich_data\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"enrich_data\"},\n    ),\n    ReadableSpan(\n        name=\"post_to_webhook\",\n        start_time=3,\n        end_time=4,\n        attributes={\"tool.name\": \"post_to_webhook\"},\n    ),\n    ReadableSpan(\n        name=\"log_result\",\n        start_time=4,\n        end_time=5,\n        attributes={\"tool.name\": \"log_result\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"API integration\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOrderEvaluator(\n    id=\"api-workflow\",\n    config={\n        \"name\": \"ToolCallOrderEvaluator\",\n        \"strict\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_calls_order\": [\n            \"get_api_token\",\n            \"fetch_user_data\",\n            \"enrich_data\",\n            \"post_to_webhook\",\n            \"log_result\"\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0\n</code></pre>"},{"location":"eval/tool_call_order/#using-default-criteria","title":"Using Default Criteria","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"init\",\n        start_time=0,\n        end_time=1,\n        attributes={\"tool.name\": \"init\"},\n    ),\n    ReadableSpan(\n        name=\"process\",\n        start_time=1,\n        end_time=2,\n        attributes={\"tool.name\": \"process\"},\n    ),\n    ReadableSpan(\n        name=\"cleanup\",\n        start_time=2,\n        end_time=3,\n        attributes={\"tool.name\": \"cleanup\"},\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Standard workflow\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOrderEvaluator(\n    id=\"order-default\",\n    config={\n        \"name\": \"ToolCallOrderEvaluator\",\n        \"strict\": False,\n        \"default_evaluation_criteria\": {\n            \"tool_calls_order\": [\"init\", \"process\", \"cleanup\"]\n        }\n    }\n)\n\n# Use default criteria\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria=None  # Uses default\n)\n\nprint(f\"Score: {result.score}\")  # 1.0\n</code></pre>"},{"location":"eval/tool_call_order/#justification-details","title":"Justification Details","text":"<p>The evaluator returns a <code>ToolCallOrderEvaluatorJustification</code> (inherits from <code>BaseEvaluatorJustification</code>) with:</p> <pre><code>{\n    \"expected\": \"['tool1', 'tool2', 'tool3', 'tool4']\",  # What was expected\n    \"actual\": \"['tool1', 'tool2', 'tool3']\",  # What the agent called\n    \"lcs\": [\"tool1\", \"tool2\", \"tool3\"]  # Longest common subsequence (non-strict mode)\n}\n</code></pre>"},{"location":"eval/tool_call_order/#best-practices","title":"Best Practices","text":"<ol> <li>Use strict mode for critical sequences - Authentication, transactions, data integrity workflows</li> <li>Use non-strict mode for flexible workflows - When some steps might be optional or reorderable</li> <li>Combine with other evaluators - Use with Tool Call Count and Tool Call Args</li> <li>Be specific with tool names - Ensure tool names in criteria match exactly (case-sensitive)</li> <li>Consider repeated calls - If a tool should be called multiple times, list it multiple times</li> <li>Test partial workflows - Use non-strict mode during development, strict in production</li> </ol>"},{"location":"eval/tool_call_order/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use Tool Call Order when:</p> <ul> <li>Sequence of operations is important</li> <li>Workflow has defined steps</li> <li>Business logic requires specific order</li> <li>Data dependencies exist between steps</li> </ul> <p>Use Tool Call Count when:</p> <ul> <li>Order doesn't matter, only frequency</li> <li>Testing tool usage patterns</li> <li>Ensuring tools are called correct number of times</li> </ul> <p>Use LLM Judge Trajectory when:</p> <ul> <li>More flexible, semantic evaluation needed</li> <li>Decision-making process is complex</li> <li>Exact sequences are less important than overall behavior</li> </ul>"},{"location":"eval/tool_call_order/#limitations","title":"Limitations","text":"<ol> <li>Case-sensitive matching - Tool names must match exactly</li> <li>No argument validation - Only checks tool names, not arguments (use Tool Call Args Evaluator)</li> <li>Position-based - Doesn't consider parallel execution</li> <li>Multiple calls - Each call is treated as separate position in sequence</li> </ol>"},{"location":"eval/tool_call_order/#error-handling","title":"Error Handling","text":"<p>The evaluator handles these scenarios gracefully:</p> <ul> <li>Empty actual calls: Score 0.0</li> <li>Empty expected calls: Error (invalid criteria)</li> <li>Missing tools in trace: Extracts only tool calls found</li> <li>Extra tools called: In non-strict mode, uses LCS; in strict mode, score 0.0</li> </ul>"},{"location":"eval/tool_call_order/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Fast evaluation: O(n*m) for LCS algorithm</li> <li>No LLM calls: Deterministic and quick</li> <li>Low memory: Efficient for large sequences</li> </ul>"},{"location":"eval/tool_call_order/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Tool Call Count Evaluator: Validates tool usage frequencies</li> <li>Tool Call Args Evaluator: Validates tool arguments</li> <li>Tool Call Output Evaluator: Validates tool outputs</li> <li>LLM Judge Trajectory Evaluator: For semantic trajectory evaluation</li> </ul>"},{"location":"eval/tool_call_output/","title":"Tool Call Output Evaluator","text":"<p>The Tool Call Output Evaluator validates that tools return the expected outputs. This is crucial for testing tool integrations, verifying data transformations, and ensuring that agents correctly handle tool responses.</p>"},{"location":"eval/tool_call_output/#overview","title":"Overview","text":"<p>Evaluator ID: <code>tool-call-output</code></p> <p>Use Cases:</p> <ul> <li>Validate tool return values</li> <li>Test tool integration correctness</li> <li>Verify data processing results</li> <li>Ensure proper error handling</li> <li>Check API response handling</li> </ul> <p>Returns: Continuous score from 0.0 to 1.0 based on output accuracy</p>"},{"location":"eval/tool_call_output/#configuration","title":"Configuration","text":""},{"location":"eval/tool_call_output/#toolcalloutputevaluatorconfig","title":"ToolCallOutputEvaluatorConfig","text":"Parameter Type Default Description <code>name</code> <code>str</code> <code>\"ToolCallOutputEvaluator\"</code> The evaluator's name <code>strict</code> <code>bool</code> <code>False</code> Controls scoring when multiple tools expected: True = all-or-nothing (1.0 or 0.0), False = proportional (ratio of matched outputs) <code>default_evaluation_criteria</code> <code>ToolCallOutputEvaluationCriteria or None</code> <code>None</code> Default criteria"},{"location":"eval/tool_call_output/#evaluation-modes","title":"Evaluation Modes","text":"<ul> <li>Strict mode (<code>strict=True</code>): All-or-nothing - returns 1.0 if ALL outputs match, 0.0 if ANY output doesn't match</li> <li>Non-strict mode (<code>strict=False</code>): Proportional scoring - returns ratio of matched outputs (e.g., 2/3 match = 0.66)</li> </ul>"},{"location":"eval/tool_call_output/#evaluation-criteria","title":"Evaluation Criteria","text":""},{"location":"eval/tool_call_output/#toolcalloutputevaluationcriteria","title":"ToolCallOutputEvaluationCriteria","text":"Parameter Type Description <code>tool_outputs</code> <code>list[ToolOutput]</code> List of expected tool outputs"},{"location":"eval/tool_call_output/#tooloutput-structure","title":"ToolOutput Structure","text":"<pre><code>{\n    \"name\": \"tool_name\",        # Tool name\n    \"output\": {...}             # Expected output value\n}\n</code></pre>"},{"location":"eval/tool_call_output/#scoring-algorithm","title":"Scoring Algorithm","text":"<p>For each expected tool output: 1. Find matching tool calls by name in the trace 2. Compare actual output with expected output 3. Use strict or JSON similarity comparison based on mode</p> <p>Final score: Average across all expected tool outputs</p>"},{"location":"eval/tool_call_output/#examples","title":"Examples","text":""},{"location":"eval/tool_call_output/#basic-output-validation","title":"Basic Output Validation","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\nfrom uipath.eval.evaluators import ToolCallOutputEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Sample agent execution with tool calls and outputs\nmock_spans = [\n    ReadableSpan(\n        name=\"get_user\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"get_user\",\n            \"output.value\": '{\"content\": \"{\\\\\"user_id\\\\\": 123, \\\\\"name\\\\\": \\\\\"John Doe\\\\\", \\\\\"email\\\\\": \\\\\"john@example.com\\\\\", \\\\\"status\\\\\": \\\\\"active\\\\\"}\"}',\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"user_id\": 123},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOutputEvaluator(\n    id=\"output-check-1\",\n    config={\n        \"name\": \"ToolCallOutputEvaluator\",\n        \"strict\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_outputs\": [\n            {\n                \"name\": \"get_user\",\n                \"output\": '{\"user_id\": 123, \"name\": \"John Doe\", \"email\": \"john@example.com\", \"status\": \"active\"}'\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (exact match)\nprint(f\"Details: {result.details}\")\n</code></pre>"},{"location":"eval/tool_call_output/#strict-mode-exact-output-matching","title":"Strict Mode - Exact Output Matching","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"calculate_total\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"calculate_total\",\n            \"output.value\": '{\"content\": \"{\\\\\"total\\\\\": 99.99, \\\\\"currency\\\\\": \\\\\"USD\\\\\"}\"}',\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"items\": [\"item1\", \"item2\"]},\n    agent_output={\"status\": \"calculated\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOutputEvaluator(\n    id=\"output-strict\",\n    config={\n        \"name\": \"ToolCallOutputEvaluator\",\n        \"strict\": True\n    }\n)\n\n# Outputs must match exactly\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_outputs\": [\n            {\n                \"name\": \"calculate_total\",\n                \"output\": {\"total\": 99.99, \"currency\": \"USD\"}\n            }\n        ]\n    }\n)\n\n# Score is 1.0 only if output matches exactly\nprint(f\"Score: {result.score}\")  # 1.0\n</code></pre>"},{"location":"eval/tool_call_output/#non-strict-mode-proportional-scoring","title":"Non-Strict Mode - Proportional Scoring","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\nfrom uipath.eval.evaluators import ToolCallOutputEvaluator\nfrom uipath.eval.models import AgentExecution\n\n# Agent produced 3 outputs, but only 2 match expected\nmock_spans = [\n    ReadableSpan(\n        name=\"fetch_data\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"fetch_data\",\n            \"output.value\": '{\"content\": \"{\\\\\"records\\\\\": 150, \\\\\"status\\\\\": \\\\\"success\\\\\"}\"}',  # \u2713 Matches\n        },\n    ),\n    ReadableSpan(\n        name=\"process_data\",\n        start_time=1,\n        end_time=2,\n        attributes={\n            \"tool.name\": \"process_data\",\n            \"output.value\": '{\"content\": \"{\\\\\"processed\\\\\": 100, \\\\\"errors\\\\\": 5}\"}',  # \u2717 Wrong values\n        },\n    ),\n    ReadableSpan(\n        name=\"save_results\",\n        start_time=2,\n        end_time=3,\n        attributes={\n            \"tool.name\": \"save_results\",\n            \"output.value\": '{\"content\": \"{\\\\\"saved\\\\\": 150, \\\\\"location\\\\\": \\\\\"/data/results.csv\\\\\"}\"}',  # \u2713 Matches\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Process data pipeline\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOutputEvaluator(\n    id=\"output-proportional\",\n    config={\n        \"name\": \"ToolCallOutputEvaluator\",\n        \"strict\": False  # Proportional scoring\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_outputs\": [\n            {\n                \"name\": \"fetch_data\",\n                \"output\": '{\"records\": 150, \"status\": \"success\"}'  # \u2713 Matches\n            },\n            {\n                \"name\": \"process_data\",\n                \"output\": '{\"processed\": 150, \"errors\": 0}'  # \u2717 Actual had errors: 5\n            },\n            {\n                \"name\": \"save_results\",\n                \"output\": '{\"saved\": 150, \"location\": \"/data/results.csv\"}'  # \u2713 Matches\n            }\n        ]\n    }\n)\n\n# Score is 2/3 = 0.66 (2 out of 3 outputs matched)\nprint(f\"Score: {result.score}\")  # 0.66 (proportional!)\n</code></pre>"},{"location":"eval/tool_call_output/#multiple-tool-outputs","title":"Multiple Tool Outputs","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\n# Multiple tools called in sequence\nmock_spans = [\n    ReadableSpan(\n        name=\"fetch_data\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"fetch_data\",\n            \"output.value\": '{\"content\": \"{\\\\\"records\\\\\": 150, \\\\\"status\\\\\": \\\\\"success\\\\\"}\"}',\n        },\n    ),\n    ReadableSpan(\n        name=\"process_data\",\n        start_time=1,\n        end_time=2,\n        attributes={\n            \"tool.name\": \"process_data\",\n            \"output.value\": '{\"content\": \"{\\\\\"processed\\\\\": 150, \\\\\"errors\\\\\": 0}\"}',\n        },\n    ),\n    ReadableSpan(\n        name=\"save_results\",\n        start_time=2,\n        end_time=3,\n        attributes={\n            \"tool.name\": \"save_results\",\n            \"output.value\": '{\"content\": \"{\\\\\"saved\\\\\": 150, \\\\\"location\\\\\": \\\\\"/data/results.csv\\\\\"}\"}',\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Process data pipeline\"},\n    agent_output={\"status\": \"completed\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOutputEvaluator(\n    id=\"output-multiple\",\n    config={\n        \"name\": \"ToolCallOutputEvaluator\",\n        \"strict\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_outputs\": [\n            {\n                \"name\": \"fetch_data\",\n                \"output\": {\"records\": 150, \"status\": \"success\"}\n            },\n            {\n                \"name\": \"process_data\",\n                \"output\": {\"processed\": 150, \"errors\": 0}\n            },\n            {\n                \"name\": \"save_results\",\n                \"output\": {\"saved\": 150, \"location\": \"/data/results.csv\"}\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (all outputs match)\n</code></pre>"},{"location":"eval/tool_call_output/#complex-nested-outputs","title":"Complex Nested Outputs","text":"<pre><code>from opentelemetry.sdk.trace import ReadableSpan\n\nmock_spans = [\n    ReadableSpan(\n        name=\"generate_report\",\n        start_time=0,\n        end_time=1,\n        attributes={\n            \"tool.name\": \"generate_report\",\n            \"output.value\": '{\"content\": \"{\\\\\"report_id\\\\\": \\\\\"RPT-001\\\\\", \\\\\"summary\\\\\": {\\\\\"total_records\\\\\": 1000, \\\\\"processed\\\\\": 950, \\\\\"errors\\\\\": 50}, \\\\\"details\\\\\": [{\\\\\"category\\\\\": \\\\\"A\\\\\", \\\\\"count\\\\\": 400}, {\\\\\"category\\\\\": \\\\\"B\\\\\", \\\\\"count\\\\\": 350}, {\\\\\"category\\\\\": \\\\\"C\\\\\", \\\\\"count\\\\\": 200}], \\\\\"metadata\\\\\": {\\\\\"generated_at\\\\\": \\\\\"2024-01-01T12:00:00Z\\\\\", \\\\\"version\\\\\": \\\\\"1.0\\\\\"}}\"}',\n        },\n    ),\n]\n\nagent_execution = AgentExecution(\n    agent_input={\"task\": \"Generate report\"},\n    agent_output={\"status\": \"generated\"},\n    agent_trace=mock_spans,\n)\n\nevaluator = ToolCallOutputEvaluator(\n    id=\"nested-output\",\n    config={\n        \"name\": \"ToolCallOutputEvaluator\",\n        \"strict\": False\n    }\n)\n\nresult = await evaluator.validate_and_evaluate_criteria(\n    agent_execution=agent_execution,\n    evaluation_criteria={\n        \"tool_outputs\": [\n            {\n                \"name\": \"generate_report\",\n                \"output\": {\n                    \"report_id\": \"RPT-001\",\n                    \"summary\": {\n                        \"total_records\": 1000,\n                        \"processed\": 950,\n                        \"errors\": 50\n                    },\n                    \"details\": [\n                        {\"category\": \"A\", \"count\": 400},\n                        {\"category\": \"B\", \"count\": 350},\n                        {\"category\": \"C\", \"count\": 200}\n                    ],\n                    \"metadata\": {\n                        \"generated_at\": \"2024-01-01T12:00:00Z\",\n                        \"version\": \"1.0\"\n                    }\n                }\n            }\n        ]\n    }\n)\n\nprint(f\"Score: {result.score}\")  # 1.0 (nested output matches)\n</code></pre>"},{"location":"eval/tool_call_output/#justification-details","title":"Justification Details","text":"<p>The evaluator returns a <code>ToolCallOutputEvaluatorJustification</code> with:</p> <pre><code>{\n    \"explained_tool_calls_outputs\": {\n        \"get_user_0\": \"Actual: {'user_id': 123, 'name': 'John Doe'}, Expected: {'user_id': 123, 'name': 'John Doe'}, Score: 1.0\",\n        \"calculate_total_0\": \"Actual: {'total': 99.99}, Expected: {'total': 99.99}, Score: 1.0\",\n        \"api_request_0\": \"Actual: {'status': 200, 'data': {}}, Expected: {'status': 200, 'data': {}}, Score: 1.0\"\n    }\n}\n</code></pre>"},{"location":"eval/tool_call_output/#best-practices","title":"Best Practices","text":"<ol> <li>Use non-strict mode by default - Allows for minor variations in outputs</li> <li>Use strict mode for critical outputs - Boolean flags, status codes, exact values</li> <li>Validate key fields - Focus on important output fields</li> <li>Test error scenarios - Verify tools return proper error outputs</li> <li>Consider data types - Ensure strings, numbers, booleans are correct</li> <li>Test edge cases - Empty responses, null values, error conditions</li> <li>Combine with other evaluators - Use with Tool Call Args for complete validation</li> </ol>"},{"location":"eval/tool_call_output/#when-to-use-vs-other-evaluators","title":"When to Use vs Other Evaluators","text":"<p>Use Tool Call Output when:</p> <ul> <li>Tool return values need validation</li> <li>Testing tool integration correctness</li> <li>Verifying data processing results</li> <li>Ensuring proper error handling</li> </ul> <p>Use Tool Call Args when:</p> <ul> <li>Validating inputs to tools (not outputs)</li> <li>Testing parameter passing</li> </ul> <p>Use Output Evaluator when:</p> <ul> <li>Validating final agent output (not tool outputs)</li> <li>Testing overall result</li> </ul> <p>Use JSON Similarity when:</p> <ul> <li>Comparing general data structures</li> <li>Not specifically tool outputs</li> </ul>"},{"location":"eval/tool_call_output/#limitations","title":"Limitations","text":"<ol> <li>Tool name matching - Must match exact tool names from trace</li> <li>Order matters - First expected output matches first actual call of that tool</li> <li>No temporal validation - Doesn't verify when outputs occurred</li> <li>Case-sensitive - Keys and values are case-sensitive</li> </ol>"},{"location":"eval/tool_call_output/#error-handling","title":"Error Handling","text":"<p>The evaluator handles:</p> <ul> <li>Missing tools: Score 0.0 for that tool</li> <li>Extra tool calls not in criteria: Ignored</li> <li>Null/empty outputs: Compared based on mode</li> <li>Type mismatches: Scored based on mode</li> </ul>"},{"location":"eval/tool_call_output/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Fast evaluation: O(n*m) where n = expected outputs, m = actual tool calls</li> <li>No LLM calls: Deterministic and quick</li> <li>JSON similarity overhead: Slightly slower than exact match</li> </ul>"},{"location":"eval/tool_call_output/#related-evaluators","title":"Related Evaluators","text":"<ul> <li>Tool Call Args Evaluator: Validates tool arguments (inputs)</li> <li>Tool Call Order Evaluator: Validates tool call sequences</li> <li>Tool Call Count Evaluator: Validates tool usage frequencies</li> <li>Output Evaluator: For final agent outputs</li> <li>JSON Similarity Evaluator: For general JSON comparison</li> </ul>"},{"location":"langchain/chat_models/","title":"Chat Models","text":"<p>UiPath provides two chat models <code>UiPathAzureChatOpenAI</code> and <code>UiPathChat</code>. These are compatible with LangGraph as drop in replacements. You do not need to add tokens from OpenAI or Anthropic, usage of these chat models will consume <code>Agent Units</code> on your account.</p>"},{"location":"langchain/chat_models/#uipathazurechatopenai","title":"UiPathAzureChatOpenAI","text":"<p><code>UiPathAzureChatOpenAI</code> can be used as a drop in replacement for <code>ChatOpenAI</code> or <code>AzureChatOpenAI</code>.</p>"},{"location":"langchain/chat_models/#example-usage","title":"Example usage","text":"<p>Here is a code that is using <code>ChatOpenAI</code></p> <pre><code>from langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    model=\"gpt-4o\",\n    temperature=0,\n    max_tokens=4000,\n    timeout=30,\n    max_retries=2,\n    # api_key=\"...\",  # if you prefer to pass api key in directly instead of using env vars\n    # base_url=\"...\",\n    # organization=\"...\",\n    # other params...\n)\n</code></pre> <p>You can simply change <code>ChatOpenAi</code> with <code>UiPathAzureChatOpenAI</code>, you don't have to provide an OpenAI token.</p> <pre><code>from uipath_langchain.chat.models import UiPathAzureChatOpenAI\n\nllm = UiPathAzureChatOpenAI(\n    model=\"gpt-4.1-mini-2025-04-14\",\n    temperature=0,\n    max_tokens=4000,\n    timeout=30,\n    max_retries=2,\n    # other params...\n)\n</code></pre> <p>Currently, the following models can be used with <code>UiPathAzureChatOpenAI</code> (this list can be updated in the future):</p> <ul> <li><code>gpt-4</code>, <code>gpt-4-1106-Preview</code>, <code>gpt-4-32k</code>, <code>gpt-4-turbo-2024-04-09</code>, <code>gpt-4-vision-preview</code>, <code>gpt-4o-2024-05-13</code>, <code>gpt-4o-2024-08-06</code>, <code>gpt-4o-mini-2024-07-18</code>, <code>gpt-4.1-mini-2025-04-14</code>, <code>o3-mini-2025-01-31</code></li> </ul>"},{"location":"langchain/chat_models/#uipathchat","title":"UiPathChat","text":"<p><code>UiPathChat</code> is a more versatile class that can suport models from diferent vendors including OpenAI.</p>"},{"location":"langchain/chat_models/#example-usage_1","title":"Example usage","text":"<p>Given the following code:</p> <pre><code>from langchain_anthropic import ChatAnthropic\n\nllm = ChatAnthropic(\n    model=\"claude-3-5-sonnet-20240620\",\n    temperature=0,\n    max_tokens=1024,\n    timeout=None,\n    max_retries=2,\n    # other params...\n)\n</code></pre> <p>You can replace it with <code>UiPathChat</code> like so:</p> <pre><code>from uipath_langchain.chat.models import UiPathChat\n\nllm = UiPathChat(\n    model=\"anthropic.claude-3-opus-20240229-v1:0\",\n    temperature=0,\n    max_tokens=1024,\n    timeout=None,\n    max_retries=2,\n    # other params...\n)\n</code></pre> <p>Currently the following models can be used with <code>UiPathChat</code> (this list can be updated in the future):</p> <ul> <li><code>anthropic.claude-3-5-sonnet-20240620-v1:0</code>, <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code>, <code>anthropic.claude-3-7-sonnet-20250219-v1:0</code>, <code>anthropic.claude-3-haiku-20240307-v1:0</code>, <code>gemini-1.5-pro-001</code>, <code>gemini-2.0-flash-001</code>, <code>gpt-4o-2024-05-13</code>, <code>gpt-4o-2024-08-06</code>, <code>gpt-4o-2024-11-20</code>, <code>gpt-4o-mini-2024-07-18</code>, <code>o3-mini-2025-01-31</code></li> </ul> <p>Warning</p> <p>Please note that you may get errors related to data residency, as some models are not available on all regions.</p> <p>Example: <code>[Enforced Region] No model configuration found for product uipath-python-sdk in EU using model anthropic.claude-3-opus-20240229-v1:0</code>.</p>"},{"location":"langchain/context_grounding/","title":"Context Grounding","text":"<p>Context Grounding Service allows you to:</p> <ul> <li>Search through indexed documents using natural language queries</li> <li>Ground LLM responses in your organization's specific information</li> <li>Retrieve context-relevant documents for various applications</li> </ul> <p>You will need to create an index in <code>Context Grounding</code> to use this feature. To create an index go to organization <code>Orchestrator</code> -&gt; the folder where you'd like to create an index -&gt; <code>Indexes</code>. There you can create a new index from a storage bucket which you've added documents to. See the full documentation here for more details.</p>"},{"location":"langchain/context_grounding/#contextgroundingretriever","title":"ContextGroundingRetriever","text":"<p>The <code>ContextGroundingRetriever</code> is a document retrieval system that uses vector search to efficiently find and retrieve relevant information from your document store.</p>"},{"location":"langchain/context_grounding/#basic-usage","title":"Basic Usage","text":"<p>Create a simple retriever by specifying an index name:</p> <pre><code>from uipath_langchain.retrievers import ContextGroundingRetriever\n\nretriever = ContextGroundingRetriever(index_name = \"Company Policy Context\")\nprint(retriever.invoke(\"What is the company policy on remote work?\"))\n</code></pre>"},{"location":"langchain/context_grounding/#integration-with-langchain-tools","title":"Integration with LangChain Tools","text":"<p>You can easily integrate the retriever with LangChain's tool system:</p> <pre><code>from langchain.agents import create_agent\nfrom langchain_core.tools.retriever import create_retriever_tool\nfrom uipath_langchain.retrievers import ContextGroundingRetriever\n\nretriever = ContextGroundingRetriever(index_name = \"Company Policy Context\")\nretriever_tool = create_retriever_tool(\n    retriever,\n    \"ContextforInvoiceDisputeInvestigation\",\n   \"\"\"\n   Use this tool to search the company internal documents for information about policies around dispute resolution.\n   Use a meaningful query to load relevant information from the documents. Save the citation for later use.\n   \"\"\"\n)\n\n# You can use the tool in your agents\nmodel = OpenAI()\ntools = [retriever_tool]\nagent = create_agent(model, tools, system_prompt=\"Answer user questions as best as you can using the search tool.\")\n</code></pre>"},{"location":"langchain/context_grounding/#advanced-usage","title":"Advanced Usage","text":"<p>For complex applications, the retriever can be combined with other LangChain components to create robust document QA systems, agents, or knowledge bases.</p>"},{"location":"langchain/context_grounding/#contextgroundingvectorstore","title":"ContextGroundingVectorStore","text":"<p><code>ContextGroundingVectorStore</code> is a vector store implementation designed for context-aware document retrieval. It allows you to perform semantic searches and create retrieval chains with language models.</p>"},{"location":"langchain/context_grounding/#searching-documents","title":"Searching Documents","text":"<p>The vector store supports various search methods:</p> <pre><code>from uipath_langchain.vectorstores.context_grounding_vectorstore import ContextGroundingVectorStore\n\nvectorstore = ContextGroundingVectorStore(index_name=\"Company policy\")\n\n# Perform semantic searches with distance scores\ndocs_with_scores = vectorstore.asimilarity_search_with_score(query=\"What is the company policy on data storage?\", k=5)\n\n# Perform a similarity search with relevance scores\ndocs_with_relevance_scores = await vectorstore.asimilarity_search_with_relevance_scores(query=query, k=5)\n</code></pre>"},{"location":"langchain/context_grounding/#creating-a-retrieval-chain","title":"Creating a Retrieval Chain","text":"<p>You can integrate the vector store into a retrieval chain with a language model:</p> <pre><code># Run a retrieval chain\nmodel = UiPathAzureChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\", max_retries=3)\nretrieval_chain = create_retrieval_chain(vectorstore=vectorstore, model=model)\n\nquery = \"What is the ECCN for a laptop?\"\nresult = retrieval_chain(query)\n</code></pre>"},{"location":"langchain/human_in_the_loop/","title":"Human In The Loop","text":"<p>Guide for Human-In-The-Loop scenarios within the UiPath-Langchain integration. It focuses on the interrupt(model) functionality, illustrating its role as a symbolic representation of an agent's wait state within the LangGraph framework.</p>"},{"location":"langchain/human_in_the_loop/#models-overview","title":"Models Overview","text":""},{"location":"langchain/human_in_the_loop/#1-createtask","title":"1. CreateTask","text":"<p>The <code>CreateTask</code> model is utilized to create an escalation action within the UiPath Action Center as part of an interrupt context. The action will rely on a previously created UiPath app. After addressing the escalation, the current agent will resume execution. For more information on UiPath apps, refer to the UiPath Apps User Guide.</p>"},{"location":"langchain/human_in_the_loop/#attributes","title":"Attributes:","text":"<ul> <li>app_name (Optional[str]): The name of the app.</li> <li>app_folder_path (Optional[str]): The folder path of the app.</li> <li>app_key (Optional[str]): The key of the app.</li> <li>title (str): The title of the action to create.</li> <li>data (Optional[Dict[str, Any]]): Values that the action will be populated with.</li> <li>assignee (Optional[str]): The username or email of the person assigned to handle the escalation.</li> </ul>"},{"location":"langchain/human_in_the_loop/#example","title":"Example:","text":"<pre><code>from uipath.platform.common import CreateTask\ntask_output = interrupt(CreateTask(app_name=\"AppName\", app_folder_path=\"MyFolderPath\", title=\"Escalate Issue\", data={\"key\": \"value\"}, assignee=\"user@example.com\"))\n</code></pre> <p>Info</p> <p>The return value of the interrupt is the task output. If the task did not produce any output, the return value will be the task status, e.g., <code>{\"status\": \"completed\"}</code>.</p> <p>For a practical implementation of the <code>CreateTask</code> model, refer to the ticket-classification sample. This sample demonstrates how to create an action with dynamic input.</p>"},{"location":"langchain/human_in_the_loop/#2-waittask","title":"2. WaitTask","text":"<p>The <code>WaitTask</code> model is used to wait for a task to be handled. This model is intended for scenarios where the task has already been created.</p>"},{"location":"langchain/human_in_the_loop/#attributes_1","title":"Attributes:","text":"<ul> <li>task (Task): The instance of the task to wait for.</li> <li>app_folder_path (Optional[str]): The folder path of the app.</li> </ul>"},{"location":"langchain/human_in_the_loop/#example_1","title":"Example:","text":"<pre><code>from uipath.platform.common import WaitTask\ntask_output = interrupt(WaitTask(task=my_task_instance, app_folder_path=\"MyFolderPath\"))\n</code></pre> <p>Info</p> <p>The return value of the interrupt is the task output. If the task did not produce any output, the return value will be the task status, e.g., <code>{\"status\": \"completed\"}</code>.</p> <p>\ud83d\udca1The UiPath-LangChain SDK also supports Robot/Agent-in-the-loop scenarios. In this context, the execution of one agent can be suspended until another robot or agent finishes its execution.</p>"},{"location":"langchain/human_in_the_loop/#3-invokeprocess","title":"3. InvokeProcess","text":"<p>The <code>InvokeProcess</code> model is utilized to invoke a process within the UiPath cloud platform. This process can be of various types, including API workflows, Agents or RPA automation. Upon completion of the invoked process, the current agent will automatically resume execution.</p>"},{"location":"langchain/human_in_the_loop/#attributes_2","title":"Attributes:","text":"<ul> <li>name (str): The name of the process to invoke.</li> <li>process_folder_path (Optional[str]): The folder path of the process.</li> <li>input_arguments (Optional[Dict[str, Any]]): A dictionary containing the input arguments required for the invoked process.</li> </ul>"},{"location":"langchain/human_in_the_loop/#example_2","title":"Example:","text":"<pre><code>from uipath.platform.common import InvokeProcess\nprocess_output = interrupt(InvokeProcess(name=\"MyProcess\", process_folder_path=\"MyFolderPath\", input_arguments={\"arg1\": \"value1\"}))\n</code></pre> <p>Info</p> <p>The return value of the interrupt is the job output. If the job did not produce any output, the return value will be the job state, e.g., <code>{\"state\": \"successful\"}</code>.</p> <p>Warning</p> <p>An agent can invoke itself if needed, but this must be done with caution. Be mindful that using the same name for invocation may lead to unintentional loops. To prevent recursion issues, implement safeguards like exit conditions.</p> <p>For a practical implementation of the <code>InvokeProcess</code> model, refer to the multi-agent-planner-researcher-coder-distributed sample. This sample demonstrates how to invoke a process with dynamic input arguments, showcasing the integration of the interrupt functionality within a multi-agent system or a system where an agent integrates with RPA processes and API workflows.</p>"},{"location":"langchain/human_in_the_loop/#4-waitjob","title":"4. WaitJob","text":"<p>The <code>WaitJob</code> model is used to wait for a job completion. Unlike <code>InvokeProcess</code>, which automatically creates a job, this model is intended for scenarios where the job has already been created.</p>"},{"location":"langchain/human_in_the_loop/#attributes_3","title":"Attributes:","text":"<ul> <li>job (Job): The instance of the job that the agent will wait for. This should be a valid job object that has been previously created.</li> <li>process_folder_path (Optional[str]): The folder path of the process.</li> </ul>"},{"location":"langchain/human_in_the_loop/#example_3","title":"Example:","text":"<pre><code>from uipath.platform.common import WaitJob\njob_output = interrupt(WaitJob(job=my_job_instance, process_folder_path=\"MyFolderPath\"))\n</code></pre> <p>Info</p> <p>The return value of the interrupt is the job output. If the job did not produce any output, the return value will be the job state, e.g., <code>{\"state\": \"successful\"}</code>.</p>"},{"location":"langchain/quick_start/","title":"Quickstart Guide: UiPath LangChain Agents","text":""},{"location":"langchain/quick_start/#introduction","title":"Introduction","text":"<p>This guide provides step-by-step instructions for setting up, creating, publishing, and running your first UiPath-LangChain Agent.</p>"},{"location":"langchain/quick_start/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have the following installed:</p> <ul> <li>Python 3.11 or higher</li> <li><code>pip</code> or <code>uv</code> package manager</li> <li>A UiPath Automation Cloud account with appropriate permissions</li> </ul> <p>By default, the quickstart agent uses UiPath LLM Gateway, which provides access to any LLM provider without requiring API keys. Alternatively, you can configure your agent to connect directly to the LLM provider of your choice (such as Anthropic or OpenAI) by providing the appropriate API key as an environment variable.</p> <p>For more details, see the Chat Models documentation.</p> <p>Optional: Using alternative LLM providers</p> <ol> <li> <p>Anthropic - Generate an Anthropic API key here.</p> </li> <li> <p>OpenAI - Generate an OpenAI API key here.</p> </li> </ol>"},{"location":"langchain/quick_start/#creating-a-new-project","title":"Creating a New Project","text":"<p>We recommend using <code>uv</code> for package management. To create a new project:</p> Linux, macOS, Windows BashWindows PowerShell mkdir examplecd example New-Item -ItemType Directory -Path exampleSet-Location example uvpip # Initialize a new uv project in the current directoryuv init . --python 3.11# Create a new virtual environment# By default, uv creates a virtual environment in a directory called .venvuv venvUsing CPython 3.11.16 interpreter at: [PATH]Creating virtual environment at: .venvActivate with: source .venv/bin/activate# Activate the virtual environment# For Windows PowerShell/ Windows CMD: .venv\\Scripts\\activate# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Install the uipath packageuv add uipath-langchain# Verify the uipath installationuipath -lvuipath-langchain version 0.1.0 # Create a new virtual environmentpython -m venv .venv# Activate the virtual environment# For Windows PowerShell: .venv\\Scripts\\Activate.ps1# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Upgrade pip to the latest versionpython -m pip install --upgrade pip# Install the uipath packagepip install uipath-langchain# Verify the uipath installationuipath -lvuipath-langchain version 0.1.0"},{"location":"langchain/quick_start/#create-your-first-uipath-agent","title":"Create Your First UiPath Agent","text":"<p>Generate your first UiPath LangChain agent:</p> uipath new my-agent\u280b Creating new agent my-agent in current directory ...\u2713  Created 'main.py' file.\u2713  Created 'langgraph.json' file.\u2713  Created 'pyproject.toml' file.\ud83d\udca1  Initialize project: uipath init\ud83d\udca1  Run agent: uipath run agent '{\"topic\": \"UiPath\"}' <p>This command creates the following files:</p> File Name Description <code>main.py</code> LangGraph agent code. <code>langgraph.json</code> LangGraph specific configuration file. <code>pyproject.toml</code> Project metadata and dependencies as per PEP 518."},{"location":"langchain/quick_start/#authenticate-with-uipath","title":"Authenticate With UiPath","text":"uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful."},{"location":"langchain/quick_start/#initialize-project","title":"Initialize Project","text":"uipath init\u280b Initializing UiPath project ...\u2713   Created '.env' file.\u2713   Created 'agent.mermaid' file.\u2713   Created 'entry-points.json' file.\u2713   Created 'bindings.json' file. <p>This command creates the following files:</p> File Name Description <code>.env</code> Environment variables and secrets (this file will not be packed &amp; published) <code>entry-points.json</code> Contains the input/output and graph schemas of your graphs <code>bindings.json</code> Allows you to configure overridable resource bindings <code>agent.mermaid</code> Graph visual representation"},{"location":"langchain/quick_start/#run-the-agent-locally","title":"Run The Agent Locally","text":"<p>Execute the agent with a sample input:</p> uipath run agent '{\"topic\": \"UiPath\"}'[2025-04-29 12:31:57,756][INFO] ((), {'topic': 'UiPath'})[2025-04-29 12:32:07,689][INFO] ((), {'topic': 'UiPath', 'report': \"...\"}) <p>This command runs your agent locally and displays the report in the standard output.</p> <p>Warning</p> <p>Depending on the shell you are using, it may be necessary to escape the input json:</p> Bash/ZSH/PowerShellWindows CMDWindows PowerShell <pre><code>uipath run agent '{\"topic\": \"UiPath\"}'\n</code></pre> <pre><code>uipath run agent \"{\"\"topic\"\": \"\"UiPath\"\"}\"\n</code></pre> <pre><code>uipath run agent '{\\\"topic\\\":\\\"uipath\\\"}'\n</code></pre> <p>Attention</p> <p>For a shell agnostic option, please refer to the next section.</p>"},{"location":"langchain/quick_start/#optional-run-the-agent-with-a-json-file-as-input","title":"(Optional) Run The Agent with a json File as Input","text":"<p>The <code>run</code> command can also take a .json file as an input. You can create a file named <code>input.json</code> having the following content:</p> <pre><code>{\n  \"topic\": \"UiPath\"\n}\n</code></pre> <p>Use this file as agent input:</p> <pre><code>&gt; uipath run agent --file input.json\n</code></pre>"},{"location":"langchain/quick_start/#deploy-the-agent-to-uipath-automation-cloud","title":"Deploy the Agent to UiPath Automation Cloud","text":"<p>Follow these steps to publish and run your agent to UiPath Automation Cloud:</p>"},{"location":"langchain/quick_start/#optional-customize-the-package","title":"(Optional) Customize the Package","text":"<p>Update author details in <code>pyproject.toml</code>:</p> <pre><code>authors = [{ name = \"Your Name\", email = \"your.name@example.com\" }]\n</code></pre>"},{"location":"langchain/quick_start/#package-your-project","title":"Package Your Project","text":"uipath pack\u280b Packaging project ...Name       : testVersion    : 0.1.0Description: Add your description hereAuthors    : Your Name\u2713  Project successfully packaged."},{"location":"langchain/quick_start/#publish-to-my-workspace","title":"Publish To My Workspace","text":"uipath publish --my-workspace\u2819 Publishing most recent package: my-agent.0.0.1.nupkg ...\u2713  Package published successfully!\u2826 Getting process information ...\ud83d\udd17 Process configuration link: [LINK]\ud83d\udca1 Use the link above to configure any environment variables <p>Info</p> <p>Please note that a process will be auto-created only upon publishing to my-workspace package feed.</p> <p>Set the environment variables using the provided link:</p> <p> </p>"},{"location":"langchain/quick_start/#invoke-the-agent-on-uipath-automation-cloud","title":"Invoke the Agent on UiPath Automation Cloud","text":"uipath invoke agent '{\"topic\": \"UiPath\"}'\u2834 Loading configuration ...\u2834 Starting job ...\u2728 Job started successfully!\ud83d\udd17 Monitor your job here: [LINK] <p>Use the provided link to monitor your job and view detailed traces.</p> <p> </p>"},{"location":"langchain/quick_start/#optional-invoke-the-agent-with-a-json-file-as-input","title":"(Optional) Invoke The Agent with a json File as Input","text":"<p>The <code>invoke</code> command operates similarly to the <code>run</code> command, allowing you to use the same .json file defined in the (Optional) Run the agent with a .json file as input section, as agent input:</p> <pre><code>&gt; uipath invoke agent --file input.json\n</code></pre>"},{"location":"langchain/quick_start/#next-steps","title":"Next Steps","text":"<p>Congratulations! You have successfully set up, created, published, and run a UiPath LangChain Agent. \ud83d\ude80</p> <p>For more advanced agents and agent samples, please refer to our samples section in GitHub.</p>"},{"location":"llamaindex/context_grounding/","title":"Context Grounding","text":"<p>Context Grounding Service allows you to:</p> <ul> <li>Search through indexed documents using natural language queries</li> <li>Ground LLM responses in your organization's specific information</li> <li>Retrieve context-relevant documents for various applications</li> </ul> <p>You will need to create an index in <code>Context Grounding</code> to use this feature. To create an index go to organization <code>Orchestrator</code> -&gt; the folder where you'd like to create an index -&gt; <code>Indexes</code>. There you can create a new index from a storage bucket which you've added documents to. See the full documentation here for more details.</p>"},{"location":"llamaindex/context_grounding/#contextgroundingretriever","title":"ContextGroundingRetriever","text":"<p>The <code>ContextGroundingRetriever</code> is a document retrieval system that uses vector search to efficiently find and retrieve relevant information from your document store.</p>"},{"location":"llamaindex/context_grounding/#basic-usage","title":"Basic Usage","text":"<p>Create a simple retriever by specifying an index name:</p> <pre><code>from uipath_llamaindex.retrievers import ContextGroundingRetriever\n\nretriever = ContextGroundingRetriever(index_name = \"Company Policy Context\")\nprint(retriever.retrieve(\"What is the company policy on remote work?\"))\n</code></pre>"},{"location":"llamaindex/context_grounding/#contextgroundingqueryengine","title":"ContextGroundingQueryEngine","text":"<p>Query engines are interfaces that allows you to ask question over your data. The <code>ContextGroundingQueryEngine</code> is a query engine system that leverages the <code>ContextGroundingRetriever</code>.</p>"},{"location":"llamaindex/context_grounding/#basic-usage_1","title":"Basic Usage","text":"<p>Create a simple query engine by specifying an index name and a synthesizer strategy:</p> <pre><code>from uipath_llamaindex.query_engines import ContextGroundingQueryEngine\nfrom llama_index.core.response_synthesizers.type import ResponseMode\nfrom llama_index.core import get_response_synthesizer\n\nsynthesizer = get_response_synthesizer(ResponseMode.SIMPLE_SUMMARIZE)\nquery_engine = ContextGroundingQueryEngine(index_name = \"Company Policy Context\", response_synthesizer=synthesizer)\nprint(query_engine.query(\"What is the company policy on remote work?\"))\n</code></pre>"},{"location":"llamaindex/context_grounding/#integration-with-llamaindex-tools","title":"Integration with LlamaIndex Tools","text":"<p>You can easily integrate the query engine with LlamaIndex's tool system:</p> <pre><code>from uipath_llamaindex.query_engines import ContextGroundingQueryEngine\nfrom llama_index.core.response_synthesizers.type import ResponseMode\nfrom llama_index.core import get_response_synthesizer\n\nquery_engine = ContextGroundingQueryEngine(\n    index_name=\"Company Policy Context\",\n    response_synthesizer=get_response_synthesizer(ResponseMode.REFINE),\n)\nquery_engine_tools = [QueryEngineTool(\n            query_engine=query_engine,\n            metadata=ToolMetadata(\n                name=\"Company policy\",\n                description=\"Information about general company policy\",\n            )\n        )]\n# You can use the tool in your agents\nreact_agent = ReActAgent.from_tools(query_engine_tools)\nresponse = react_agent.chat(\"Answer user questions as best as you can using the query engine tool.\")\n</code></pre> <p>Tip</p> <p>Check our travel-helper-RAG-agent sample to see context grounding query engines in action.</p>"},{"location":"llamaindex/human_in_the_loop/","title":"Human In The Loop","text":"<p>Guide for Human-In-The-Loop scenarios within the UiPath-LlamaIndex integration. It focuses on the ctx.write_event_to_stream LlamaIndex functionality.</p>"},{"location":"llamaindex/human_in_the_loop/#models-overview","title":"Models Overview","text":""},{"location":"llamaindex/human_in_the_loop/#1-createtaskevent","title":"1. CreateTaskEvent","text":"<p>The <code>CreateTaskEvent</code> model is utilized to create an escalation task within the UiPath Action Center as part of an interrupt context. The task will rely on a previously created UiPath App. After addressing the escalation, the current agent will resume execution. For more information on UiPath Apps, refer to the UiPath Apps User Guide.</p>"},{"location":"llamaindex/human_in_the_loop/#attributes","title":"Attributes:","text":"<ul> <li>app_name (Optional[str]): The name of the app.</li> <li>app_folder_path (Optional[str]): The folder path of the app.</li> <li>app_key (Optional[str]): The key of the app.</li> <li>title (str): The title of the task to create.</li> <li>data (Optional[Dict[str, Any]]): Values that the task will be populated with.</li> <li>assignee (Optional[str]): The username or email of the person assigned to handle the escalation.</li> </ul>"},{"location":"llamaindex/human_in_the_loop/#example","title":"Example:","text":"<pre><code>from uipath_llamaindex.models import CreateTaskEvent\nctx.write_event_to_stream(CreateTaskEvent(app_name=\"AppName\", app_folder_path=\"MyFolderPath\", title=\"Escalate Issue\", data={\"key\": \"value\"}, assignee=\"user@example.com\"))\ntask_data = await ctx.wait_for_event(HumanResponseEvent)\n</code></pre> <p>For a practical implementation of the <code>CreateTaskEvent</code> model, refer to the action-center-hitl-agent. This sample demonstrates how to create a task with dynamic input.</p>"},{"location":"llamaindex/human_in_the_loop/#2-waittaskevent","title":"2. WaitTaskEvent","text":"<p>The <code>WaitTaskEvent</code> model is used to wait for a task to be approved. This model is intended for scenarios where the task has already been created.</p>"},{"location":"llamaindex/human_in_the_loop/#attributes_1","title":"Attributes:","text":"<ul> <li>action (Task): The instance of the task to wait for.</li> <li>app_folder_path (Optional[str]): The folder path of the app.</li> </ul>"},{"location":"llamaindex/human_in_the_loop/#example_1","title":"Example:","text":"<pre><code>from uipath_llamaindex.models import WaitTaskEvent\nctx.write_event_to_stream(WaitTaskEvent(action=my_task_instance, app_folder_path=\"MyFolderPath\"))\ntask_data = await ctx.wait_for_event(HumanResponseEvent)\n</code></pre> <p>\ud83d\udca1 UiPath LlamaIndex sdk also supports Robot/Agent-in-the-loop scenarios. In this context, the execution of one agent can be suspended until another robot or agent finishes its execution.</p>"},{"location":"llamaindex/human_in_the_loop/#3-invokeprocessevent","title":"3. InvokeProcessEvent","text":"<p>The <code>InvokeProcessEvent</code> model is utilized to invoke a process within the UiPath cloud platform. This process can be of various types, including API workflows, Agents or RPA automation. Upon completion of the invoked process, the current agent will automatically resume execution.</p>"},{"location":"llamaindex/human_in_the_loop/#attributes_2","title":"Attributes:","text":"<ul> <li>name (str): The name of the process to invoke.</li> <li>process_folder_path (Optional[str]): The folder path of the process.</li> <li>input_arguments (Optional[Dict[str, Any]]): A dictionary containing the input arguments required for the invoked process.</li> </ul>"},{"location":"llamaindex/human_in_the_loop/#example_2","title":"Example:","text":"<pre><code>from uipath_llamaindex.models import InvokeProcessEvent\nctx.write_event_to_stream(InvokeProcessEvent(name=\"MyProcess\", process_folder_path=\"MyFolderPath\", input_arguments={\"arg1\": \"value1\"}))\njob_data = await ctx.wait_for_event(HumanResponseEvent)\n</code></pre> <p>Warning</p> <p>An agent can invoke itself if needed, but this must be done with caution. Be mindful that using the same name for invocation may lead to unintentional loops. To prevent recursion issues, implement safeguards like exit conditions.</p> <p>For a practical implementation of the <code>InvokeProcessEvent</code> model, refer to the multi-agent sample. This sample demonstrates how to invoke a process with dynamic input arguments, showcasing the integration of the interrupt functionality within a multi-agent system or a system where an agent integrates with RPA processes and API workflows.</p>"},{"location":"llamaindex/human_in_the_loop/#4-waitjob","title":"4. WaitJob","text":"<p>The <code>WaitJobEvent</code> model is used to wait for a job completion. Unlike <code>InvokeProcessEvent</code>, which automatically creates a job, this model is intended for scenarios where the job has already been created.</p>"},{"location":"llamaindex/human_in_the_loop/#attributes_3","title":"Attributes:","text":"<ul> <li>job (Job): The instance of the job that the agent will wait for. This should be a valid job object that has been previously created.</li> <li>process_folder_path (Optional[str]): The folder path of the process.</li> </ul>"},{"location":"llamaindex/human_in_the_loop/#example_3","title":"Example:","text":"<pre><code>from uipath_llamaindex.models import WaitJobEvent\nctx.write_event_to_stream(WaitJobEvent(job=my_job_instance, process_folder_path=\"MyFolderPath\"))\njob_data = await ctx.wait_for_event(HumanResponseEvent)\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/","title":"LLMs and Embeddings","text":"<p>UiPath provides pre-configured LLM and embedding classes that handle authentication, routing, and configuration automatically, allowing you to focus on building your agents. You do not need to add API keys from OpenAI, AWS, or Google, usage of these models will consume <code>Agent Units</code> on your account.</p>"},{"location":"llamaindex/llms_and_embeddings/#uipathopenai","title":"UiPathOpenAI","text":"<p>The <code>UiPathOpenAI</code> class is a pre-configured Azure OpenAI client that routes requests through UiPath.</p>"},{"location":"llamaindex/llms_and_embeddings/#available-models","title":"Available Models","text":"<p>The following OpenAI models are available through the <code>OpenAIModel</code> enum:</p> <ul> <li><code>GPT_4_1_2025_04_14</code></li> <li><code>GPT_4_1_MINI_2025_04_14</code></li> <li><code>GPT_4_1_NANO_2025_04_14</code></li> <li><code>GPT_4O_2024_05_13</code></li> <li><code>GPT_4O_2024_08_06</code></li> <li><code>GPT_4O_2024_11_20</code></li> <li><code>GPT_4O_MINI_2024_07_18</code> (default)</li> <li><code>O3_MINI_2025_01_31</code></li> <li><code>TEXT_DAVINCI_003</code></li> </ul>"},{"location":"llamaindex/llms_and_embeddings/#basic-usage","title":"Basic Usage","text":"<pre><code>from uipath_llamaindex.llms import UiPathOpenAI\nfrom llama_index.core.llms import ChatMessage\n\n# Create an LLM instance with default settings\nllm = UiPathOpenAI()\n\n# Create chat messages\nmessages = [\n    ChatMessage(\n        role=\"system\", content=\"You are a pirate with colorful personality.\"\n    ),\n    ChatMessage(role=\"user\", content=\"Hello\"),\n]\n\n# Generate a response\nresponse = llm.chat(messages)\nprint(response)\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#custom-model-configuration","title":"Custom Model Configuration","text":"<pre><code>from uipath_llamaindex.llms import UiPathOpenAI, OpenAIModel\n\n# Use a specific model\nllm = UiPathOpenAI(model=OpenAIModel.GPT_4_1_2025_04_14)\n\n# Or use a model string directly\nllm = UiPathOpenAI(model=\"gpt-4.1-2025-04-14\")\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#uipathopenaiembedding","title":"UiPathOpenAIEmbedding","text":"<p>The <code>UiPathOpenAIEmbedding</code> class provides text embedding capabilities using OpenAI's embedding models through UiPath.</p>"},{"location":"llamaindex/llms_and_embeddings/#available-embedding-models","title":"Available Embedding Models","text":"<p>The following embedding models are available through the <code>OpenAIEmbeddingModel</code> enum:</p> <ul> <li><code>TEXT_EMBEDDING_ADA_002</code> (default)</li> <li><code>TEXT_EMBEDDING_3_LARGE</code></li> </ul>"},{"location":"llamaindex/llms_and_embeddings/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from uipath_llamaindex.embeddings import UiPathOpenAIEmbedding\n\n# Create an embedding model instance\nembed_model = UiPathOpenAIEmbedding()\n\n# Get embeddings for a single text\nresult = embed_model.get_text_embedding(\"the quick brown fox jumps over the lazy dog\")\nprint(f\"Embedding dimension: {len(result)}\")\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#batch-embeddings","title":"Batch Embeddings","text":"<pre><code>from uipath_llamaindex.embeddings import UiPathOpenAIEmbedding\n\nembed_model = UiPathOpenAIEmbedding()\n\n# Get embeddings for multiple texts\ntexts = [\n    \"Hello world\",\n    \"How are you?\",\n    \"This is a test\"\n]\n\nembeddings = embed_model.get_text_embedding_batch(texts)\nprint(f\"Number of embeddings: {len(embeddings)}\")\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#uipathchatbedrock-and-uipathchatbedrockconverse","title":"UiPathChatBedrock and UiPathChatBedrockConverse","text":"<p><code>UiPathChatBedrock</code> and <code>UiPathChatBedrockConverse</code> provide access to AWS Bedrock models through UiPath using the Invoke API and Converse API respectively.</p>"},{"location":"llamaindex/llms_and_embeddings/#installation","title":"Installation","text":"<p>These classes require additional dependencies. Install them with:</p> <pre><code>pip install uipath-llamaindex[bedrock]\n# or using uv:\nuv add 'uipath-llamaindex[bedrock]'\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#example-usage","title":"Example Usage","text":"<pre><code>from uipath_llamaindex.llms.bedrock import UiPathChatBedrockConverse\nfrom uipath_llamaindex.llms import BedrockModel\nfrom llama_index.core.llms import ChatMessage\n\n# Create an LLM instance with default settings\nllm = UiPathChatBedrockConverse()\n\n# Or use a specific model\nllm = UiPathChatBedrockConverse(model=BedrockModel.anthropic_claude_sonnet_4_5)\n\n# Create chat messages\nmessages = [\n    ChatMessage(role=\"user\", content=\"Hello\"),\n]\n\n# Generate a response\nresponse = llm.chat(messages)\nprint(response)\n</code></pre> <p>Similarly, <code>UiPathChatBedrock</code> can be used with the Invoke API:</p> <pre><code>from uipath_llamaindex.llms.bedrock import UiPathChatBedrock\nfrom uipath_llamaindex.llms import BedrockModel\n\nllm = UiPathChatBedrock(model=BedrockModel.anthropic_claude_sonnet_4)\n</code></pre> <p>Currently, the following models can be used (this list can be updated in the future):</p> <ul> <li><code>anthropic.claude-3-7-sonnet-20250219-v1:0</code>, <code>anthropic.claude-sonnet-4-20250514-v1:0</code>, <code>anthropic.claude-sonnet-4-5-20250929-v1:0</code>, <code>anthropic.claude-haiku-4-5-20251001-v1:0</code></li> </ul>"},{"location":"llamaindex/llms_and_embeddings/#uipathvertex","title":"UiPathVertex","text":"<p><code>UiPathVertex</code> provides access to Google Vertex AI (Gemini) models through UiPath.</p>"},{"location":"llamaindex/llms_and_embeddings/#installation_1","title":"Installation","text":"<p>This class requires additional dependencies. Install them with:</p> <pre><code>pip install uipath-llamaindex[vertex]\n# or using uv:\nuv add 'uipath-llamaindex[vertex]'\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#example-usage_1","title":"Example Usage","text":"<pre><code>from uipath_llamaindex.llms.vertex import UiPathVertex\nfrom uipath_llamaindex.llms import GeminiModel\nfrom llama_index.core.llms import ChatMessage\n\n# Create an LLM instance with default settings\nllm = UiPathVertex()\n\n# Or use a specific model\nllm = UiPathVertex(model=GeminiModel.gemini_2_5_pro)\n\n# Create chat messages\nmessages = [\n    ChatMessage(role=\"user\", content=\"Hello\"),\n]\n\n# Generate a response\nresponse = llm.chat(messages)\nprint(response)\n</code></pre> <p>Currently, the following models can be used (this list can be updated in the future):</p> <ul> <li><code>gemini-2.0-flash-001</code>, <code>gemini-2.5-flash</code>, <code>gemini-2.5-pro</code></li> </ul>"},{"location":"llamaindex/llms_and_embeddings/#integration-with-llamaindex","title":"Integration with LlamaIndex","text":"<p>These classes integrate seamlessly with LlamaIndex components:</p>"},{"location":"llamaindex/llms_and_embeddings/#using-with-agents","title":"Using with Agents","text":"<pre><code>import asyncio\nfrom llama_index.core.agent.workflow import ReActAgent\nfrom uipath_llamaindex.llms import UiPathOpenAI, OpenAIModel\n\ndef multiply(a: int, b: int) -&gt; int:\n    \"\"\"Multiply two integers and returns the result integer\"\"\"\n    return a * b\n\n\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"Add two integers and returns the result integer\"\"\"\n    return a + b\n\n# Create agent with UiPath LLM\nagent = ReActAgent(\n    tools=[multiply, add],\n    llm=UiPathOpenAI(model=OpenAIModel.GPT_4_1_2025_04_14))\n\nasync def main():\n    handler = agent.run(\"What is 2+(2*4)?\")\n    response = await handler\n\nasyncio.run(main())\n</code></pre>"},{"location":"llamaindex/llms_and_embeddings/#using-with-vectorstoreindex","title":"Using with VectorStoreIndex","text":"<pre><code>from llama_index.core import VectorStoreIndex, Document\nfrom uipath_llamaindex.llms import UiPathOpenAI\nfrom uipath_llamaindex.embeddings import UiPathOpenAIEmbedding\n\n# Create documents\ndocuments = [\n    Document(text=\"This is a sample document about artificial intelligence.\"),\n    Document(text=\"Machine learning is a subset of AI that focuses on algorithms.\"),\n]\n\n# Create index with UiPath models\nindex = VectorStoreIndex.from_documents(\n    documents,\n    embed_model=UiPathOpenAIEmbedding()\n)\n\n# Create query engine with UiPath LLM\nquery_engine = index.as_query_engine(\n    llm=UiPathOpenAI(model=OpenAIModel.GPT_4_1_2025_04_14)\n)\n\nresponse = query_engine.query(\"What is machine learning?\")\n</code></pre> <p>Warning</p> <p>Please note that you may get errors related to data residency, as some models are not available on all regions.</p> <p>Example: <code>[Enforced Region] No model configuration found for product uipath-python-sdk in EU</code>.</p>"},{"location":"llamaindex/quick_start/","title":"Quickstart Guide: UiPath LlamaIndex Agents","text":""},{"location":"llamaindex/quick_start/#introduction","title":"Introduction","text":"<p>This guide provides step-by-step instructions for setting up, creating, publishing, and running your first UiPath-LlamaIndex Agent.</p>"},{"location":"llamaindex/quick_start/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have the following installed:</p> <ul> <li>Python 3.11 or higher</li> <li><code>pip</code> or <code>uv</code> package manager</li> <li>A UiPath Automation Cloud account with appropriate permissions</li> <li>An OpenAI API key</li> </ul> <p>Info</p> <p>OpenAI - Generate an OpenAI API key here.</p>"},{"location":"llamaindex/quick_start/#creating-a-new-project","title":"Creating a New Project","text":"<p>We recommend using <code>uv</code> for package management. To create a new project:</p> Linux, macOS, Windows BashWindows PowerShell mkdir examplecd example New-Item -ItemType Directory -Path exampleSet-Location example uvpip # Initialize a new uv project in the current directoryuv init . --python 3.11# Create a new virtual environment# By default, uv creates a virtual environment in a directory called .venvuv venvUsing CPython 3.11.16 interpreter at: [PATH]Creating virtual environment at: .venvActivate with: source .venv/bin/activate# Activate the virtual environment# For Windows PowerShell/ Windows CMD: .venv\\Scripts\\activate# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Install the uipath packageuv add uipath-llamaindex # Create a new virtual environmentpython -m venv .venv# Activate the virtual environment# For Windows PowerShell: .venv\\Scripts\\Activate.ps1# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Upgrade pip to the latest versionpython -m pip install --upgrade pip# Install the uipath packagepip install uipath-llamaindex"},{"location":"llamaindex/quick_start/#create-your-first-uipath-agent","title":"Create Your First UiPath Agent","text":"<p>Generate your first UiPath LlamaIndex agent:</p> uipath new my-agent\u280b Creating new agent my-agent in current directory ...\u2713  Created 'main.py' file.\u2713  Created 'llama_index.json' file.\u2713  Created 'pyproject.toml' file.\ud83d\udd27  Please ensure to define OPENAI_API_KEY in your .env file.\ud83d\udca1  Initialize project: uipath init\ud83d\udca1  Run agent: uipath run agent '{\"topic\": \"UiPath\"}' <p>This command creates the following files:</p> File Name Description <code>main.py</code> LlamaIndex agent code. <code>llama_index.json</code> LlamaIndex specific configuration file. <code>pyproject.toml</code> Project metadata and dependencies as per PEP 518."},{"location":"llamaindex/quick_start/#initialize-project","title":"Initialize Project","text":"uipath init\u280b Initializing UiPath project ...\u2713   Created '.env' file.\u2713   Created 'agent.mermaid' file.\u2713   Created 'entry-points.json' file. <p>This command creates the following files:</p> File Name Description <code>.env</code> Environment variables and secrets (this file will not be packed &amp; published). <code>uipath.json</code> Input/output JSON schemas and bindings. <code>agent.mermaid</code> Graph visual representation."},{"location":"llamaindex/quick_start/#set-up-environment-variables","title":"Set Up Environment Variables","text":"<p>Before running the agent, configure <code>OPENAI_API_KEY</code> in the <code>.env</code> file:</p> Open AI <pre><code>OPENAI_API_KEY=sk-proj-......\n</code></pre>"},{"location":"llamaindex/quick_start/#authenticate-with-uipath","title":"Authenticate With UiPath","text":"uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful."},{"location":"llamaindex/quick_start/#run-the-agent-locally","title":"Run The Agent Locally","text":"<p>Execute the agent with a sample input:</p> uipath run agent '{\"topic\": \"UiPath\"}'{'joke': 'Why did the UiPath robot go to therapy? \\nBecause it had too many unresolved workflows!', 'critique': \"Analysis:\\nThis joke plays on the concept of therapy and unresolved issues, but applies it to a UiPath robot, which is a software automation tool used in businesses. The joke cleverly incorporates the idea of workflows, which are sequences of automated tasks that the robot performs, as the source of the robot's need for therapy.\\n\\nCritique:\\n- Clever wordplay: The joke is clever in its use of wordplay, as it takes a common phrase related to therapy and applies it in a humorous way to a robot and its workflows. This adds an element of surprise and wit to the joke.\\n- Relevant to the audience: The joke is likely to resonate with those familiar with UiPath or other automation tools, as they will understand the reference to workflows and the challenges that can arise from managing them.\\n- Lack of depth: While the joke is amusing on the surface, it may lack depth or complexity compared to more nuanced humor. Some may find it to be a simple play on words rather than a joke with deeper layers of meaning.\\n- Limited appeal: The joke's humor may be limited to a specific audience who are familiar with automation tools and workflows, potentially excluding those who are not familiar with these concepts.\\n\\nOverall, the joke is a clever play on words that will likely resonate with those in the automation industry, but may not have broad appeal beyond that specific audience.\"}\u2713  Successful execution. <p>This command runs your agent locally and displays the report in the standard output.</p> <p>Warning</p> <p>Depending on the shell you are using, it may be necessary to escape the input json:</p> Bash/ZSH/PowerShellWindows CMDWindows PowerShell <pre><code>uipath run agent '{\"topic\": \"UiPath\"}'\n</code></pre> <pre><code>uipath run agent \"{\"\"topic\"\": \"\"UiPath\"\"}\"\n</code></pre> <pre><code>uipath run agent '{\\\"topic\\\":\\\"uipath\\\"}'\n</code></pre> <p>Attention</p> <p>For a shell agnostic option, please refer to the next section.</p>"},{"location":"llamaindex/quick_start/#optional-run-the-agent-with-a-json-file-as-input","title":"(Optional) Run The Agent with a json File as Input","text":"<p>The <code>run</code> command can also take a .json file as an input. You can create a file named <code>input.json</code> having the following content:</p> <pre><code>{\n  \"topic\": \"UiPath\"\n}\n</code></pre> <p>Use this file as agent input:</p> <pre><code>&gt; uipath run agent --file input.json\n</code></pre>"},{"location":"llamaindex/quick_start/#deploy-the-agent-to-uipath-automation-cloud","title":"Deploy the Agent to UiPath Automation Cloud","text":"<p>Follow these steps to publish and run your agent to UiPath Automation Cloud:</p>"},{"location":"llamaindex/quick_start/#optional-customize-the-package","title":"(Optional) Customize the Package","text":"<p>Update author details in <code>pyproject.toml</code>:</p> <pre><code>authors = [{ name = \"Your Name\", email = \"your.name@example.com\" }]\n</code></pre>"},{"location":"llamaindex/quick_start/#package-your-project","title":"Package Your Project","text":"uipath pack\u280b Packaging project ...Name       : testVersion    : 0.1.0Description: Add your description hereAuthors    : Your Name\u2713  Project successfully packaged."},{"location":"llamaindex/quick_start/#publish-to-my-workspace","title":"Publish To My Workspace","text":"uipath publish --my-workspace\u2819 Publishing most recent package: my-agent.0.0.1.nupkg ...\u2713  Package published successfully!\u2826 Getting process information ...\ud83d\udd17 Process configuration link: [LINK]\ud83d\udca1 Use the link above to configure any environment variables <p>Info</p> <p>Please note that a process will be auto-created only upon publishing to my-workspace package feed.</p> <p>Set the environment variables using the provided link:</p> <p> </p>"},{"location":"llamaindex/quick_start/#invoke-the-agent-on-uipath-automation-cloud","title":"Invoke the Agent on UiPath Automation Cloud","text":"uipath invoke agent '{\"topic\": \"UiPath\"}'\u2834 Loading configuration ...\u2834 Starting job ...\u2728 Job started successfully!\ud83d\udd17 Monitor your job here: [LINK] <p>Use the provided link to monitor your job and view detailed traces.</p> <p> </p>"},{"location":"llamaindex/quick_start/#optional-invoke-the-agent-with-a-json-file-as-input","title":"(Optional) Invoke The Agent with a json File as Input","text":"<p>The <code>invoke</code> command operates similarly to the <code>run</code> command, allowing you to use the same .json file defined in the (Optional) Run the agent with a .json file as input section, as agent input:</p> <pre><code>&gt; uipath invoke agent --file input.json\n</code></pre>"},{"location":"llamaindex/quick_start/#next-steps","title":"Next Steps","text":"<p>Congratulations! You have successfully set up, created, published, and run a UiPath LlamaIndex Agent. \ud83d\ude80</p> <p>For more advanced agents and agent samples, please refer to our samples section in GitHub.</p>"},{"location":"mcp/how_to_pack_binary/","title":"How To Pack Binary","text":"<p>This guide explains how to manually package and publish the official GitHub MCP server to UiPath Orchestrator. For automation, see the example GitHub Actions workflow.</p> <p>Attention</p> <p>To build binary MCP servers locally, your environment must match UiPath's serverless runtime architecture (Ubuntu 64-bit AMD64). On other operating systems, use the GitHub Actions workflow described in the Automating with GitHub Actions section below.</p>"},{"location":"mcp/how_to_pack_binary/#prerequisites","title":"Prerequisites","text":"<ul> <li>UiPath Automation Cloud account</li> <li>UiPath personal access token</li> <li><code>go</code> (version 1.21+)</li> <li><code>python</code> (version 3.11+)</li> <li><code>uv</code> package manager (<code>pip install uv</code>)</li> </ul>"},{"location":"mcp/how_to_pack_binary/#steps","title":"Steps","text":""},{"location":"mcp/how_to_pack_binary/#1-clone-and-build-the-github-mcp-server","title":"1. Clone and Build the GitHub MCP Server","text":"# Clone the repositorygit clone https://github.com/github/github-mcp-server.gitcd github-mcp-server# Build the servercd cmd/github-mcp-servergo build"},{"location":"mcp/how_to_pack_binary/#2-create-package-directory","title":"2. Create Package Directory","text":"# Create package directory and copy executablemkdir -p mcp-packagecp github-mcp-server mcp-package/cd mcp-package"},{"location":"mcp/how_to_pack_binary/#3-create-configuration-files","title":"3. Create Configuration Files","text":"<p>Create the following files in the mcp-package directory:</p> <ol> <li> <p><code>mcp.json</code> - Server configuration: <pre><code>{\n  \"servers\": {\n    \"github\": {\n      \"command\": \"/bin/sh\",\n      \"args\": [\"-c\", \"chmod +x github-mcp-server &amp;&amp; ./github-mcp-server stdio\"],\n      \"env\": {\n        \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"x\"\n      }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p><code>pyproject.toml</code> - Project metadata: <pre><code>[project]\nname = \"mcp-github-server\"\nversion = \"0.0.1\"\ndescription = \"Official GitHub MCP Server\"\nauthors = [{ name = \"John Doe\" }]\ndependencies = [\n    \"uipath-mcp&gt;=0.0.99\",\n]\nrequires-python = \"&gt;=3.11\"\n</code></pre></p> </li> </ol>"},{"location":"mcp/how_to_pack_binary/#4-set-up-python-environment","title":"4. Set Up Python Environment","text":"# Initialize a new uv project in the current directoryuv venv# Activate the virtual environmentsource .venv/bin/activate# Install dependenciesuv sync"},{"location":"mcp/how_to_pack_binary/#5-authenticate-with-uipath","title":"5. Authenticate With UiPath","text":"uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful."},{"location":"mcp/how_to_pack_binary/#6-initialize-uipath-package","title":"6. Initialize UiPath Package","text":"\u280b Initializing UiPath project ...\u2713   Created '.env' file.\u2713   Created 'uipath.json' file. <p>Edit the generated <code>uipath.json</code> to include the executable: <pre><code>{\n  \"settings\": {\n    \"filesIncluded\": [\"github-mcp-server\"]\n  }\n}\n</code></pre></p>"},{"location":"mcp/how_to_pack_binary/#7-package-for-uipath","title":"7. Package for UiPath","text":"\u280b Packaging project ...Name       : mcp-github-serverVersion    : 0.0.1Description: Official GitHub MCP ServerAuthors    : John Doe\u2713  Project successfully packaged."},{"location":"mcp/how_to_pack_binary/#8-upload-to-uipath-orchestrator","title":"8. Upload to UiPath Orchestrator","text":"\u2819 Publishing most recent package: mcp-github-server.0.0.1.nupkg ...\u2713  Package published successfully!"},{"location":"mcp/how_to_pack_binary/#automating-with-github-actions","title":"Automating with GitHub Actions","text":"<p>To automate this process:</p> <ol> <li>Copy the example workflow to <code>.github/workflows/</code> in your repository.</li> <li>Go to GitHub Actions tab and run the workflow.</li> <li>Provide the version when prompted.</li> <li>Download the artifact after completion.</li> </ol> <p>The workflow handles all the manual steps automatically, including the crucial modification of <code>uipath.json</code> to include the executable in the package.</p>"},{"location":"mcp/quick_start/","title":"Quickstart Guide: UiPath Coded MCP Servers","text":""},{"location":"mcp/quick_start/#introduction","title":"Introduction","text":"<p>This guide provides instructions for setting up and running a UiPath coded MCP Server.</p>"},{"location":"mcp/quick_start/#prerequisites","title":"Prerequisites","text":"<p>You need:</p> <ul> <li>Python 3.11 or higher</li> <li><code>pip</code> or <code>uv</code> package manager</li> <li>A UiPath Automation Cloud account with appropriate permissions</li> <li>A UiPath Personal Access Token with Orchestrator API Access scopes</li> </ul>"},{"location":"mcp/quick_start/#creating-a-new-project","title":"Creating a New Project","text":"<p>Use <code>uv</code> for package management. To create a new project:</p> Linux, macOS, Windows BashWindows PowerShell mkdir examplecd example New-Item -ItemType Directory -Path exampleSet-Location example uvpip # Initialize a new uv project in the current directoryuv init . --python 3.11# Create a new virtual environment# By default, uv creates a virtual environment in a directory called .venvuv venvUsing CPython 3.11.16 interpreter at: [PATH]Creating virtual environment at: .venvActivate with: source .venv/bin/activate# Activate the virtual environment# For Windows PowerShell/ Windows CMD: .venv\\Scripts\\activate# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Install the uipath packageuv add uipath-mcp # Create a new virtual environmentpython -m venv .venv# Activate the virtual environment# For Windows PowerShell: .venv\\Scripts\\Activate.ps1# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Upgrade pip to the latest versionpython -m pip install --upgrade pip# Install the uipath packagepip install uipath-mcp"},{"location":"mcp/quick_start/#create-your-first-uipath-coded-mcp-server","title":"Create Your First UiPath Coded MCP Server","text":"<p>Create your first MCP server</p> uipath new math-server\u280b Creating new mcp server 'math-server' in current directory ...\u2713  Created 'server.py' file.\u2713  Created 'mcp.json' file.\u2713  Created 'pyproject.toml' file.\ud83d\udca1  Initialize project: uipath init\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550Start 'math-server' as a self-hosted MCP server\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ud83d\udca1  1. Set UIPATH_FOLDER_PATH environment variable\ud83d\udca1  2. Start the server locally: uipath run math-server <p>Warning</p> <p>uipath new command deletes all previous <code>.py</code> files in the current directory.</p> <p>This command creates the following files:</p> File Name Description <code>server.py</code> A sample MCP math server using FastMCP <code>mcp.json</code> Configuration file needed for coded UiPath MCP Servers. <code>pyproject.toml</code> Project metadata and dependencies as per PEP 518."},{"location":"mcp/quick_start/#initialize-project","title":"Initialize Project","text":"uipath init\u280b Initializing UiPath project ...\u2713   Created '.env' file.\u2713   Created 'uipath.json' file. <p>This command creates the following files:</p> File Name Description <code>.env</code> Environment variables and secrets (this file is not packed &amp; published). <code>uipath.json</code> Input/output JSON schemas and bindings."},{"location":"mcp/quick_start/#authenticate-with-uipath","title":"Authenticate With UiPath","text":"uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful."},{"location":"mcp/quick_start/#run-the-mcp-server","title":"Run the MCP Server","text":"<p>There are two ways to run your coded MCP server:</p>"},{"location":"mcp/quick_start/#1-running-locally-on-prem","title":"1. Running Locally (On-Prem)","text":"<p>When running the server locally, JSON-RPC requests are tunneled from UiPath servers to your local server. During startup, the local server automatically registers itself with UiPath.</p> <p>Since MCP servers are folder-scoped in Orchestrator, you need to set the <code>UIPATH_FOLDER_PATH</code> environment variable. To do this:</p> <ol> <li>Copy the folder path from your Orchestrator interface</li> </ol> <p> </p> <ol> <li>Add it to the <code>.env</code> file (created during <code>uipath init</code>) as:    <pre><code>UIPATH_FOLDER_PATH=&lt;Copied folder path&gt;\n</code></pre></li> </ol> # Start the serveruipath run math-serverInitializing tracer instance. This should only be done once per process.HTTP Request: GET https://***/orchestrator_/api/FoldersNavigation/GetFoldersForCurrentUser?searchText=Agents&amp;skip=0&amp;take=20 \"HTTP/1.1 200 OK\"Folder key: ***Initializing client session...Initialization successfulRegistering server runtime ......"},{"location":"mcp/quick_start/#verifying-the-server","title":"Verifying the Server","text":"<p>Once started successfully, your MCP server will appear in Orchestrator. Navigate to the MCP Servers tab in your configured folder:</p> <p> </p> <p>You can inspect the available tools by clicking on the server:</p> <p> </p> <p>Now we can connect to the server using any MCP client. See the Connecting to the MCP Server section.</p>"},{"location":"mcp/quick_start/#2-running-on-uipath-automation-cloud","title":"2. Running on UiPath Automation Cloud","text":"<p>Info</p> <p>This quickstart guide provides instructions for deploying the MCP Server in My Workspace folder. Choosing this folder simplifies the configuration process, as you won\u2019t need to manually handle the following:</p> <ul> <li> <p>Serverless machine allocation</p> </li> <li> <p>Unattended robot permissions</p> </li> <li> <p>Process creation (processes are automatically provisioned when a package is published to <code>My Workspace</code>)</p> </li> </ul> <p>If you prefer to deploy the MCP Server in a different folder, additional steps are required:</p> <ol> <li> <p>Create a process from the MCP Server package.</p> </li> <li> <p>Ensure a serverless runtime (machine) is assigned to the target folder in Orchestrator.</p> </li> <li> <p>Confirm that a user with unattended robot permissions is assigned to the target folder.</p> </li> </ol> <p>To deploy your MCP server to UiPath Automation Cloud, follow these steps:</p>"},{"location":"mcp/quick_start/#optional-customize-the-package","title":"(Optional) Customize the Package","text":"<p>Update author details in <code>pyproject.toml</code>:</p> <pre><code>authors = [{ name = \"Your Name\", email = \"your.name@example.com\" }]\n</code></pre>"},{"location":"mcp/quick_start/#package-your-project","title":"Package Your Project","text":"uipath pack\u2839 Packaging project ...Name       : math-serverVersion    : 0.0.1Description: Description for math-server projectAuthors    : John Doe\u2713  Project successfully packaged."},{"location":"mcp/quick_start/#publish-the-mcp-server-package","title":"Publish The MCP Server Package","text":"uipath publish --my-workspace\u2819 Publishing most recent package: math-server.0.0.1.nupkg ...\u2713  Package published successfully!\u2826 Getting process information ...\ud83d\udd17 Process configuration link: [LINK]\ud83d\udca1 Use the link above to configure any environment variables <p>After publishing, you can configure and manage your MCP server through the UiPath Automation Cloud interface:</p>"},{"location":"mcp/quick_start/#configure-in-uipath-automation-cloud","title":"Configure in UiPath Automation Cloud","text":"<ol> <li>In <code>My Workspace</code>, navigate to the MCP Servers tab and click Add MCP Server</li> </ol> <ol> <li>In the configuration dialog:</li> </ol> <ul> <li>Select <code>Coded</code> as the server type</li> <li>Choose the <code>math-server</code> process</li> <li>Click Add to deploy the server</li> </ul> <p>Once deployed, the server automatically starts and registers its available tools. You can monitor the job status in the MCP Server side panel.</p>"},{"location":"mcp/quick_start/#connecting-to-the-mcp-server","title":"Connecting to the MCP Server","text":"<p>You can connect to your MCP server using any MCP client. Here's what you need:</p> <ol> <li>MCP Server URL: Copy this from the UiPath MCP Servers page in Orchestrator</li> </ol> <p> </p> <ol> <li>Authentication: Use your Personal Access Token (PAT) with Orchestrator API Access scopes as authorization header</li> <li>Transport: Configure the client to use HTTP Streamable transport</li> </ol>"},{"location":"mcp/quick_start/#next-steps","title":"Next Steps","text":"<p>Congratulations! You have successfully set up, created, published, and run a coded UiPath MCP Server. \ud83d\ude80</p> <p>For more coded MCP samples, please refer to our samples section in GitHub.</p>"},{"location":"openai-agents/quick_start/","title":"Quickstart Guide: UiPath OpenAI Agents","text":""},{"location":"openai-agents/quick_start/#introduction","title":"Introduction","text":"<p>This guide provides step-by-step instructions for setting up, creating, publishing, and running your first UiPath OpenAI Agent.</p>"},{"location":"openai-agents/quick_start/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure you have the following installed:</p> <ul> <li>Python 3.11 or higher</li> <li><code>pip</code> or <code>uv</code> package manager</li> <li>A UiPath Automation Cloud account with appropriate permissions</li> <li>An OpenAI API key</li> </ul> <p>Info</p> <p>OpenAI - Generate an OpenAI API key here.</p>"},{"location":"openai-agents/quick_start/#creating-a-new-project","title":"Creating a New Project","text":"<p>We recommend using <code>uv</code> for package management. To create a new project:</p> Linux, macOS, Windows BashWindows PowerShell mkdir examplecd example New-Item -ItemType Directory -Path exampleSet-Location example uvpip # Initialize a new uv project in the current directoryuv init . --python 3.11# Create a new virtual environment# By default, uv creates a virtual environment in a directory called .venvuv venvUsing CPython 3.11.16 interpreter at: [PATH]Creating virtual environment at: .venvActivate with: source .venv/bin/activate# Activate the virtual environment# For Windows PowerShell/ Windows CMD: .venv\\Scripts\\activate# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Install the uipath packageuv add uipath-openai-agents # Create a new virtual environmentpython -m venv .venv# Activate the virtual environment# For Windows PowerShell: .venv\\Scripts\\Activate.ps1# For Windows Bash: source .venv/Scripts/activatesource .venv/bin/activate# Upgrade pip to the latest versionpython -m pip install --upgrade pip# Install the uipath packagepip install uipath-openai-agents"},{"location":"openai-agents/quick_start/#create-your-first-uipath-agent","title":"Create Your First UiPath Agent","text":"<p>Generate your first UiPath OpenAI agent:</p> uipath new my-agent\u280b Creating new agent my-agent in current directory ...\u2713  Created 'main.py' file.\u2713  Created 'openai_agents.json' file.\u2713  Created 'pyproject.toml' file.\ud83d\udd27  Please ensure to define OPENAI_API_KEY in your .env file.\ud83d\udca1  Initialize project: uipath init\ud83d\udca1  Run agent: uipath run agent '{\"messages\": \"Hello\"}' <p>This command creates the following files:</p> File Name Description <code>main.py</code> OpenAI Agents code. <code>openai_agents.json</code> OpenAI Agents specific configuration file. <code>pyproject.toml</code> Project metadata and dependencies as per PEP 518."},{"location":"openai-agents/quick_start/#initialize-project","title":"Initialize Project","text":"uipath init\u280b Initializing UiPath project ...\u2713   Created '.env' file.\u2713   Created 'agent.mermaid' file.\u2713   Created 'entry-points.json' file. <p>This command creates the following files:</p> File Name Description <code>.env</code> Environment variables and secrets (this file will not be packed &amp; published). <code>uipath.json</code> Input/output JSON schemas and bindings. <code>agent.mermaid</code> Graph visual representation."},{"location":"openai-agents/quick_start/#set-up-environment-variables","title":"Set Up Environment Variables","text":"<p>Before running the agent, configure <code>OPENAI_API_KEY</code> in the <code>.env</code> file:</p> Open AI <pre><code>OPENAI_API_KEY=sk-proj-......\n</code></pre>"},{"location":"openai-agents/quick_start/#authenticate-with-uipath","title":"Authenticate With UiPath","text":"uipath auth\u280b Authenticating with UiPath ...\ud83d\udd17 If a browser window did not open, please open the following URL in your browser: [LINK]\ud83d\udc47 Select tenant:  0: Tenant1  1: Tenant2Select tenant number: 0Selected tenant: Tenant1\u2713  Authentication successful."},{"location":"openai-agents/quick_start/#run-the-agent-locally","title":"Run The Agent Locally","text":"<p>Execute the agent with a sample input:</p> uipath run agent '{\"messages\": \"Hello\"}'{'response': 'Hello! How can I help you today?', 'agent_used': 'main'}\u2713  Successful execution. <p>This command runs your agent locally and displays the output in the standard output.</p> <p>Warning</p> <p>Depending on the shell you are using, it may be necessary to escape the input json:</p> Bash/ZSH/PowerShellWindows CMDWindows PowerShell <pre><code>uipath run agent '{\"messages\": \"Hello\"}'\n</code></pre> <pre><code>uipath run agent \"{\"\"messages\"\": \"\"Hello\"\"}\"\n</code></pre> <pre><code>uipath run agent '{\\\"messages\\\":\\\"Hello\\\"}'\n</code></pre> <p>Attention</p> <p>For a shell agnostic option, please refer to the next section.</p>"},{"location":"openai-agents/quick_start/#optional-run-the-agent-with-a-json-file-as-input","title":"(Optional) Run The Agent with a json File as Input","text":"<p>The <code>run</code> command can also take a .json file as an input. You can create a file named <code>input.json</code> having the following content:</p> <pre><code>{\n  \"messages\": \"Hello\"\n}\n</code></pre> <p>Use this file as agent input:</p> <pre><code>&gt; uipath run agent --file input.json\n</code></pre>"},{"location":"openai-agents/quick_start/#deploy-the-agent-to-uipath-automation-cloud","title":"Deploy the Agent to UiPath Automation Cloud","text":"<p>Follow these steps to publish and run your agent to UiPath Automation Cloud:</p>"},{"location":"openai-agents/quick_start/#optional-customize-the-package","title":"(Optional) Customize the Package","text":"<p>Update author details in <code>pyproject.toml</code>:</p> <pre><code>authors = [{ name = \"Your Name\", email = \"your.name@example.com\" }]\n</code></pre>"},{"location":"openai-agents/quick_start/#package-your-project","title":"Package Your Project","text":"uipath pack\u280b Packaging project ...Name       : testVersion    : 0.1.0Description: Add your description hereAuthors    : Your Name\u2713  Project successfully packaged."},{"location":"openai-agents/quick_start/#publish-to-my-workspace","title":"Publish To My Workspace","text":"uipath publish --my-workspace\u2819 Publishing most recent package: my-agent.0.0.1.nupkg ...\u2713  Package published successfully!\u2826 Getting process information ...\ud83d\udd17 Process configuration link: [LINK]\ud83d\udca1 Use the link above to configure any environment variables <p>Info</p> <p>Please note that a process will be auto-created only upon publishing to my-workspace package feed.</p> <p>Set the environment variables using the provided link.</p>"},{"location":"openai-agents/quick_start/#invoke-the-agent-on-uipath-automation-cloud","title":"Invoke the Agent on UiPath Automation Cloud","text":"uipath invoke agent '{\"messages\": \"Hello\"}'\u2834 Loading configuration ...\u2834 Starting job ...\u2728 Job started successfully!\ud83d\udd17 Monitor your job here: [LINK] <p>Use the provided link to monitor your job and view detailed traces.</p>"},{"location":"openai-agents/quick_start/#optional-invoke-the-agent-with-a-json-file-as-input","title":"(Optional) Invoke The Agent with a json File as Input","text":"<p>The <code>invoke</code> command operates similarly to the <code>run</code> command, allowing you to use the same .json file defined in the (Optional) Run the agent with a .json file as input section, as agent input:</p> <pre><code>&gt; uipath invoke agent --file input.json\n</code></pre>"},{"location":"openai-agents/quick_start/#next-steps","title":"Next Steps","text":"<p>Congratulations! You have successfully set up, created, published, and run a UiPath OpenAI Agent. \ud83d\ude80</p> <p>For more advanced agents and agent samples, please refer to our samples section in GitHub.</p>"}]}